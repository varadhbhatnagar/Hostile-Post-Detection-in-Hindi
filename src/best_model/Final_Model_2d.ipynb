{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model_2d.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6bf196158ea14a698f1fea85908254b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b6f9cd6b38b04fb3a93d835389b3495d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_747c1fd3804c4a3b957be4c6554e9098",
              "IPY_MODEL_2ba6b21677dc4b958d408a554c8fa28d"
            ]
          }
        },
        "b6f9cd6b38b04fb3a93d835389b3495d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "747c1fd3804c4a3b957be4c6554e9098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96e325dd81954f908463a760d543ace8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1215,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1215,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b1928ed3a104d968b72d54b963b7ffb"
          }
        },
        "2ba6b21677dc4b958d408a554c8fa28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7dee468a8d764cc5b7a46a5441a303b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.22k/1.22k [00:00&lt;00:00, 1.61kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01a3198dac6945fb93d8db97fe74a96c"
          }
        },
        "96e325dd81954f908463a760d543ace8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b1928ed3a104d968b72d54b963b7ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dee468a8d764cc5b7a46a5441a303b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01a3198dac6945fb93d8db97fe74a96c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a20477374ff41bd9488c02404b434a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c56dc03319c342258f356b08c437d582",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42f082f8452b4b05ab1b59e45e20aed3",
              "IPY_MODEL_72590b7510fc41b0ac958b094db4da0c"
            ]
          }
        },
        "c56dc03319c342258f356b08c437d582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42f082f8452b4b05ab1b59e45e20aed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab7ce78bde4e4528b4c3c6bddfa84874",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87878d460fcb4cf6a3d235d035224890"
          }
        },
        "72590b7510fc41b0ac958b094db4da0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6bb1205bc25e423ebaed094b736c6a1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 2.21MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f045a92e5934c30a291c896041babb4"
          }
        },
        "ab7ce78bde4e4528b4c3c6bddfa84874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87878d460fcb4cf6a3d235d035224890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bb1205bc25e423ebaed094b736c6a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f045a92e5934c30a291c896041babb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20c2fd9e02fd4a1ea4f441a830b66e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_077b2411f73546a1897942575962a8eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d2f8bc02e5a84174a8ef3697fafb56fa",
              "IPY_MODEL_ff437774560545dbbdc362f5c3e237ec"
            ]
          }
        },
        "077b2411f73546a1897942575962a8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2f8bc02e5a84174a8ef3697fafb56fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bf818839c1e41f0b94733f5e10cf8cc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_357e2ba970d54ff3b4992b1758c56752"
          }
        },
        "ff437774560545dbbdc362f5c3e237ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb88a07fcf334fbbb757396d4b14b3fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 729B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2760e8165fd34c4ca09a9507c101998d"
          }
        },
        "0bf818839c1e41f0b94733f5e10cf8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "357e2ba970d54ff3b4992b1758c56752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb88a07fcf334fbbb757396d4b14b3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2760e8165fd34c4ca09a9507c101998d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc5eafb635fa4729870bbf9e9381f993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ad2c374737d4706ac897cac0b8b5201",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_95e0149818f043bb8a17c2036ed14958",
              "IPY_MODEL_f902959729e140c4a77fed3cea656b2b"
            ]
          }
        },
        "5ad2c374737d4706ac897cac0b8b5201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95e0149818f043bb8a17c2036ed14958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_692d1f61adb54bc9b1f7e2a30724ad7b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 152,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 152,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5a9f048915140cc85f902f05f670646"
          }
        },
        "f902959729e140c4a77fed3cea656b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31c4febc3b724d099ee3896cb3d3856d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 152/152 [00:00&lt;00:00, 1.02kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4efd87c6a4c848debcea211e83db035c"
          }
        },
        "692d1f61adb54bc9b1f7e2a30724ad7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5a9f048915140cc85f902f05f670646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31c4febc3b724d099ee3896cb3d3856d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4efd87c6a4c848debcea211e83db035c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eed9d4ab13d44274a704463242c13f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3f8433c9e55847d1aeff789586b2f3f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fec2c81db31d4725be5b202a5c5a0065",
              "IPY_MODEL_9a9c156104034b4c8864d771ba5724c8"
            ]
          }
        },
        "3f8433c9e55847d1aeff789586b2f3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fec2c81db31d4725be5b202a5c5a0065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2aefd51cefa541b78b0d5a9e9df53c13",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714309763,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714309763,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c1cf13202924689abd711e4b06c1150"
          }
        },
        "9a9c156104034b4c8864d771ba5724c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5da67453863549329a6b9d7bd23fc72e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:16&lt;00:00, 42.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16ba7cd46823459b9068822b4b2e77a4"
          }
        },
        "2aefd51cefa541b78b0d5a9e9df53c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c1cf13202924689abd711e4b06c1150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5da67453863549329a6b9d7bd23fc72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16ba7cd46823459b9068822b4b2e77a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyjuPoOPjJq"
      },
      "source": [
        "**Model Specifications**\n",
        "Detect Offensive using verloop Bert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWMvHep3B7C"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOS1Mp42yMw",
        "outputId": "99060026-3d40-4bd3-818c-e9ec6c345ca0"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 16.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c94a3175ce6fb39ef0dcd0ef51c26d1d403dfba251638bb8e2a3326192aa8ff7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBBc1EW3F4v"
      },
      "source": [
        "**Required Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPNhzGe3A_-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import ast\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ958U2_3YnT"
      },
      "source": [
        "**Reading Data and Rearranging into DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJalNxA3Xqj"
      },
      "source": [
        "train_file = 'train.csv'\n",
        "val_file = 'val.csv'\n",
        "test_file = 'test.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDH9cHl3fjU"
      },
      "source": [
        "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
        "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
        "non_hostile_val_data = pd.read_csv('y_pred_val_non_hostile.csv', header=0, index_col=0)\n",
        "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
        "train_val_data = train_data.append(val_data, ignore_index=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6tPwxYgijPd"
      },
      "source": [
        "non_hostile_test_data = pd.read_csv('y_pred_test_non_hostile.csv', header=0, index_col=0)\n",
        "val_data_orig = val_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Y-IcvgC1DK"
      },
      "source": [
        "train_data.drop(train_data[train_data['Labels Set']=='non-hostile'].index, inplace = True)\n",
        "val_data.drop(non_hostile_val_data[non_hostile_val_data['non-hostile']==1].index, inplace=True)\n",
        "train_val_data.drop(train_val_data[train_val_data['Labels Set']=='non-hostile'].index, inplace = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mtwrtNEig5N"
      },
      "source": [
        "test_data.drop(non_hostile_test_data[non_hostile_test_data['non-hostile']==1].index, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "mL-Yczph4Chg",
        "outputId": "eec75a1a-33df-4b29-9767-d535d71f4b8b"
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ... Unnamed: 13\n",
              "Unique ID                                                     ...            \n",
              "1          मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "4          @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "6          चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "11         RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "12         RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "nSxggvRQ4EGE",
        "outputId": "d76e9f25-8d89-4493-9df3-49ccc4389ccd"
      },
      "source": [
        "print(val_data.shape)\n",
        "val_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(380, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>defamation</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "2          भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...  ...  भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...\n",
              "8          अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...  ...  अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...\n",
              "13         भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...  ...  भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...\n",
              "14         यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...  ...  दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...\n",
              "15         सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...  ...  सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JHNlD7M44Esg",
        "outputId": "4d765523-2b7a-4c5f-a787-a3ae3da6eb9e"
      },
      "source": [
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(759, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '😂', '👍']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['👇', '😂', '😂', '😂', '😂']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>इन पंचर छापों को कोन समझाए कि उनके रोजगार मे...</td>\n",
              "      <td>पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@BasudebaTripat4:', '@Rajanspsingh1']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अच्छा किया साले का सर फोड़ दिया,, गर्दन तोड़...</td>\n",
              "      <td>अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...  ...  कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...\n",
              "3          कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...  ...  कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...\n",
              "4          अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...  ...  अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।\n",
              "5          RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...  ...  पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...\n",
              "8          @BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...  ...  अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hMC_GwsU8-Sm",
        "outputId": "b15c79df-1d8f-4d6e-cb1e-6290709aaee9"
      },
      "source": [
        "print(train_val_data.shape)\n",
        "train_val_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3054, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Post  ... Unnamed: 13\n",
              "0   मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "3   @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "5   चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "10  RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "11  RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTg69u-b4wDw"
      },
      "source": [
        "**Transforming the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPoz0-5P4IsD"
      },
      "source": [
        "labels_set = {'defamation',\n",
        " 'fake',\n",
        " 'hate',\n",
        " 'non-hostile',\n",
        " 'offensive'}\n",
        "\n",
        "labels_mapping = {'defamation':0,\n",
        " 'fake':1,\n",
        " 'hate':2,\n",
        " 'non-hostile':3,\n",
        " 'offensive':4}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1OzBY4MKF"
      },
      "source": [
        "train_y = np.empty((0, 5))\n",
        "for index, row in train_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_y = np.vstack((train_y, y))\n",
        "\n",
        "\n",
        "val_y = np.empty((0, 5))\n",
        "for index, row in val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  val_y = np.vstack((val_y, y))\n",
        "\n",
        "train_val_y = np.empty((0, 5))\n",
        "for index, row in train_val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_val_y = np.vstack((train_val_y, y))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBa01jcE4NWo",
        "outputId": "51a3ca2a-9c94-4748-868c-85cf75361d5e"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(train_val_y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 5)\n",
            "(380, 5)\n",
            "(3054, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCtXMKS64VT"
      },
      "source": [
        "**Modelling Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AzCgmM40un"
      },
      "source": [
        "def X_process(sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FZSOIJ5Ua2"
      },
      "source": [
        "def train_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    return train_dataloader"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AFD9Fs5aOw"
      },
      "source": [
        "def val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return validation_dataloader"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fjVV8d5a5f"
      },
      "source": [
        "def test_load(input_ids, attention_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMF_Pg-9XYn"
      },
      "source": [
        "def train_val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_validation_dataloader = DataLoader(\n",
        "                train_val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return train_validation_dataloader"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBErql77BAv"
      },
      "source": [
        "def train_fn(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask,\n",
        "                                       labels=b_labels)\n",
        "                loss = state.loss\n",
        "                logits = state.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17SD78fGdXtx"
      },
      "source": [
        "def train_fn_test(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask)\n",
        "                logits = state.logits\n",
        "\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBONPGg77Clo"
      },
      "source": [
        "def stats(training_stats):\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    return df_stats\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhcuXIG7Dpk"
      },
      "source": [
        "def plot_stats(df_stats):\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evcCcgjA7FTu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MSQH9l7GSm"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHqtP0nElkb"
      },
      "source": [
        "def evaluation(y_true, y_pred):\n",
        "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEu7-vTNxst"
      },
      "source": [
        "\n",
        "**Training for Offensive Class (Using Train Data and Val Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxBtbX61Nxsu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6bf196158ea14a698f1fea85908254b0",
            "b6f9cd6b38b04fb3a93d835389b3495d",
            "747c1fd3804c4a3b957be4c6554e9098",
            "2ba6b21677dc4b958d408a554c8fa28d",
            "96e325dd81954f908463a760d543ace8",
            "4b1928ed3a104d968b72d54b963b7ffb",
            "7dee468a8d764cc5b7a46a5441a303b6",
            "01a3198dac6945fb93d8db97fe74a96c",
            "4a20477374ff41bd9488c02404b434a1",
            "c56dc03319c342258f356b08c437d582",
            "42f082f8452b4b05ab1b59e45e20aed3",
            "72590b7510fc41b0ac958b094db4da0c",
            "ab7ce78bde4e4528b4c3c6bddfa84874",
            "87878d460fcb4cf6a3d235d035224890",
            "6bb1205bc25e423ebaed094b736c6a1e",
            "3f045a92e5934c30a291c896041babb4",
            "20c2fd9e02fd4a1ea4f441a830b66e2a",
            "077b2411f73546a1897942575962a8eb",
            "d2f8bc02e5a84174a8ef3697fafb56fa",
            "ff437774560545dbbdc362f5c3e237ec",
            "0bf818839c1e41f0b94733f5e10cf8cc",
            "357e2ba970d54ff3b4992b1758c56752",
            "cb88a07fcf334fbbb757396d4b14b3fc",
            "2760e8165fd34c4ca09a9507c101998d",
            "bc5eafb635fa4729870bbf9e9381f993",
            "5ad2c374737d4706ac897cac0b8b5201",
            "95e0149818f043bb8a17c2036ed14958",
            "f902959729e140c4a77fed3cea656b2b",
            "692d1f61adb54bc9b1f7e2a30724ad7b",
            "a5a9f048915140cc85f902f05f670646",
            "31c4febc3b724d099ee3896cb3d3856d",
            "4efd87c6a4c848debcea211e83db035c",
            "eed9d4ab13d44274a704463242c13f81",
            "3f8433c9e55847d1aeff789586b2f3f4",
            "fec2c81db31d4725be5b202a5c5a0065",
            "9a9c156104034b4c8864d771ba5724c8",
            "2aefd51cefa541b78b0d5a9e9df53c13",
            "2c1cf13202924689abd711e4b06c1150",
            "5da67453863549329a6b9d7bd23fc72e",
            "16ba7cd46823459b9068822b4b2e77a4"
          ]
        },
        "outputId": "818214a7-4315-4756-9930-7716910d8764"
      },
      "source": [
        "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
        "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(26)\n",
        "np.random.seed(26)\n",
        "torch.manual_seed(26)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device) # Send the model to the GPU if we have one"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bf196158ea14a698f1fea85908254b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1215.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a20477374ff41bd9488c02404b434a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20c2fd9e02fd4a1ea4f441a830b66e2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc5eafb635fa4729870bbf9e9381f993",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=152.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eed9d4ab13d44274a704463242c13f81",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714309763.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UumXdB9Nxsx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Nr_05qNxsy"
      },
      "source": [
        "**TODO: Tryout different batchsize and length (80, 100)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2RNGhpNxsy"
      },
      "source": [
        "batch_size = 8\n",
        "max_length = 256"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPL2bLLvOWzr"
      },
      "source": [
        "# train_sentences = train_data['Filtered_Post'].values\n",
        "# val_sentences = val_data['Filtered_Post'].values\n",
        "# test_sentences = test_data['Filtered_Post'].values\n",
        "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
        "\n",
        "train_sentences = train_data['Post'].values\n",
        "val_sentences = val_data['Post'].values\n",
        "test_sentences = test_data['Post'].values\n",
        "train_val_sentences = train_val_data['Post'].values"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbgOIjuQffx"
      },
      "source": [
        "y_train_offensive = train_y[:,4].astype(int)\n",
        "y_val_offensive = val_y[:,4].astype(int)\n",
        "y_train_val_offensive = train_val_y[:,4].astype(int)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzuEr8LedH7Y"
      },
      "source": [
        "train_labels_offensive = y_train_offensive\n",
        "val_labels_offensive = y_val_offensive"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8t3Bc3Nxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83070bd2-32d8-47e3-adb2-467dc11eefe1"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_sentences)\n",
        "train_dataloader = train_load(input_ids, attention_masks, train_labels_offensive)\n",
        "\n",
        "input_ids, attention_masks = X_process(val_sentences)\n",
        "validation_dataloader = val_load(input_ids, attention_masks, val_labels_offensive)\n",
        "\n",
        "input_ids, attention_masks = X_process(test_sentences)\n",
        "test_dataloader = test_load(input_ids, attention_masks)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2p6AI3Nxsy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JzyqSFNxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6dded1b-2a48-4e88-afc8-f6f29eafa471"
      },
      "source": [
        "training_stats, y_pred_val_offensive = train_fn(train_dataloader, validation_dataloader)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    335.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    335.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    335.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    335.    Elapsed: 0:01:08.\n",
            "  Batch   320  of    335.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.52\n",
            "  Validation took: 0:00:03\n",
            "[{'epoch': 1, 'Training Loss': 0.5649171155335299, 'Valid. Loss': 0.5246555572375655, 'Valid. Accur.': 0.7552083333333334, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    335.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    335.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    335.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    335.    Elapsed: 0:01:08.\n",
            "  Batch   320  of    335.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.52\n",
            "  Validation took: 0:00:03\n",
            "[{'epoch': 1, 'Training Loss': 0.5649171155335299, 'Valid. Loss': 0.5246555572375655, 'Valid. Accur.': 0.7552083333333334, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}, {'epoch': 2, 'Training Loss': 0.46877439297846896, 'Valid. Loss': 0.5173495428947111, 'Valid. Accur.': 0.78125, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    335.    Elapsed: 0:00:39.\n",
            "  Batch   200  of    335.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    335.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    335.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    335.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:00:03\n",
            "[{'epoch': 1, 'Training Loss': 0.5649171155335299, 'Valid. Loss': 0.5246555572375655, 'Valid. Accur.': 0.7552083333333334, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}, {'epoch': 2, 'Training Loss': 0.46877439297846896, 'Valid. Loss': 0.5173495428947111, 'Valid. Accur.': 0.78125, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}, {'epoch': 3, 'Training Loss': 0.3948856049787198, 'Valid. Loss': 0.7119659920378277, 'Valid. Accur.': 0.7864583333333334, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    335.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    335.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    335.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    335.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    335.    Elapsed: 0:01:17.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:03\n",
            "[{'epoch': 1, 'Training Loss': 0.5649171155335299, 'Valid. Loss': 0.5246555572375655, 'Valid. Accur.': 0.7552083333333334, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}, {'epoch': 2, 'Training Loss': 0.46877439297846896, 'Valid. Loss': 0.5173495428947111, 'Valid. Accur.': 0.78125, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}, {'epoch': 3, 'Training Loss': 0.3948856049787198, 'Valid. Loss': 0.7119659920378277, 'Valid. Accur.': 0.7864583333333334, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}, {'epoch': 4, 'Training Loss': 0.3154290693631368, 'Valid. Loss': 0.6934038076821404, 'Valid. Accur.': 0.7864583333333334, 'Training Time': '0:01:21', 'Validation Time': '0:00:03'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoV30azNxsz"
      },
      "source": [
        "**Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvWJNE7YNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "530e6165-1371-46a6-aa59-7ede0f04f19e"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZ4Tx8PNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7b66a8b1-7a60-4c80-cfd9-1ec27db7640c"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.56         0.52           0.76       0:01:21         0:00:03\n",
              "2               0.47         0.52           0.78       0:01:21         0:00:03\n",
              "3               0.39         0.71           0.79       0:01:21         0:00:03\n",
              "4               0.32         0.69           0.79       0:01:21         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrRQFllONxsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74213ca7-4860-42be-d83a-7aece32209b9"
      },
      "source": [
        "evaluation(y_val_offensive, y_pred_val_offensive)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine Grained Accuracy = 0.7894736842105263\n",
            "\n",
            "\n",
            "Fine Grained Metrics\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       278\n",
            "           1       0.63      0.52      0.57       102\n",
            "\n",
            "    accuracy                           0.79       380\n",
            "   macro avg       0.73      0.70      0.72       380\n",
            "weighted avg       0.78      0.79      0.78       380\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHgr-fodo8e"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_val_offensive, index = val_data.index, columns=['offensive'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_val_offensive.csv')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HWdCRDNxs0"
      },
      "source": [
        "**Training for Offensive Class (Using Train +Val Data and Test Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwvcdNspi294"
      },
      "source": [
        "train_val_labels_offensive = y_train_val_offensive"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-RaRs7Nxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8acf673-0042-41f1-d017-f79d8b5f7223"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_val_sentences)\n",
        "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_offensive)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wfwVeBNxs0"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_val_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmjATAqNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da322448-1ef3-4c83-925b-3828e65a6d95"
      },
      "source": [
        "training_stats, y_pred_offensive = train_fn_test(train_val_dataloader, test_dataloader)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    382.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    382.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    382.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    382.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    382.    Elapsed: 0:01:17.\n",
            "  Batch   360  of    382.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:06\n",
            "[{'epoch': 1, 'Training Loss': 0.38509326056986853, 'Training Time': '0:01:32', 'Validation Time': '0:00:06'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    382.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    382.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    382.    Elapsed: 0:00:58.\n",
            "  Batch   280  of    382.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    382.    Elapsed: 0:01:17.\n",
            "  Batch   360  of    382.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:06\n",
            "[{'epoch': 1, 'Training Loss': 0.38509326056986853, 'Training Time': '0:01:32', 'Validation Time': '0:00:06'}, {'epoch': 2, 'Training Loss': 0.3207547056046193, 'Training Time': '0:01:32', 'Validation Time': '0:00:06'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    382.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    382.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    382.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    382.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    382.    Elapsed: 0:01:16.\n",
            "  Batch   360  of    382.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:06\n",
            "[{'epoch': 1, 'Training Loss': 0.38509326056986853, 'Training Time': '0:01:32', 'Validation Time': '0:00:06'}, {'epoch': 2, 'Training Loss': 0.3207547056046193, 'Training Time': '0:01:32', 'Validation Time': '0:00:06'}, {'epoch': 3, 'Training Loss': 0.2326070866325056, 'Training Time': '0:01:31', 'Validation Time': '0:00:06'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:19.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:29.\n",
            "  Batch   160  of    382.    Elapsed: 0:00:38.\n",
            "  Batch   200  of    382.    Elapsed: 0:00:48.\n",
            "  Batch   240  of    382.    Elapsed: 0:00:57.\n",
            "  Batch   280  of    382.    Elapsed: 0:01:07.\n",
            "  Batch   320  of    382.    Elapsed: 0:01:16.\n",
            "  Batch   360  of    382.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:01:31\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:06\n",
            "[{'epoch': 1, 'Training Loss': 0.38509326056986853, 'Training Time': '0:01:32', 'Validation Time': '0:00:06'}, {'epoch': 2, 'Training Loss': 0.3207547056046193, 'Training Time': '0:01:32', 'Validation Time': '0:00:06'}, {'epoch': 3, 'Training Loss': 0.2326070866325056, 'Training Time': '0:01:31', 'Validation Time': '0:00:06'}, {'epoch': 4, 'Training Loss': 0.16537638715482367, 'Training Time': '0:01:31', 'Validation Time': '0:00:06'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlAyssNRJ2S"
      },
      "source": [
        "**Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhWwhMUNxs0"
      },
      "source": [
        "df_stats  = stats(training_stats)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54illM8xNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3d96b3c2-ed2c-4af0-e896-a0a3b3607549"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0:01:32</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0:01:32</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0:01:31</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.17</td>\n",
              "      <td>0:01:31</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss Training Time Validation Time\n",
              "epoch                                             \n",
              "1               0.39       0:01:32         0:00:06\n",
              "2               0.32       0:01:32         0:00:06\n",
              "3               0.23       0:01:31         0:00:06\n",
              "4               0.17       0:01:31         0:00:06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amqNhvhitcLw"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_offensive, index = test_data.index, columns=['offensive'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_test_offensive.csv')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns2a9AgNg6sD",
        "outputId": "816f7948-1c21-4702-f4d9-347675d0019d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuWhX_F-hhr6"
      },
      "source": [
        "model_save_name = 'offensive_test.tar'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 50,
      "outputs": []
    }
  ]
}