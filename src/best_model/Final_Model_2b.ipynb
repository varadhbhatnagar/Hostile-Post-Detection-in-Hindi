{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model_2b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "261075dc16644e50aa881cac33e17f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ea3d92c2691498e90aef00a35e58b9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef6a4cbe57c14920b6d35968659dcd40",
              "IPY_MODEL_5116f53d9c864c76a9289d953173a03c"
            ]
          }
        },
        "2ea3d92c2691498e90aef00a35e58b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef6a4cbe57c14920b6d35968659dcd40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4c2fe449a8c8401e9a6f2edcc430ba89",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1215,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1215,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_329a8f66e72049db9fe64d0e590483f6"
          }
        },
        "5116f53d9c864c76a9289d953173a03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eedbb73e791d4746b6d1ad03cb54a43b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.22k/1.22k [00:00&lt;00:00, 44.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71ff8e2d12ad4da1be4c2ab2bdefeb1e"
          }
        },
        "4c2fe449a8c8401e9a6f2edcc430ba89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "329a8f66e72049db9fe64d0e590483f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eedbb73e791d4746b6d1ad03cb54a43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71ff8e2d12ad4da1be4c2ab2bdefeb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d109f46620bb4b4da938254ed7a03966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e8aa709a159474884e43faaf28abf3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b209d75372234ee88c4a3bc28bd9ac30",
              "IPY_MODEL_39181bd1438a42cea6de101165e238d1"
            ]
          }
        },
        "2e8aa709a159474884e43faaf28abf3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b209d75372234ee88c4a3bc28bd9ac30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_005a1c998b6d4096a22570f6289af7d5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db7656007ce14627bfbeb6c61ba05863"
          }
        },
        "39181bd1438a42cea6de101165e238d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_51e7f9840d134b7bbe08e43eb4cf7db8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:05&lt;00:00, 177kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_862fabf263b644c2b442d9ceb987eeaa"
          }
        },
        "005a1c998b6d4096a22570f6289af7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db7656007ce14627bfbeb6c61ba05863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51e7f9840d134b7bbe08e43eb4cf7db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "862fabf263b644c2b442d9ceb987eeaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81cf4b2baed8492c9feeb1e78f7bb7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_89ab23591e0d4cddac731588db85141c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a24873dfa41047b2a36b22e7b2ba2d6a",
              "IPY_MODEL_8e229c622c2b4d919ab71f7c14df7c27"
            ]
          }
        },
        "89ab23591e0d4cddac731588db85141c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a24873dfa41047b2a36b22e7b2ba2d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2ee55868d5e4eabab560acafedd3806",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a2bf30a76fe498c94138fc54a393745"
          }
        },
        "8e229c622c2b4d919ab71f7c14df7c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a21e06cfa30f45be8e3294337a9655ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:01&lt;00:00, 80.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_740cbf9c267246499cd049abe2798e27"
          }
        },
        "d2ee55868d5e4eabab560acafedd3806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a2bf30a76fe498c94138fc54a393745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a21e06cfa30f45be8e3294337a9655ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "740cbf9c267246499cd049abe2798e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1546fc3ddd80400887e3a567cb5a249b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a08ff9b33c224f6193bb283f949b808e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_881455d52d634a46a5f24dff8d8bd28e",
              "IPY_MODEL_190565e206b44f2f8e04cc2332596e61"
            ]
          }
        },
        "a08ff9b33c224f6193bb283f949b808e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "881455d52d634a46a5f24dff8d8bd28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57d9f69dc53344a8a46ba7e6a035b69b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 152,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 152,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33c268c14f6a4895bff4fd72e8b008bb"
          }
        },
        "190565e206b44f2f8e04cc2332596e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ec0f52d21984140b8cdde243795ae97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 152/152 [00:00&lt;00:00, 1.04kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40c20eae45a54c8f9cf40332201b5bdc"
          }
        },
        "57d9f69dc53344a8a46ba7e6a035b69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33c268c14f6a4895bff4fd72e8b008bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ec0f52d21984140b8cdde243795ae97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40c20eae45a54c8f9cf40332201b5bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6e420a197394b798e2badc3e7c43d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4bb0f13ac15849018aa31edc8b027700",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c61342dc02c6459b9f06edd5c0ba96c9",
              "IPY_MODEL_2d959fc570a84db2b0fea84bb62fa8c3"
            ]
          }
        },
        "4bb0f13ac15849018aa31edc8b027700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c61342dc02c6459b9f06edd5c0ba96c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c89b324699a3417fbc0bf62fb3d29876",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714309763,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714309763,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c3ae3c68dfa42c79042d308bda42403"
          }
        },
        "2d959fc570a84db2b0fea84bb62fa8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c2b0c5c78254d989de1c00fef470491",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [01:09&lt;00:00, 10.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e131fdf4cbef4745afd16ff55ab8598b"
          }
        },
        "c89b324699a3417fbc0bf62fb3d29876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c3ae3c68dfa42c79042d308bda42403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c2b0c5c78254d989de1c00fef470491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e131fdf4cbef4745afd16ff55ab8598b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyjuPoOPjJq"
      },
      "source": [
        "**Model Specifications**\n",
        "Detect Fake Using verloop Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWMvHep3B7C"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOS1Mp42yMw",
        "outputId": "49894e03-bd85-4562-ccad-ecb95027626f"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 20.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=097750be4e1431111dcf8e5f0338b0f1e2c6d4c6a0d4d2497d8e1afbef8bd3d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBBc1EW3F4v"
      },
      "source": [
        "**Required Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPNhzGe3A_-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import ast\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ958U2_3YnT"
      },
      "source": [
        "**Reading Data and Rearranging into DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJalNxA3Xqj"
      },
      "source": [
        "train_file = 'train.csv'\n",
        "val_file = 'val.csv'\n",
        "test_file = 'test.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDH9cHl3fjU"
      },
      "source": [
        "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
        "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
        "non_hostile_val_data = pd.read_csv('y_pred_val_non_hostile.csv', header=0, index_col=0)\n",
        "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
        "train_val_data = train_data.append(val_data, ignore_index=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6tPwxYgijPd"
      },
      "source": [
        "non_hostile_test_data = pd.read_csv('y_pred_test_non_hostile.csv', header=0, index_col=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Y-IcvgC1DK"
      },
      "source": [
        "train_data.drop(train_data[train_data['Labels Set']=='non-hostile'].index, inplace = True)\n",
        "val_data.drop(non_hostile_val_data[non_hostile_val_data['non-hostile']==1].index, inplace=True)\n",
        "train_val_data.drop(train_val_data[train_val_data['Labels Set']=='non-hostile'].index, inplace = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mtwrtNEig5N"
      },
      "source": [
        "test_data.drop(non_hostile_test_data[non_hostile_test_data['non-hostile']==1].index, inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "mL-Yczph4Chg",
        "outputId": "948838e8-bff0-4820-8065-aece52def3ba"
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ... Unnamed: 13\n",
              "Unique ID                                                     ...            \n",
              "1          मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "4          @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "6          चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "11         RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "12         RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "nSxggvRQ4EGE",
        "outputId": "7d172233-54b3-4e46-d24f-51b05866b82f"
      },
      "source": [
        "print(val_data.shape)\n",
        "val_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(380, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>defamation</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "2          भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...  ...  भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...\n",
              "8          अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...  ...  अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...\n",
              "13         भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...  ...  भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...\n",
              "14         यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...  ...  दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...\n",
              "15         सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...  ...  सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JHNlD7M44Esg",
        "outputId": "4de3ed57-f89f-4366-9c2b-56621e4a906d"
      },
      "source": [
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(759, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '😂', '👍']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['👇', '😂', '😂', '😂', '😂']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>इन पंचर छापों को कोन समझाए कि उनके रोजगार मे...</td>\n",
              "      <td>पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@BasudebaTripat4:', '@Rajanspsingh1']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अच्छा किया साले का सर फोड़ दिया,, गर्दन तोड़...</td>\n",
              "      <td>अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...  ...  कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...\n",
              "3          कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...  ...  कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...\n",
              "4          अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...  ...  अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।\n",
              "5          RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...  ...  पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...\n",
              "8          @BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...  ...  अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hMC_GwsU8-Sm",
        "outputId": "eb15ed63-2f3a-40fe-e109-fd5065d13690"
      },
      "source": [
        "print(train_val_data.shape)\n",
        "train_val_data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3054, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Post  ... Unnamed: 13\n",
              "0   मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "3   @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "5   चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "10  RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "11  RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTg69u-b4wDw"
      },
      "source": [
        "**Transforming the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPoz0-5P4IsD"
      },
      "source": [
        "labels_set = {'defamation',\n",
        " 'fake',\n",
        " 'hate',\n",
        " 'non-hostile',\n",
        " 'offensive'}\n",
        "\n",
        "labels_mapping = {'defamation':0,\n",
        " 'fake':1,\n",
        " 'hate':2,\n",
        " 'non-hostile':3,\n",
        " 'offensive':4}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1OzBY4MKF"
      },
      "source": [
        "train_y = np.empty((0, 5))\n",
        "for index, row in train_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_y = np.vstack((train_y, y))\n",
        "\n",
        "\n",
        "val_y = np.empty((0, 5))\n",
        "for index, row in val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  val_y = np.vstack((val_y, y))\n",
        "\n",
        "train_val_y = np.empty((0, 5))\n",
        "for index, row in train_val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_val_y = np.vstack((train_val_y, y))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBa01jcE4NWo",
        "outputId": "ff63eba8-0807-4a13-9ec4-5227171506ac"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(train_val_y.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 5)\n",
            "(380, 5)\n",
            "(3054, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCtXMKS64VT"
      },
      "source": [
        "**Modelling Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AzCgmM40un"
      },
      "source": [
        "def X_process(sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FZSOIJ5Ua2"
      },
      "source": [
        "def train_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    return train_dataloader"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AFD9Fs5aOw"
      },
      "source": [
        "def val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return validation_dataloader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fjVV8d5a5f"
      },
      "source": [
        "def test_load(input_ids, attention_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMF_Pg-9XYn"
      },
      "source": [
        "def train_val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_validation_dataloader = DataLoader(\n",
        "                train_val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return train_validation_dataloader"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBErql77BAv"
      },
      "source": [
        "def train_fn(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask,\n",
        "                                       labels=b_labels)\n",
        "                loss = state.loss\n",
        "                logits = state.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17SD78fGdXtx"
      },
      "source": [
        "def train_fn_test(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask)\n",
        "                logits = state.logits\n",
        "\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBONPGg77Clo"
      },
      "source": [
        "def stats(training_stats):\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    return df_stats\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhcuXIG7Dpk"
      },
      "source": [
        "def plot_stats(df_stats):\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evcCcgjA7FTu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MSQH9l7GSm"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHqtP0nElkb"
      },
      "source": [
        "def evaluation(y_true, y_pred):\n",
        "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEu7-vTNxst"
      },
      "source": [
        "**Training for Fake Class (Using Train Data and Val Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxBtbX61Nxsu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "261075dc16644e50aa881cac33e17f47",
            "2ea3d92c2691498e90aef00a35e58b9d",
            "ef6a4cbe57c14920b6d35968659dcd40",
            "5116f53d9c864c76a9289d953173a03c",
            "4c2fe449a8c8401e9a6f2edcc430ba89",
            "329a8f66e72049db9fe64d0e590483f6",
            "eedbb73e791d4746b6d1ad03cb54a43b",
            "71ff8e2d12ad4da1be4c2ab2bdefeb1e",
            "d109f46620bb4b4da938254ed7a03966",
            "2e8aa709a159474884e43faaf28abf3b",
            "b209d75372234ee88c4a3bc28bd9ac30",
            "39181bd1438a42cea6de101165e238d1",
            "005a1c998b6d4096a22570f6289af7d5",
            "db7656007ce14627bfbeb6c61ba05863",
            "51e7f9840d134b7bbe08e43eb4cf7db8",
            "862fabf263b644c2b442d9ceb987eeaa",
            "81cf4b2baed8492c9feeb1e78f7bb7d3",
            "89ab23591e0d4cddac731588db85141c",
            "a24873dfa41047b2a36b22e7b2ba2d6a",
            "8e229c622c2b4d919ab71f7c14df7c27",
            "d2ee55868d5e4eabab560acafedd3806",
            "2a2bf30a76fe498c94138fc54a393745",
            "a21e06cfa30f45be8e3294337a9655ab",
            "740cbf9c267246499cd049abe2798e27",
            "1546fc3ddd80400887e3a567cb5a249b",
            "a08ff9b33c224f6193bb283f949b808e",
            "881455d52d634a46a5f24dff8d8bd28e",
            "190565e206b44f2f8e04cc2332596e61",
            "57d9f69dc53344a8a46ba7e6a035b69b",
            "33c268c14f6a4895bff4fd72e8b008bb",
            "3ec0f52d21984140b8cdde243795ae97",
            "40c20eae45a54c8f9cf40332201b5bdc",
            "e6e420a197394b798e2badc3e7c43d2c",
            "4bb0f13ac15849018aa31edc8b027700",
            "c61342dc02c6459b9f06edd5c0ba96c9",
            "2d959fc570a84db2b0fea84bb62fa8c3",
            "c89b324699a3417fbc0bf62fb3d29876",
            "6c3ae3c68dfa42c79042d308bda42403",
            "3c2b0c5c78254d989de1c00fef470491",
            "e131fdf4cbef4745afd16ff55ab8598b"
          ]
        },
        "outputId": "46592392-68a5-4510-86f9-46b04285aaa4"
      },
      "source": [
        "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
        "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(26)\n",
        "np.random.seed(26)\n",
        "torch.manual_seed(26)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device) # Send the model to the GPU if we have one"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "261075dc16644e50aa881cac33e17f47",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1215.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d109f46620bb4b4da938254ed7a03966",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81cf4b2baed8492c9feeb1e78f7bb7d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1546fc3ddd80400887e3a567cb5a249b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=152.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6e420a197394b798e2badc3e7c43d2c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714309763.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UumXdB9Nxsx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Nr_05qNxsy"
      },
      "source": [
        "**TODO: Tryout different batchsize and length (80, 100)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2RNGhpNxsy"
      },
      "source": [
        "batch_size = 8\n",
        "max_length = 256"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPL2bLLvOWzr"
      },
      "source": [
        "# train_sentences = train_data['Filtered_Post'].values\n",
        "# val_sentences = val_data['Filtered_Post'].values\n",
        "# test_sentences = test_data['Filtered_Post'].values\n",
        "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
        "\n",
        "train_sentences = train_data['Post'].values\n",
        "val_sentences = val_data['Post'].values\n",
        "test_sentences = test_data['Post'].values\n",
        "train_val_sentences = train_val_data['Post'].values"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbgOIjuQffx"
      },
      "source": [
        "y_train_fake = train_y[:,1].astype(int)\n",
        "y_val_fake = val_y[:,1].astype(int)\n",
        "y_train_val_fake = train_val_y[:,1].astype(int)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzuEr8LedH7Y"
      },
      "source": [
        "train_labels_fake = y_train_fake\n",
        "val_labels_fake = y_val_fake"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8t3Bc3Nxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13003b9-e338-45a9-eec7-4c7025324297"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_sentences)\n",
        "train_dataloader = train_load(input_ids, attention_masks, train_labels_fake)\n",
        "\n",
        "input_ids, attention_masks = X_process(val_sentences)\n",
        "validation_dataloader = val_load(input_ids, attention_masks, val_labels_fake)\n",
        "\n",
        "input_ids, attention_masks = X_process(test_sentences)\n",
        "test_dataloader = test_load(input_ids, attention_masks)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2p6AI3Nxsy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JzyqSFNxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85f1aa4-5e9c-413d-f008-7ab403916220"
      },
      "source": [
        "training_stats, y_pred_val_fake = train_fn(train_dataloader, validation_dataloader)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:03.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:24.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:44.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:02:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.511434615125407, 'Valid. Loss': 0.39411045936867595, 'Valid. Accur.': 0.8333333333333334, 'Training Time': '0:02:52', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:44.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:05.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:26.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:46.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:02:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.511434615125407, 'Valid. Loss': 0.39411045936867595, 'Valid. Accur.': 0.8333333333333334, 'Training Time': '0:02:52', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.38772564284614663, 'Valid. Loss': 0.3345353549035887, 'Valid. Accur.': 0.8723958333333334, 'Training Time': '0:02:54', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:44.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:04.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:25.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:46.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:02:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.49\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.511434615125407, 'Valid. Loss': 0.39411045936867595, 'Valid. Accur.': 0.8333333333333334, 'Training Time': '0:02:52', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.38772564284614663, 'Valid. Loss': 0.3345353549035887, 'Valid. Accur.': 0.8723958333333334, 'Training Time': '0:02:54', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.29792582864330996, 'Valid. Loss': 0.48932761811496067, 'Valid. Accur.': 0.8697916666666666, 'Training Time': '0:02:53', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:04.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:24.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:45.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:02:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.511434615125407, 'Valid. Loss': 0.39411045936867595, 'Valid. Accur.': 0.8333333333333334, 'Training Time': '0:02:52', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.38772564284614663, 'Valid. Loss': 0.3345353549035887, 'Valid. Accur.': 0.8723958333333334, 'Training Time': '0:02:54', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.29792582864330996, 'Valid. Loss': 0.48932761811496067, 'Valid. Accur.': 0.8697916666666666, 'Training Time': '0:02:53', 'Validation Time': '0:00:07'}, {'epoch': 4, 'Training Loss': 0.23692161221432487, 'Valid. Loss': 0.5755930253847813, 'Valid. Accur.': 0.8697916666666666, 'Training Time': '0:02:53', 'Validation Time': '0:00:07'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoV30azNxsz"
      },
      "source": [
        "**Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvWJNE7YNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9b2c3776-3468-47a7-a7d3-a9858096c729"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZ4Tx8PNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2f241631-e05c-419e-801e-701aa66387d9"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:02:52</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:02:54</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:02:53</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:02:53</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.51         0.39           0.83       0:02:52         0:00:07\n",
              "2               0.39         0.33           0.87       0:02:54         0:00:07\n",
              "3               0.30         0.49           0.87       0:02:53         0:00:07\n",
              "4               0.24         0.58           0.87       0:02:53         0:00:07"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrRQFllONxsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa95835-37e7-46a5-cd19-cd2dd92a1d4a"
      },
      "source": [
        "evaluation(y_val_fake, y_pred_val_fake)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine Grained Accuracy = 0.868421052631579\n",
            "\n",
            "\n",
            "Fine Grained Metrics\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.89       226\n",
            "           1       0.82      0.86      0.84       154\n",
            "\n",
            "    accuracy                           0.87       380\n",
            "   macro avg       0.86      0.87      0.86       380\n",
            "weighted avg       0.87      0.87      0.87       380\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHgr-fodo8e"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_val_fake, index = val_data.index, columns=['fake'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_val_fake.csv')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HWdCRDNxs0"
      },
      "source": [
        "**Training for Fake Class (Using Train +Val Data and Test Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwvcdNspi294"
      },
      "source": [
        "train_val_labels_fake = y_train_val_fake"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-RaRs7Nxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7122765f-8746-4b8f-8c9c-90c0b62d1fd5"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_val_sentences)\n",
        "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_fake)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wfwVeBNxs0"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_val_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmjATAqNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9c7747-8728-4927-eab3-cc1d6943f30a"
      },
      "source": [
        "training_stats, y_pred_test_fake = train_fn_test(train_val_dataloader, test_dataloader)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:04.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:25.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:45.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:06.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:03:17\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:13\n",
            "[{'epoch': 1, 'Training Loss': 0.30243992607544434, 'Training Time': '0:03:17', 'Validation Time': '0:00:13'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:04.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:24.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:45.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:06.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:03:17\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:13\n",
            "[{'epoch': 1, 'Training Loss': 0.30243992607544434, 'Training Time': '0:03:17', 'Validation Time': '0:00:13'}, {'epoch': 2, 'Training Loss': 0.2609813827140554, 'Training Time': '0:03:17', 'Validation Time': '0:00:13'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:03.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:24.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:45.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:05.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:03:16\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:13\n",
            "[{'epoch': 1, 'Training Loss': 0.30243992607544434, 'Training Time': '0:03:17', 'Validation Time': '0:00:13'}, {'epoch': 2, 'Training Loss': 0.2609813827140554, 'Training Time': '0:03:17', 'Validation Time': '0:00:13'}, {'epoch': 3, 'Training Loss': 0.1696617408821369, 'Training Time': '0:03:16', 'Validation Time': '0:00:13'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:03.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:24.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:44.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:05.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:03:16\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:13\n",
            "[{'epoch': 1, 'Training Loss': 0.30243992607544434, 'Training Time': '0:03:17', 'Validation Time': '0:00:13'}, {'epoch': 2, 'Training Loss': 0.2609813827140554, 'Training Time': '0:03:17', 'Validation Time': '0:00:13'}, {'epoch': 3, 'Training Loss': 0.1696617408821369, 'Training Time': '0:03:16', 'Validation Time': '0:00:13'}, {'epoch': 4, 'Training Loss': 0.11560071726586836, 'Training Time': '0:03:16', 'Validation Time': '0:00:13'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlAyssNRJ2S"
      },
      "source": [
        "**Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhWwhMUNxs0"
      },
      "source": [
        "df_stats  = stats(training_stats)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54illM8xNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "70962e85-c6c9-4d1e-b019-32ba584ff8b0"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0:03:17</td>\n",
              "      <td>0:00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0:03:17</td>\n",
              "      <td>0:00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.17</td>\n",
              "      <td>0:03:16</td>\n",
              "      <td>0:00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0:03:16</td>\n",
              "      <td>0:00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss Training Time Validation Time\n",
              "epoch                                             \n",
              "1               0.30       0:03:17         0:00:13\n",
              "2               0.26       0:03:17         0:00:13\n",
              "3               0.17       0:03:16         0:00:13\n",
              "4               0.12       0:03:16         0:00:13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnTc0kEYthUm"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_test_fake, index = test_data.index, columns=['fake'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_test_fake.csv')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jaHtVsc8Bww"
      },
      "source": [
        "torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, 'fake_test.tar')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnwsYUQRTA9d",
        "outputId": "2a43acc9-1018-415f-852c-a1d649e69d9b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNFzcxiwTC7L"
      },
      "source": [
        "model_save_name = 'fake_test.tar'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 52,
      "outputs": []
    }
  ]
}