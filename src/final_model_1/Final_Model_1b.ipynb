{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model_1b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyjuPoOPjJq"
      },
      "source": [
        "**Model Specifications**\n",
        "Detect Fake Using verloop Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWMvHep3B7C"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOS1Mp42yMw",
        "outputId": "f6da917e-9df0-4cd3-b340-64f9bf434e1d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBBc1EW3F4v"
      },
      "source": [
        "**Required Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPNhzGe3A_-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import ast\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ958U2_3YnT"
      },
      "source": [
        "**Reading Data and Rearranging into DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJalNxA3Xqj"
      },
      "source": [
        "train_file = 'train.csv'\n",
        "val_file = 'val.csv'\n",
        "test_file = 'test.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDH9cHl3fjU"
      },
      "source": [
        "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
        "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
        "non_hostile_val_data = pd.read_csv('y_pred_val_non_hostile.csv', header=0, index_col=0)\n",
        "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
        "train_val_data = train_data.append(val_data, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6tPwxYgijPd"
      },
      "source": [
        "non_hostile_test_data = pd.read_csv('y_pred_test_non_hostile.csv', header=0, index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Y-IcvgC1DK"
      },
      "source": [
        "train_data.drop(train_data[train_data['Labels Set']=='non-hostile'].index, inplace = True)\n",
        "val_data.drop(non_hostile_val_data[non_hostile_val_data['non-hostile']==1].index, inplace=True)\n",
        "train_val_data.drop(train_val_data[train_val_data['Labels Set']=='non-hostile'].index, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mtwrtNEig5N"
      },
      "source": [
        "test_data.drop(non_hostile_test_data[non_hostile_test_data['non-hostile']==1].index, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "mL-Yczph4Chg",
        "outputId": "1b4ee80c-8c75-438a-db8e-a86f839050fe"
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üôè', 'üôè']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
              "      <td>‡§ö‡•Ä‡§® UN ‡§§‡§∞‡•ç‡§ï ‡§≠‡§æ‡§∞‡§§ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§Ö‡§ú‡§∞‚Äå ‡§Æ‡§∏‡•Å‡§¶ ‡§Ü‡§§‡§Ç‡§ï‡•Ä ‡§Æ‡§æ‡§®‡§§‡§æ ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['ü§î']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ñ‡§°‡•Ä ‡§π‡•à,\\n\\...</td>\n",
              "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ñ‡§°‡•Ä ‡§π‡•à, ‡§∏‡§Ø‡§æ‡§®‡•á ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§™‡§°‡•á ‡§π‡•à? ‡§¨‡•ã...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•ã...</td>\n",
              "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§´‡§∞‡•ç‡§ï‡§º ‡§™‡§°‡§º‡§§‡§æ! ‡§Ö‡§Æ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ... Unnamed: 13\n",
              "Unique ID                                                     ...            \n",
              "1          ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
              "4          @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
              "6          ‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...  ...         NaN\n",
              "11         RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...  ...         NaN\n",
              "12         RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "nSxggvRQ4EGE",
        "outputId": "8e3910cf-9d01-46ba-b491-0a493e97c026"
      },
      "source": [
        "print(val_data.shape)\n",
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(379, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
              "      <td>defamation</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
              "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§ú‡•ã ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à ‡§ï‡§ø ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§Ø‡•Å‡§¶‡•ç...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§ú‡•ã ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à ‡§ï‡§ø ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§Ø‡•Å‡§¶‡•ç...</td>\n",
              "      <td>‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§π‡•à, ‡§∏‡§®...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö...</td>\n",
              "      <td>‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§Æ‡§¶‡§¶ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö‡§≤‡•Ä ‡§Ü‡§§‡•ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>‡§Ø‡§π ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§Æ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Ø‡§π ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§Æ...</td>\n",
              "      <td>‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§π‡•Å‡§à,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>‡§∏‡§§‡•ç‡§Ø ‡§ï‡§≠‡•Ä ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§π‡•ã‡§®‡•á ‡§¶‡•á‡§§‡§æ‡•§ ‡§î‡§∞ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§ï‡§≠‡•Ä ‡§¶...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡§§‡•ç‡§Ø ‡§ï‡§≠‡•Ä ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§π‡•ã‡§®‡•á ‡§¶‡•á‡§§‡§æ‡•§ ‡§î‡§∞ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§ï‡§≠‡•Ä ‡§¶...</td>\n",
              "      <td>‡§∏‡§§‡•ç‡§Ø ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§¶‡•á‡§§‡§æ‡•§ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§¶‡•Å‡§É‡§ñ‡•Ä ‡§≠‡§Ø‡§≠‡•Ä‡§§ ‡§®‡§π‡•Ä ‡§¶...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "2          ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...  ...  ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...\n",
              "8          ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§ú‡•ã ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à ‡§ï‡§ø ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§Ø‡•Å‡§¶‡•ç...  ...  ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§π‡•à, ‡§∏‡§®...\n",
              "13         ‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö...  ...  ‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§Æ‡§¶‡§¶ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö‡§≤‡•Ä ‡§Ü‡§§‡•ç...\n",
              "14         ‡§Ø‡§π ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§Æ...  ...  ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§π‡•Å‡§à,...\n",
              "15         ‡§∏‡§§‡•ç‡§Ø ‡§ï‡§≠‡•Ä ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§π‡•ã‡§®‡•á ‡§¶‡•á‡§§‡§æ‡•§ ‡§î‡§∞ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§ï‡§≠‡•Ä ‡§¶...  ...  ‡§∏‡§§‡•ç‡§Ø ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§¶‡•á‡§§‡§æ‡•§ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§¶‡•Å‡§É‡§ñ‡•Ä ‡§≠‡§Ø‡§≠‡•Ä‡§§ ‡§®‡§π‡•Ä ‡§¶...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JHNlD7M44Esg",
        "outputId": "cc24bbad-f04f-4207-d769-a6d8ea788d83"
      },
      "source": [
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(783, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
              "      <td>‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üôè', 'üòÇ', 'üëç']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
              "      <td>‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
              "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üëá', 'üòÇ', 'üòÇ', 'üòÇ', 'üòÇ']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡•á...</td>\n",
              "      <td>‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@BasudebaTripat4: @Rajanspsingh1 ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§∏‡§æ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@BasudebaTripat4:', '@Rajanspsingh1']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§∏‡§æ‡§≤‡•á ‡§ï‡§æ ‡§∏‡§∞ ‡§´‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ,, ‡§ó‡§∞‡•ç‡§¶‡§® ‡§§‡•ã‡§°‡§º...</td>\n",
              "      <td>‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§æ‡§≤‡•á ‡§∏‡§∞ ‡§´‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ,, ‡§ó‡§∞‡•ç‡§¶‡§® ‡§§‡•ã‡§°‡§º ‡§¶‡•á‡§§‡•á ‡§Ö‡§ö‡•ç‡§õ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          ‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...  ...  ‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...\n",
              "3          ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...  ...  ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...\n",
              "4          ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...  ...  ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§\n",
              "5          RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...  ...  ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...\n",
              "8          @BasudebaTripat4: @Rajanspsingh1 ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§∏‡§æ...  ...  ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§æ‡§≤‡•á ‡§∏‡§∞ ‡§´‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ,, ‡§ó‡§∞‡•ç‡§¶‡§® ‡§§‡•ã‡§°‡§º ‡§¶‡•á‡§§‡•á ‡§Ö‡§ö‡•ç‡§õ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hMC_GwsU8-Sm",
        "outputId": "ddc684d7-473a-4f64-a2e5-56884aa7c54c"
      },
      "source": [
        "print(train_val_data.shape)\n",
        "train_val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3054, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üôè', 'üôè']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
              "      <td>‡§ö‡•Ä‡§® UN ‡§§‡§∞‡•ç‡§ï ‡§≠‡§æ‡§∞‡§§ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§Ö‡§ú‡§∞‚Äå ‡§Æ‡§∏‡•Å‡§¶ ‡§Ü‡§§‡§Ç‡§ï‡•Ä ‡§Æ‡§æ‡§®‡§§‡§æ ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['ü§î']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ñ‡§°‡•Ä ‡§π‡•à,\\n\\...</td>\n",
              "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ñ‡§°‡•Ä ‡§π‡•à, ‡§∏‡§Ø‡§æ‡§®‡•á ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§™‡§°‡•á ‡§π‡•à? ‡§¨‡•ã...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•ã...</td>\n",
              "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§´‡§∞‡•ç‡§ï‡§º ‡§™‡§°‡§º‡§§‡§æ! ‡§Ö‡§Æ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Post  ... Unnamed: 13\n",
              "0   ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
              "3   @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
              "5   ‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...  ...         NaN\n",
              "10  RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...  ...         NaN\n",
              "11  RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTg69u-b4wDw"
      },
      "source": [
        "**Transforming the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPoz0-5P4IsD"
      },
      "source": [
        "labels_set = {'defamation',\n",
        " 'fake',\n",
        " 'hate',\n",
        " 'non-hostile',\n",
        " 'offensive'}\n",
        "\n",
        "labels_mapping = {'defamation':0,\n",
        " 'fake':1,\n",
        " 'hate':2,\n",
        " 'non-hostile':3,\n",
        " 'offensive':4}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1OzBY4MKF"
      },
      "source": [
        "train_y = np.empty((0, 5))\n",
        "for index, row in train_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_y = np.vstack((train_y, y))\n",
        "\n",
        "\n",
        "val_y = np.empty((0, 5))\n",
        "for index, row in val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  val_y = np.vstack((val_y, y))\n",
        "\n",
        "train_val_y = np.empty((0, 5))\n",
        "for index, row in train_val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_val_y = np.vstack((train_val_y, y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBa01jcE4NWo",
        "outputId": "1386235d-2489-44a8-c695-3a45ecb7b1b1"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(train_val_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 5)\n",
            "(379, 5)\n",
            "(3054, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCtXMKS64VT"
      },
      "source": [
        "**Modelling Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AzCgmM40un"
      },
      "source": [
        "def X_process(sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FZSOIJ5Ua2"
      },
      "source": [
        "def train_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    return train_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AFD9Fs5aOw"
      },
      "source": [
        "def val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return validation_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fjVV8d5a5f"
      },
      "source": [
        "def test_load(input_ids, attention_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMF_Pg-9XYn"
      },
      "source": [
        "def train_val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_validation_dataloader = DataLoader(\n",
        "                train_val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return train_validation_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBErql77BAv"
      },
      "source": [
        "def train_fn(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask,\n",
        "                                       labels=b_labels)\n",
        "                loss = state.loss\n",
        "                logits = state.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17SD78fGdXtx"
      },
      "source": [
        "def train_fn_test(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask)\n",
        "                logits = state.logits\n",
        "\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBONPGg77Clo"
      },
      "source": [
        "def stats(training_stats):\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    return df_stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhcuXIG7Dpk"
      },
      "source": [
        "def plot_stats(df_stats):\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evcCcgjA7FTu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MSQH9l7GSm"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHqtP0nElkb"
      },
      "source": [
        "def evaluation(y_true, y_pred):\n",
        "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEu7-vTNxst"
      },
      "source": [
        "**Training for Fake Class (Using Train Data and Val Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxBtbX61Nxsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc38e77-0072-49cc-b78e-fa2f57646ba7"
      },
      "source": [
        "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
        "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(26)\n",
        "np.random.seed(26)\n",
        "torch.manual_seed(26)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device) # Send the model to the GPU if we have one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UumXdB9Nxsx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Nr_05qNxsy"
      },
      "source": [
        "**TODO: Tryout different batchsize and length (80, 100)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2RNGhpNxsy"
      },
      "source": [
        "batch_size = 4\n",
        "max_length = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPL2bLLvOWzr"
      },
      "source": [
        "# train_sentences = train_data['Filtered_Post'].values\n",
        "# val_sentences = val_data['Filtered_Post'].values\n",
        "# test_sentences = test_data['Filtered_Post'].values\n",
        "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
        "\n",
        "train_sentences = train_data['Post'].values\n",
        "val_sentences = val_data['Post'].values\n",
        "test_sentences = test_data['Post'].values\n",
        "train_val_sentences = train_val_data['Post'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbgOIjuQffx"
      },
      "source": [
        "y_train_fake = train_y[:,1].astype(int)\n",
        "y_val_fake = val_y[:,1].astype(int)\n",
        "y_train_val_fake = train_val_y[:,1].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzuEr8LedH7Y"
      },
      "source": [
        "train_labels_fake = y_train_fake\n",
        "val_labels_fake = y_val_fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8t3Bc3Nxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46181d4-adc8-46fd-bc0c-24869877a0a5"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_sentences)\n",
        "train_dataloader = train_load(input_ids, attention_masks, train_labels_fake)\n",
        "\n",
        "input_ids, attention_masks = X_process(val_sentences)\n",
        "validation_dataloader = val_load(input_ids, attention_masks, val_labels_fake)\n",
        "\n",
        "input_ids, attention_masks = X_process(test_sentences)\n",
        "test_dataloader = test_load(input_ids, attention_masks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2p6AI3Nxsy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JzyqSFNxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db15b5db-328b-42a1-fc79-931fe104d229"
      },
      "source": [
        "training_stats, y_pred_val_fake = train_fn(train_dataloader, validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    670.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    670.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    670.    Elapsed: 0:00:32.\n",
            "  Batch   160  of    670.    Elapsed: 0:00:43.\n",
            "  Batch   200  of    670.    Elapsed: 0:00:53.\n",
            "  Batch   240  of    670.    Elapsed: 0:01:04.\n",
            "  Batch   280  of    670.    Elapsed: 0:01:14.\n",
            "  Batch   320  of    670.    Elapsed: 0:01:25.\n",
            "  Batch   360  of    670.    Elapsed: 0:01:35.\n",
            "  Batch   400  of    670.    Elapsed: 0:01:46.\n",
            "  Batch   440  of    670.    Elapsed: 0:01:56.\n",
            "  Batch   480  of    670.    Elapsed: 0:02:07.\n",
            "  Batch   520  of    670.    Elapsed: 0:02:17.\n",
            "  Batch   560  of    670.    Elapsed: 0:02:28.\n",
            "  Batch   600  of    670.    Elapsed: 0:02:38.\n",
            "  Batch   640  of    670.    Elapsed: 0:02:49.\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Training epcoh took: 0:02:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.580888066368539, 'Valid. Loss': 0.4267104253761078, 'Valid. Accur.': 0.8342105263157895, 'Training Time': '0:02:57', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    670.    Elapsed: 0:00:11.\n",
            "  Batch    80  of    670.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    670.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    670.    Elapsed: 0:00:42.\n",
            "  Batch   200  of    670.    Elapsed: 0:00:52.\n",
            "  Batch   240  of    670.    Elapsed: 0:01:03.\n",
            "  Batch   280  of    670.    Elapsed: 0:01:13.\n",
            "  Batch   320  of    670.    Elapsed: 0:01:24.\n",
            "  Batch   360  of    670.    Elapsed: 0:01:34.\n",
            "  Batch   400  of    670.    Elapsed: 0:01:44.\n",
            "  Batch   440  of    670.    Elapsed: 0:01:55.\n",
            "  Batch   480  of    670.    Elapsed: 0:02:05.\n",
            "  Batch   520  of    670.    Elapsed: 0:02:16.\n",
            "  Batch   560  of    670.    Elapsed: 0:02:26.\n",
            "  Batch   600  of    670.    Elapsed: 0:02:37.\n",
            "  Batch   640  of    670.    Elapsed: 0:02:47.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:02:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.53\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.580888066368539, 'Valid. Loss': 0.4267104253761078, 'Valid. Accur.': 0.8342105263157895, 'Training Time': '0:02:57', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.4951798197987086, 'Valid. Loss': 0.5337284478898111, 'Valid. Accur.': 0.8631578947368421, 'Training Time': '0:02:55', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    670.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    670.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    670.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    670.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    670.    Elapsed: 0:00:52.\n",
            "  Batch   240  of    670.    Elapsed: 0:01:02.\n",
            "  Batch   280  of    670.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    670.    Elapsed: 0:01:23.\n",
            "  Batch   360  of    670.    Elapsed: 0:01:33.\n",
            "  Batch   400  of    670.    Elapsed: 0:01:43.\n",
            "  Batch   440  of    670.    Elapsed: 0:01:53.\n",
            "  Batch   480  of    670.    Elapsed: 0:02:04.\n",
            "  Batch   520  of    670.    Elapsed: 0:02:14.\n",
            "  Batch   560  of    670.    Elapsed: 0:02:24.\n",
            "  Batch   600  of    670.    Elapsed: 0:02:35.\n",
            "  Batch   640  of    670.    Elapsed: 0:02:45.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:02:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.580888066368539, 'Valid. Loss': 0.4267104253761078, 'Valid. Accur.': 0.8342105263157895, 'Training Time': '0:02:57', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.4951798197987086, 'Valid. Loss': 0.5337284478898111, 'Valid. Accur.': 0.8631578947368421, 'Training Time': '0:02:55', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.38288733729529684, 'Valid. Loss': 0.6854262132197618, 'Valid. Accur.': 0.85, 'Training Time': '0:02:53', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    670.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    670.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    670.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    670.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    670.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    670.    Elapsed: 0:01:02.\n",
            "  Batch   280  of    670.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    670.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    670.    Elapsed: 0:01:33.\n",
            "  Batch   400  of    670.    Elapsed: 0:01:43.\n",
            "  Batch   440  of    670.    Elapsed: 0:01:53.\n",
            "  Batch   480  of    670.    Elapsed: 0:02:04.\n",
            "  Batch   520  of    670.    Elapsed: 0:02:14.\n",
            "  Batch   560  of    670.    Elapsed: 0:02:24.\n",
            "  Batch   600  of    670.    Elapsed: 0:02:35.\n",
            "  Batch   640  of    670.    Elapsed: 0:02:45.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:02:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.75\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.580888066368539, 'Valid. Loss': 0.4267104253761078, 'Valid. Accur.': 0.8342105263157895, 'Training Time': '0:02:57', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.4951798197987086, 'Valid. Loss': 0.5337284478898111, 'Valid. Accur.': 0.8631578947368421, 'Training Time': '0:02:55', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.38288733729529684, 'Valid. Loss': 0.6854262132197618, 'Valid. Accur.': 0.85, 'Training Time': '0:02:53', 'Validation Time': '0:00:07'}, {'epoch': 4, 'Training Loss': 0.2763411876926226, 'Valid. Loss': 0.7515081385800026, 'Valid. Accur.': 0.8447368421052631, 'Training Time': '0:02:52', 'Validation Time': '0:00:07'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoV30azNxsz"
      },
      "source": [
        "**Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvWJNE7YNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "79f53277-9d1a-4cb3-f7d3-f179758d74cd"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd2BT9fo/8HdGk46kbbpL0xYodFJKQRkCMgtlI1u44Fa8gl68DrjqvY4vXi+ioKLcn+h1IIJMARkChTIUQfZoWUW6F11JupI05/dH2khogRTapuP9+st+zsiTYw998snzeY5IEAQBRERERERkN2J7B0BERERE1NYxKSciIiIisjMm5UREREREdsaknIiIiIjIzpiUExERERHZGZNyIiIiIiI7Y1JORK1WRkYGwsLC8Mknn9z1OebPn4+wsLAGjKr1utX1DgsLw/z58206xyeffIKwsDBkZGQ0eHwbN25EWFgYjhw50uDnJiK6V1J7B0BEbUd9ktuEhASo1epGjKblKSsrw3//+19s374deXl58PDwQI8ePfDXv/4VISEhNp3j+eefx88//4wff/wRERERde4jCAKGDBkCjUaDQ4cOwdHRsSHfRqM6cuQIjh49ikceeQSurq72DqeWjIwMDBkyBDNmzMA///lPe4dDRM0Ik3IiajKLFi2y+vn48eP44YcfMHXqVPTo0cNqm4eHxz2/XkBAAM6cOQOJRHLX53jnnXfw1ltv3XMsDeH111/Htm3bMHr0aPTs2RP5+fnYu3cvTp8+bXNSPmnSJPz888/YsGEDXn/99Tr3+e2335CZmYmpU6c2SEJ+5swZiMVN88Xs0aNHsWzZMjz00EO1kvJx48Zh1KhRcHBwaJJYiIjqg0k5ETWZcePGWf1cVVWFH374Ad26dau17WY6nQ4KhaJerycSiSCXy+sd542aSwJXXl6OnTt3ol+/fvjggw8s43PmzIFer7f5PP369YO/vz+2bt2KV155BTKZrNY+GzduBGBO4BvCvf4/aCgSieSePqARETUm1pQTUbMzePBgzJw5E0lJSXjiiSfQo0cPjB07FoA5OV+yZAkmT56MXr16oUuXLoiLi8PixYtRXl5udZ66apxvHNu3bx8mTpyI6Oho9OvXD//5z39gNBqtzlFXTXnNmFarxb/+9S/06dMH0dHRmDZtGk6fPl3r/RQVFWHBggXo1asXYmNjMWvWLCQlJWHmzJkYPHiwTddEJBJBJBLV+SGhrsT6VsRiMR566CEUFxdj7969tbbrdDrs2rULoaGh6Nq1a72u963UVVNuMpnw//7f/8PgwYMRHR2N0aNHY8uWLXUen5KSgjfffBOjRo1CbGwsYmJiMGHCBKxbt85qv/nz52PZsmUAgCFDhiAsLMzq//+tasoLCwvx1ltvYcCAAejSpQsGDBiAt956C0VFRVb71Rx/+PBhfPnllxg6dCi6dOmC4cOHY9OmTTZdi/q4cOECnnvuOfTq1QvR0dEYOXIkVqxYgaqqKqv9srOzsWDBAgwaNAhdunRBnz59MG3aNKuYTCYTvv76a4wZMwaxsbHo3r07hg8fjn/84x8wGAwNHjsR1R9nyomoWcrKysIjjzyC+Ph4DBs2DGVlZQCA3NxcrF+/HsOGDcPo0aMhlUpx9OhRfPHFF0hOTsaXX35p0/n379+P77//HtOmTcPEiRORkJCA//3vf3Bzc8Ps2bNtOscTTzwBDw8PPPfccyguLsZXX32Fp59+GgkJCZZZfb1ej8ceewzJycmYMGECoqOjcfHiRTz22GNwc3Oz+Xo4Ojpi/Pjx2LBhA3766SeMHj3a5mNvNmHCBCxfvhwbN25EfHy81bZt27ahoqICEydOBNBw1/tm//73v/Htt9/i/vvvx6OPPoqCggK8/fbbCAwMrLXv0aNHcezYMQwcOBBqtdryrcHrr7+OwsJCPPPMMwCAqVOnQqfTYffu3ViwYAFUKhWA269l0Gq1ePjhh5GamoqJEyciMjISycnJWL16NX777TesW7eu1jc0S5YsQUVFBaZOnQqZTIbVq1dj/vz5CAoKqlWGdbfOnj2LmTNnQiqVYsaMGfDy8sK+ffuwePFiXLhwwfJtidFoxGOPPYbc3FxMnz4d7du3h06nw8WLF3Hs2DE89NBDAIDly5fj448/xqBBgzBt2jRIJBJkZGRg79690Ov1zeYbIaI2TSAispMNGzYIoaGhwoYNG6zGBw0aJISGhgpr166tdUxlZaWg1+trjS9ZskQIDQ0VTp8+bRlLT08XQkNDhY8//rjWWExMjJCenm4ZN5lMwqhRo4S+fftanffVV18VQkND6xz717/+ZTW+fft2ITQ0VFi9erVl7LvvvhNCQ0OFzz77zGrfmvFBgwbVei910Wq1wlNPPSV06dJFiIyMFLZt22bTcbcya9YsISIiQsjNzbUanzJlihAVFSUUFBQIgnDv11sQBCE0NFR49dVXLT+npKQIYWFhwqxZswSj0WgZP3funBAWFiaEhoZa/b8pLS2t9fpVVVXCX/7yF6F79+5W8X388ce1jq9R8/v222+/WcY+/PBDITQ0VPjuu++s9q35/7NkyZJax48bN06orKy0jOfk5AhRUVHCvHnzar3mzWqu0VtvvXXb/aZOnSpEREQIycnJljGTySQ8//zzQmhoqPDrr78KgiAIycnJQmhoqPD555/f9nzjx48XRowYccf4iMh+WL5CRM2Su7s7JkyYUGtcJpNZZvWMRiNKSkpQWFiIBx54AADqLB+py5AhQ6y6u4hEIvTq1Qv5+fkoLS216RyPPvqo1c+9e/cGAKSmplrG9u3bB4lEglmzZlntO3nyZCiVSptex2Qy4YUXXsCFCxewY8cOPPjgg3jppZewdetWq/3eeOMNREVF2VRjPmnSJFRVVeHHH3+0jKWkpODUqVMYPHiwZaFtQ13vGyUkJEAQBDz22GNWNd5RUVHo27dvrf2dnZ0t/11ZWYmioiIUFxejb9++0Ol0uHr1ar1jqLF79254eHhg6tSpVuNTp06Fh4cH9uzZU+uY6dOnW5UM+fr6okOHDrh27dpdx3GjgoICnDx5EoMHD0Z4eLhlXCQS4dlnn7XEDcDyO3TkyBEUFBTc8pwKhQK5ubk4duxYg8RIRA2P5StE1CwFBgbeclHeqlWrsGbNGly5cgUmk8lqW0lJic3nv5m7uzsAoLi4GC4uLvU+R025RHFxsWUsIyMDPj4+tc4nk8mgVquh0Wju+DoJCQk4dOgQ3n//fajVanz00UeYM2cOXnnlFRiNRkuJwsWLFxEdHW1TjfmwYcPg6uqKjRs34umnnwYAbNiwAQAspSs1GuJ63yg9PR0A0LFjx1rbQkJCcOjQIaux0tJSLFu2DDt27EB2dnatY2y5hreSkZGBLl26QCq1/nMolUrRvn17JCUl1TrmVr87mZmZdx3HzTEBQKdOnWpt69ixI8RiseUaBgQEYPbs2fj888/Rr18/REREoHfv3oiPj0fXrl0tx7344ot47rnnMGPGDPj4+KBnz54YOHAghg8fXq81CUTUeJiUE1Gz5OTkVOf4V199hffeew/9+vXDrFmz4OPjAwcHB+Tm5mL+/PkQBMGm89+uC8e9nsPW421VszDx/vvvB2BO6JctW4Znn30WCxYsgNFoRHh4OE6fPo2FCxfadE65XI7Ro0fj+++/x4kTJxATE4MtW7bAz88P/fv3t+zXUNf7Xvz9739HYmIipkyZgvvvvx/u7u6QSCTYv38/vv7661ofFBpbU7V3tNW8efMwadIkJCYm4tixY1i/fj2+/PJLPPnkk3j55ZcBALGxsdi9ezcOHTqEI0eO4MiRI/jpp5+wfPlyfP/995YPpERkP0zKiahF2bx5MwICArBixQqr5OjAgQN2jOrWAgICcPjwYZSWllrNlhsMBmRkZNj0gJua95mZmQl/f38A5sT8s88+w+zZs/HGG28gICAAoaGhGD9+vM2xTZo0Cd9//z02btyIkpIS5OfnY/bs2VbXtTGud81M89WrVxEUFGS1LSUlxepnjUaDxMREjBs3Dm+//bbVtl9//bXWuUUiUb1j+eOPP2A0Gq1my41GI65du1bnrHhjqymrunLlSq1tV69ehclkqhVXYGAgZs6ciZkzZ6KyshJPPPEEvvjiCzz++OPw9PQEALi4uGD48OEYPnw4APM3IG+//TbWr1+PJ598spHfFRHdSfP6uE9EdAdisRgikchqhtZoNGLFihV2jOrWBg8ejKqqKnz77bdW42vXroVWq7XpHAMGDABg7vpxY724XC7Hhx9+CFdXV2RkZGD48OG1yjBuJyoqChEREdi+fTtWrVoFkUhUqzd5Y1zvwYMHQyQS4auvvrJq73f+/PlaiXbNB4GbZ+Tz8vJqtUQE/qw/t7WsZujQoSgsLKx1rrVr16KwsBBDhw616TwNydPTE7Gxsdi3bx8uXbpkGRcEAZ9//jkAIC4uDoC5e8zNLQ3lcrmlNKjmOhQWFtZ6naioKKt9iMi+OFNORC1KfHw8PvjgAzz11FOIi4uDTqfDTz/9VK9ktClNnjwZa9aswdKlS5GWlmZpibhz504EBwfX6otel759+2LSpElYv349Ro0ahXHjxsHPzw/p6enYvHkzAHOC9emnnyIkJAQjRoywOb5JkybhnXfewcGDB9GzZ89aM7CNcb1DQkIwY8YMfPfdd3jkkUcwbNgwFBQUYNWqVQgPD7eq41YoFOjbty+2bNkCR0dHREdHIzMzEz/88APUarVV/T4AxMTEAAAWL16MMWPGQC6Xo3PnzggNDa0zlieffBI7d+7E22+/jaSkJERERCA5ORnr169Hhw4dGm0G+dy5c/jss89qjUulUjz99NN47bXXMHPmTMyYMQPTp0+Ht7c39u3bh0OHDmH06NHo06cPAHNp0xtvvIFhw4ahQ4cOcHFxwblz57B+/XrExMRYkvORI0eiW7du6Nq1K3x8fJCfn4+1a9fCwcEBo0aNapT3SET10zz/ihER3cITTzwBQRCwfv16LFy4EN7e3hgxYgQmTpyIkSNH2ju8WmQyGb755hssWrQICQkJ2LFjB7p27Yqvv/4ar732GioqKmw6z8KFC9GzZ0+sWbMGX375JQwGAwICAhAfH4/HH38cMpkMU6dOxcsvvwylUol+/frZdN4xY8Zg0aJFqKysrLXAE2i86/3aa6/By8sLa9euxaJFi9C+fXv885//RGpqaq3Fle+//z4++OAD7N27F5s2bUL79u0xb948SKVSLFiwwGrfHj164KWXXsKaNWvwxhtvwGg0Ys6cObdMypVKJVavXo2PP/4Ye/fuxcaNG+Hp6Ylp06Zh7ty59X6KrK1Onz5dZ+camUyGp59+GtHR0VizZg0+/vhjrF69GmVlZQgMDMRLL72Exx9/3LJ/WFgY4uLicPToUWzduhUmkwn+/v545plnrPZ7/PHHsX//fqxcuRJarRaenp6IiYnBM888Y9XhhYjsRyQ0xSodIiKyUlVVhd69e6Nr1653/QAeIiJqPVhTTkTUyOqaDV+zZg00Gk2dfbmJiKjtYfkKEVEje/3116HX6xEbGwuZTIaTJ0/ip59+QnBwMKZMmWLv8IiIqBlg+QoRUSP78ccfsWrVKly7dg1lZWXw9PTEgAED8MILL8DLy8ve4RERUTPApJyIiIiIyM5YU05EREREZGdMyomIiIiI7IwLPasVFZXCZGraSh5PTwUKCnRN+ppELRHvFSLb8F4hso297hWxWASVyqXObUzKq5lMQpMn5TWvS0R3xnuFyDa8V4hs09zuFZavEBERERHZGZNyIiIiIiI7Y1JORERERGRnTMqJiIiIiOyMSTkRERERkZ2x+4qNjEYDSks1qKwsh8lU1SDnzMsTw2QyNci5qHmQSBygULjByanudkdEREREdWFSbgOj0YDCwlw4Oyvh4eEHiUQCkUh0z+eVSsUwGpmUtxaCIMBgqERx8XVIpQ5wcJDZOyQiIiJqIVi+YoPSUg2cnZVQKNwglUobJCGn1kckEkEmc4SLixt0umJ7h0NEREQtCJNyG1RWlsPRkeUIZBtHRycYDHp7h0FEREQtCMtXbGAyVUEikdg7DGohxGJJg607ICIiooZzNOcEtqTsRHFlMdzl7hgbEo+eft3tHRYAJuU2Y8kK2Yq/K0RERM3P0ZwT+P7CBhhMBgBAUWUxvr+wAQCaRWLO8hUiIiIiatVKDWXYePknS0Jew2AyYEvKTjtFZY0z5dSo5sx5GgCwbNnnTXosERERtU3lxnKkazORqslAmjYDaZoMXK8ovOX+RZXNozkDk/I2ql+/+2zab926LfD3b9fI0RARERHVX4WxEhm6LKRp0pGqNSfheWXXLds9HT0Q5KpGv4DeSEg7AK1BV+scKrl7U4Z8S0zK26g33njb6ue1a1cjNzcbc+e+aDXu7q66p9dZsuRTuxxLRERErYu+So8MXTbSqmfAU7UZyC3NgwABgDm5DnJVo5fffQhWqhHoGgCFw5/d89zkrlY15QDgIHbA2JD4Jn8vdWFS3kYNHz7S6ufExASUlBTXGr9ZRUUFHB0dbX4dBweHu4rvXo8lIiKilstgMiJLl/1nCYo2A9mluTAJ5ocuusqUCHZVo4dPVwQp1QhyVcNVprztOWsWc7L7CrU4c+Y8DZ1Oh1de+Qc++WQJLl68gBkzZuGJJ57BwYOJ2LJlEy5dugiNpgTe3j4YOXIMZs58zKp95M114SdOHMPzz8/GwoWL8McfV/Hjjxug0ZQgOjoGL7/8D6jVgQ1yLABs2LAWa9asQkHBdYSEhGDOnHlYsWK51TmJiIjIvqpMVcgqzUGaJsNSgpKly0GVYG4vrHBwQZBSjWivSAQp1Qh2VcNN5npX3c56+nVHT7/u8PZWIj9f29Bv5Z4wKbeTw+dzsPHAVRSUVMDTVY4JA0LQJ8rP3mHVUlxchFdemYdhw+IRHz8Kvr7mGLdv/wlOTs6YOnUGnJ2dcPz4MXzxxX9RWlqK55574Y7n/eabLyEWSzB9+ixotRqsXr0Sb731Olas+KZBjt20aT2WLFmEbt26Y+rUh5GdnY0FC16CUqmEt7fP3V8QIiIiumtVpirklOVZlaBk6rJhNBkBAE5SJwQr1RgS9KB5Blyphoeje5toN8yk3A4On8/BNzsuQG80fwVToKnENzsuAECzS8yvX8/H/PlvYPTocVbjb775f5DL/yxjGT9+Et5//11s2rQOTz31LGQy2W3PazQa8b//fQOp1Pwr6Orqho8+WoyrV6+gY8dO93SswWDAF18sR1RUNJYu/cyyX6dOnbFw4ZtMyomIiJqASTAhryzfqgQlXZtlqel2lMgRqAzAAPUDCFaqEaQMhJeTR5tIwOvCpPwe/HI2G4fOZNf7uJSsEhirBKsxvdGEr7Yn48CprHqfr19Xf/SN9q/3cbZwdHREfPyoWuM3JuRlZaXQ6w2IiYnF5s0bkZp6DZ07h972vKNGjbUkywAQE9MNAJCVlXnHpPxOx164kISSkhL89a8PWe0XFxePjz/+8LbnJiIiovoTBAH55QWWFoSp2nSkazNRWaUHAMjEDghUBqBfQC9zCYpSDW9nL4hFfGRODSbldnBzQn6ncXvy9vaxSmxrXL2aghUrluPEid9RWlpqta20tHa7oZvVlMHUUCpdAQBa7Z3ru+50bE6O+YPSzTXmUqkU/v6N8+GFiIiorRAEAYUVReb67xtmwcuNFQAAB7EUakU79Pa/z1KC4ufiwwT8DpiU34O+0Xc3Q/3yZ7+gQFNZa9zTVY5XZzSPFcA1bpwRr6HVajF37tNwdlbgiSdmIyBADZlMhkuXLmD58k9gMpnueF6xWFLnuCDc+YPJvRxLREREthMEAcWVJTfMgJsT8FJDGQBAIpIgQOGPHr7dqktQ1PB38YXkFn+r6daYlNvBhAEhVjXlACCTijFhQIgdo7LdyZPHUVJSgoUL30e3bn9+iMjOrn/pTWPw8zN/UMrISEdMTKxl3Gg0Ijs7GyEhty+PISIiaqtKKrVI06ZbLcTU6s3fgItFYrRz8UOMVxcEuZpLUPwVfnAQM51sCLyKdlCzmLMldF+pi1hs/vrpxplpg8GATZvW2SskK+HhkXBzc8OWLZswfPhIS/nN7t07odVq7BwdERFR86DV65CmzbQqQSmuLAEAiCCCv4svojzCEeRqngEPUPhDJuEzRBoLk3I76RPlh/4x7WA03rnUo7mJju4KpdIVCxe+iUmTpkIkEuHnn7ejuVSPODg44PHHn8aSJe/jb3/7KwYNGoLs7Gzs2LEVAQHqNruqm4iI2q4yQ5klAa8pQSmsKLJs93X2Rmf3jpYEPFAZALnk9p3UqGExKad6c3Nzx6JFS7Bs2VKsWLEcSqUrhg0bgfvu64kXX5xj7/AAABMnToUgCFizZhU+/fQjhIR0xnvvfYilSxdDJpPbOzwiIqJGU26sQLo206oO/Hp5gWW7l5MnOrgGYYD6AUsC7iS1/Wnd1DhEAlfHAQAKCnQwmeq+FDk5qfDzC27w15RKxS1yprylMplMGD06DgMGDMKrr77eqK/VWL8zbVVzfPIaUXPEe6XtqazSWyXgadoM5JblW7Z7OKosLQiDXM0JuIuDsx0jbh7sda+IxSJ4eirq3MaZcmqVKisrIZdbz4jv3LkNGk0JYmN72CkqIiKiu6evMiBTl2XVijCnNA8CzJOK7nI3BCnVuN+3e3UZSgCUsroTQGp+mJRTq3TmzCksX/4JBg4cDFdXN1y6dAHbtm1Bx44hGDRoqL3DIyIiui2DyYgsXbZVCUp2aS5MgvkbdqWDAsGuasR6R1vqwN3krnaOmu4Fk3Jqldq1C4CXlzfWr/8BGk0JXF3dEB8/CrNnz4GDA1eOExFR81FlqkJ2aa6lBWGaJgNZumwYhSoAgIuDM4KUakR7RlgScHe5GxsXtDJMyqlVCghQY9GiJfYOg4iIyIpJMCGnNM/SgjBNk4EMXRYMJiMAwEnqiCClGoMC+1t6gXs4qpiAtwFMyomIiIgagUkwIb/suqUFYZomA+naTOhNBgCAXCJDoDIA/QP6INg1EEFKNbycPPg4+jaKSTkRERHRPRIEAdfLC5GmTbeUoKRrM1FRVQkAcBA7IFDZDg+062nuhuKqho+zNxNwsmBSTkRERFQPgiCgsKLYqgQlVZuBcmM5AEAqkiBA2Q49/bojqLoVoZ+zDyRiiZ0jp+aMSTkRERHRLQiCgBK9BqmaDKte4DpDKQBALBIjQOGP7j5dLb3A/V18IRUzxaL64W8MERERUTWNXvvno+irE3CN3vyQGbFIDH8XX0R7RVpKUNq5+MFBwq5edO+YlBMREVGbpNOX1ipBKa4sAQCIIIKviw8iPEItJShqhT9kEpmdo6bWikk5ERERtXplhnLL4+hTNelI02agoKLIst3H2Qud3DtUl6AEQq3wh6PU0Y4RU1tj16Rcr9fjo48+wubNm6HRaBAeHo558+ahT58+tz1u8ODByMzMrHNbcHAwdu3a1Rjh0m1s374V7777Ftat2wJ//3YAgEmTxiA2tgdee+3Neh97r06cOIbnn5+Njz/+L7p3v69BzklERC1DhbEC6dosq1nwvPLrlu1ejh4Idg2sbkWoRqAyAE5SJztGTGTnpHz+/PnYtWsXZs2aheDgYGzatAlPPfUUVq5cidjY2Fse949//AOlpaVWY1lZWVi6dCn69u3b2GG3Cq+8Mg8nTvyOrVt3w8mp7n+IXnxxDs6fP4stW3ZBLpc3cYS22bPnZxQWFmDKlOn2DoWIiOxAX6VHhi7LaiFmblk+BAgAAJXcHUGuavTyv8+SgCscXOwcNVFtdkvKz5w5g23btmHBggV49NFHAQDjx4/H6NGjsXjxYqxateqWxw4dOrTW2GeffQYAGDNmTKPE29rExQ3Hr78exKFD+xEXF19re1FRIY4f/x3Dho2464T8++83QCxu3P6rCQm7cPnypVpJebdu3ZGQ8AscHLj4hoiotTBUGZBZmm21EDO7NNeSgLvKlAh2VaOHb4ylDtxVprRz1ES2sVtSvnPnTjg4OGDy5MmWMblcjkmTJmHJkiXIy8uDj4+Pzef76aefoFar0b1798YIt9Xp338gnJycsWfPz3Um5Xv37kFVVRWGDau9zVYymf0Ww4jF4mY7u09ERHdmNBmRVZpj6YCSpslAZmkOTIIJAKBwcEGQqxox3lGWBNxd7mbnqInunt2S8uTkZHTo0AEuLtZfIXXt2hWCICA5OdnmpDwpKQkpKSmYPXt2Y4TaKjk6OqJ//wHYt28PNBoNXF1drbbv2fMzPD09ERgYjMWL38Px40eRm5sLR0dHdO9+H5577oU71n/XVVN+9WoKli59H+fOnYWbmxvGjZsALy/vWscePJiILVs24dKli9BoSuDt7YORI8dg5szHIJGYH74wZ87TOHXqBACgXz9z3bifnz/Wr996y5ryhIRd+O67r5Gaeg3Ozi7o27c/nn32ebi7u1v2mTPnaeh0Ovzzn2/jww8XITn5PJRKV0yePA0zZjxSvwtNRER3VGWqQk5ZnlUJSqYuC0ahCgDgLHVCkFKNoUEDLL3AVXJ3iEQiO0dO1HDslpTn5+fD19e31ri3tzlBy8vLs/lcW7duBQCMHTu2YYJrAkdzTmDr1Z0orCiGSu6OsSHx6OnXtLP8cXHx2LVrBxITEzB27EOW8ZycbJw7dwaTJk1DcvJ5nDt3BkOHDoe3tw+ys7Pw448bMHfuM/juu3VwdLR9ZXpBwXU8//xsmEwm/OUvj8DR0Qlbtmyqc0Z7+/af4OTkjKlTZ8DZ2QnHjx/DF1/8F6WlpXjuuRcAAI888jjKy8uRm5uNuXNfBAA4OTnf8vVrFpRGRUXj2WefR15eLjZs+AHJyeexYsW3VnFoNCX4+9+fx6BBQzBkyDDs27cHy5d/go4dO6FPH65bICK6WybBhNyyfKsSlAxdFgwmAwDAUeKIIGUABgb2s/QC93T0YAJOrZ7dkvKKioo6631rEqPKykqbzmMymbBt2zZERkYiJCTkruPx9FTccltenhhSacPVRh/JOo7VFzZAX/0PUFFlMVZf2ACJWIRe7Xo02OvcSZ8+favVpq4AACAASURBVKBSqZCQ8DMmTJhoGd+7dzcEQUB8/AiEhHRCXNwwq+MGDBiAJ598FAcP7sWIEaMBAGKx+R9LicT6WolEIsvPq1d/i5KSYnz11XcID48AAIwZMxaTJ4+rdew777xrlfBPmjQF//nPQmzatA7PPvscZDIZ+vR5AJs2rUdJSTFGjRptFaNEIrY6p9FowPLln6Bz51AsX77CUloTGRmJN95YgG3bNmPKlGmWmPPycvH22+9aynfGj38I48ePwvbtW9C/f/87XluxWAxvb9YxNiReTyLbNKd7xSSYkKPLx9XCVKQUpuFqUSquFqWj0mj+Gy+XytFRFYhhfg8ixCMIHT2C4afwhljUuOuRiIDmda8AdkzKHR0dYTAYao3XJOO21gMfPWouq6hZLHq3Cgp0MJmEOreZTCYYjaZa40eyj+Nw9u/1fq0/StJgFIxWY3qTAd+eX4eDGUfqfb4+/vejl//dJPNiDBo0FD/+uAE5OXnw8vICAOzatRNqdSDCwiIBwPLejUYjSkt18PNTQ6FQIjk5GXFxIwHAcu2qqqyvlSAIlp9/+eUQoqNj0KlTmGVMqXRDXNwIbNq0zupYqVRm+e+yslLo9QZER3fDpk0bkJJyFZ07h1rOf2OMNaqqTFbxnDt3HkVFhXjqqWchFkst+w8YMATe3j44dOggJkyYYjmnQqHAoEFxlv1EIgkiIiKRmZlR5+/CzUwmE/Lztbb8TyAbeHsreT2JbGDPe0UQBBRUFFl6gJtrwTNRUVUBAHAQS6FWBKC3332WEhRf55sS8AqgoKL0Fq9A1HDsda+IxaJbTgTbLSn39vaus0QlPz8fAGyuJ9+6dSvEYjFGjRrVoPE1ppsT8juNN6a4uHhs3LgOe/fuwpQp03Ht2h+4cuUSHnvsKQBAZWUFVq78Gtu3b0V+fp4lCQYAnU5Xr9fKzc1BdHRMrfGgoOBaY1evpmDFiuU4ceL3Wu0vS0vr97qAuSSnrtcSi8VQqwORm5ttNe7j41vrq1Kl0hUpKVfq/dpERK2NIAgoriyxehR9miYDpcYyAIBUJEGAoh3u94u1lKD4OftAIpbYOXKi5stuSXl4eDhWrlyJ0tJSq8Wep0+ftmy/E71ej127dqFnz5511qc3tl7+Pe5qhvr1X95FUWVxrXGV3B1/6960i1Wjo2Pg7x+A3bt3YsqU6di9eycAWDqyLFnyPrZv34rJkx9Gly7RUCgUAER4881/WCXoDUmr1WLu3Kfh7KzAE0/MRkCAGjKZDJcuXcDy5Z/AZLrzTPW9Et/iD0djvWciouaspFJT/STMPxNwrcE8QSIWidHOxQ8x3l0Q5KpGsFKNdgo/SMV8aDhRfdjtjomPj8f//vc/rFu3zlJ6otfrsXHjRnTv3t2SZGdlZaG8vLzOevH9+/dDo9G0uN7kY0Pi8f2FDZZFLQDgIHbA2JC7bz94L4YOHYaVK79CRkY6EhJ2ISwswjKjnJiYgPj4UZg7d55l/8rKynrPkgOAr68fMjLSa42npaVa/Xzy5HGUlJRg4cL30a3bn4tfs7Oz6jirbQt//Pz8La914zkFQUBGRjo6dLj79QhERK2JVq+zJN41M+Eleg0AQAQR/F18EeUZjiBXNYKUagQo/CGT8JkQRPfKbkl5TEwM4uPjsXjxYuTn5yMoKAibNm1CVlYW/v3vf1v2e/XVV3H06FFcvHix1jm2bt0KmUyG4cOHN2Xo96ymy4q9u6/UGDZsBFau/ArLli1BRka6VQJe14zxhg0/oKqqqt6v06dPX6xbtwYXL15AWJj5m5CioiLs3r3Dar+aBw7dOCttMBiwadO6Wud0cnKy6QNCeHgkVCoP/PjjeowYMdqyyHjfvgTk5+dhxoxZ9X4/REQtXamh7Ib6b/NMeM03uSKI4OPsjVBVJwRXJ+BqZTvIJfZ7BgVRa2bX75YWLVqEpUuXYvPmzSgpKUFYWBg+//xz9Ohx55IQnU6HxMREDBw4EEpl81o9a4ueft3xgPo+mxYNNrYOHTqiU6dQHDp0AGKxGEOG/Pkh54EH+uHnn7fDxUWB9u074Pz5szh27Cjc3Or/gIbp0x/Bzz9vx4svPodJk6ZBLnfEli2b4OvrD53usmW/6OiuUCpdsXDhm5g0aSpEIhF+/nk76qocCQsLx65dO/DJJx8iPDwSTk7O6NfvwVr7SaVSPPvsXLz77luYO/cZDB06DHl5uVi//gd07BiCMWMeqn1yIqIW4mjOCWxJ2YniymK432Kip9xYjnRtplUJyvWKQst2bydPdHQLRpBrXwQr1VArA+Aktb3tLRHdG7sm5XK5HK+++ipeffXVW+6zcuXKOscVCgXOnDnTWKG1OcOGxePKlUuIje1h6cICAC+88BLEYjF2796Byko9oqNjsHTpp3jxxbn1fg0vLy98/PH/w5Ili7By5ddWDw967713LPu5ublj0aIlWLZsKVasWA6l0hXDho3Afff1xIsvzrE657hxE3Hp0gVs3/4Tfvjhe/j5+deZlAPAyJFjIJPJsGrVN/j004/g4uKCuLh4zJ49l0//JKIW62jOCauSyKLKYnx/YQNyS/Ph4uBkLkHRZiCv7LrlGE9HFYKUavQN6GV+GqYyAM4Ot37OAxE1PpHAlWsAbt8SMScnFX5+tTuE3Ctz/2z7z5RTw2us35m2ii0RiW7tVs0DarjL3SwtCM0JuBoKmcst9ydqC9gSkYiIiBpMlanqtgn5u33fgJu85ZV4ErVFTMqJiIhamMoqPX7NOoqEtAO33Ecld2dCTtSCMCknIiJqIXT6UuzP+AX7M35FqbEMndw7oLtPVxzIPNxs2uwS0d1hUk5ERNTMFZQXYW/6AfyadRR6kwFdvaIQFzwQHd3Ma1fUynZ37L5CRM0bk3IiIqJmKlOXjd2p+3E87xQAoKdvdwwNHgB/F+unWPf0646eft25KJqoBWNSTkRE1MxcKf4Du1P34VzBBcgkMgxU98XgwP5QObrbOzQiaiRMyomIiJoBk2DC+YIL2JW6D1dLUqFwcMHoDsPwoPoBuLCHOFGrx6TcRoIgQCQS2TsMagHY+p+I6qPKVIXfc09id9p+5JTmwtNRhcmh4/CA//2Q8ZH2RG0Gk3IbSCQOMBgqIZPxccN0ZwaDHhIJby0iur0KYyV+zT6KvWkHUVRZjHYufng08mF09+kKiVhi7/CIqIkxc7CBQuGG4uLrcHFxg6OjE8RiCWfNqRZBEGAw6FFcnA+lUmXvcIiomdLpS5GY8QsO3NDW8OHwCYj0COPfFqI2jEm5DZycXCCVOkCnK0ZpaQlMpqoGOa9YLIbJZGqQc1HzIJFIoVSq4OTER1gTkbWC8iIkVLc1NNTR1pCI2jYm5TZycJBBpfJp0HOydRURUet3Y1tDEUS43y8WcUED4HdTW0MiatuYlBMRETUwQRCQUnKNbQ2JyGZMyomIiBqISTDh3PVk7EpNxB+amraGw/Ggug/bGhLRbTEpJyIiukdGkxHHck9ZtTWcEjoeffzvY1tDIrIJk3IiIqK7VNPWMCHtAIorSxCg8GdbQyK6K0zKiYiI6kmr12F/xi/Yn/Eryozl6OzeEdPDJ7KtIRHdNSblRERENiooL6xua/g7DCYDYqrbGnZgW0MiukdMyomIiO7A3NYwEcfzTrOtIRE1CiblREREdahpa7grdR/Os60hETUyJuVEREQ3MAkmnL2ejN1sa0hETYhJOREREcxtDX/PPYU9qYnIKctjW0MialJMyomIqE2rMFbi16wjSEg/aGlr+Fjkw4hlW0MiakJMyomIqE2qu63hJER6hLKtIRE1OSblRETUprCtIRE1R0zKiYioTbi5rWFPv+4YGjQAfi4+9g6NiIhJORERtV6CIOBK8R/YnZaI8wUXIJfIMEjdD4MC+7GtIRE1K0zKiYio1fmzreE+/KFJg8LBBWM6DseDAX3gzLaGRNQMMSknIqJWo662hlNDx6O3//2QSRzsHR4R0S0xKSciohaPbQ2JqKVjUk5ERC0W2xoSUWvBpJyIiFqc6+WFSEg7gMPZv8NoMqKrdxTiggaig1uQvUMjIrorTMqJiKjFyNRlY1fqPpzIO8O2hkTUqjApJyKiZq2mreGutH1IKrhoaWs4OKg/3OVu9g6PiKhBMCknIqJmydzWMAm7UxPZ1pCIWj0m5URE1KwYTUb8nnMSu9P2I7csD56OHmxrSEStHpNyIiJqFiqMFfgl6yj23tjWMGo6Yr2j2daQiFo9JuVERGRXWr0OidVtDcur2xrOCJ+ECLY1JKI2hEk5ERHZxZ9tDY/CaKpCjHcU4oIHor0r2xoSUdvDpJyIiJpUhjYLu9MSLW0Ne1W3NfRlW0MiasOYlBMRUaMztzW8il2piUgqrG5rGNgPgwPZ1pCICGBSTkREjaimreGu1ERc06RB6aDAmI7xeDCgN9saEhHdgEk5ERE1uJvbGno5emBq6EPo7X8f2xoSEdWBSTkRETWYCmMFDmUdwb70QyiuLIFa0Y5tDYmIbMCknIiI7plWr0Ni+iHszzyMcmM5Qt1D2NaQiKgemJQTEdFdM7c13I/D2b+zrSER0T1gUk5ERPXGtoZERA2LSTkREdlEEARcLr6K3WxrSETU4OyalOv1enz00UfYvHkzNBoNwsPDMW/ePPTp08em47du3YpvvvkGV65cgUwmQ2hoKF555RV07dq1kSMnImo7TIIJZ64nYTfbGhIRNRq7JuXz58/Hrl27MGvWLAQHB2PTpk146qmnsHLlSsTGxt722CVLluCLL77A2LFjMXXqVJSVleHChQvIz89vouiJiFo3o8mIozknsSctEbll+fBy9MC0sIfQy49tDYmIGppIEATBHi985swZTJ48GQsWLMCjjz4KAKisrMTo0aPh4+ODVatW3fLYEydOYPr06fjkk08QFxfXIPEUFOhgMjXtpfD2ViI/X9ukr0nUEvFeaVp1tTUcFjwQ3djWsNnjvUJkG3vdK2KxCJ6eijq32W2mfOfOnXBwcMDkyZMtY3K5HJMmTcKSJUuQl5cHH5+6Fwx9++23iI6ORlxcHEwmE8rLy+Hi4tJUoRMRtUp1tTX8S/hkhHt0ZltDIqJGZrekPDk5GR06dKiVTHft2hWCICA5OfmWSfnhw4cxatQofPjhh1i5ciXKysoQEBCAv/3tbxg7dmxThE9E1GpcLy/AnrQD+M3S1rALhgUPRLBroL1DIyJqM+yWlOfn58PX17fWuLe3NwAgLy+vzuNKSkpQXFyMbdu2QSKR4KWXXoK7uztWrVqFl19+GU5OTg1W0kJE1Jqla7OwO3UfTuSdgVgkRi+/Hhga9CDbGhIR2YHdkvKKigo4ONReKCSXywGY68vrUlZWBgAoLi7G2rVrERMTAwCIi4tDXFwcPv3007tKym9V39PYvL2VdnldopaG90rDEAQBSfmX8WPyzzidkwQnqSPGhA/FyNDB8HByt3d41AB4rxDZprndK3ZLyh0dHWEwGGqN1yTjNcn5zWrG1Wq1JSEHAJlMhuHDh+Pbb79FaWlpvWvMudCTqPnivXLvatoa7krdh1RNOpQOCoztGI/+AX3g7OCEKh2Qr+M1bul4rxDZhgs9b+Dt7V1niUpNS8Nb1ZO7u7tDJpPBy8ur1jYvLy8IggCdTseFn0REAAwmI37POYE9afvZ1pCIqBmzW1IeHh6OlStX1prVPn36tGV7XcRiMSIiIpCbm1trW05ODiQSCdzc+GQ5Imrbatoa7k07iBK9BoGKdng8ajrbGhIRNVNie71wfHw8DAYD1q1bZxnT6/XYuHEjunfvblkEmpWVhZSUlFrHZmdn45dffrGM6XQ67NixA7GxsXB0dGyaN0FE1Mxo9FpsSdmJ13/9NzZd2QZfFx/MiXkSr97/Anr4dmNCTkTUTNltpjwmJgbx8fFYvHgx8vPzERQUhE2bNiErKwv//ve/Lfu9+uqrOHr0KC5evGgZe/jhh7Fu3TrMnTsXjz76KFxdXbFhwwZotVq8+OKL9ng7RER2xbaGREQtm92ScgBYtGgRli5dis2bN6OkpARhYWH4/PPP0aNHj9se5+TkhG+//RaLFi3Cd999h4qKCkRFReGrr76647FERK3JjW0NJSIxevr1wNDgAfB19rZ3aEREVA8iQRCatuVIM8XuK0TNF+8Va4Ig4HJxCnalJiK58BIcJXL0C+iNQYH94C7nmpq2jPcKkW3YfYUAAIfP52Dj/hQUairh4SrHhAEh6BPlZ++wiKiZMwkmnMk/j11piea2hjLrtoZERNRyMSlvYofP5+CbHRegN5oAAAWaSnyz4wIAMDEnojrVtDXcnZaIvLLr8HLyxLSwCejt1wMObGtIRNQqMClvYhv3p1gS8hp6owkb96cwKSciK+XGCvxyY1tDZQAej5qBWJ9oiEV2a55FRESNgEl5EyvQVN5yPOlaITqr3eAgZcsyorZMo9ciMf0XHMj8FeXGCoSpOmFm5BSEqzpDJBLZOzwiImoETMqbmKer/JaJ+eI1p+AgFaNTgBsi26sQ2d4Dwb5KiMX8I0zUFtS0NTyc/TuqTFXo5t0FcWxrSETUJjApb2ITBoRY1ZQDgEwqxsNDO8NdIUfStSIkpxZiw/6r2LD/KpzlUoQHqxARrEJkexX8PJw5U0bUyqRrM7E7NdHS1rCXfw8MCWJbQyKitoRJeROrqRu/VfeVmE5eAICSUj2SUwvNSfq1Qpy4lA8AUCnliAxWIaK9ChHBHlAp5fZ5I0R0TwRBwKWiFOxO+7Ot4dCgARgU2A9ucld7h0dERE2MfcqrNec+5YIgIK+4HMnXipB0rRDJqUUorTACAPw9nRHZ3gORwSqEBang7MjPWdT6tKbey5a2hqmJSNWa2xoOVvdHv4DebGtI96w13StEjYl9yumuiEQi+Kqc4atyxsDYAJgEAem5OiRVz6QfPJ2FhOMZEImADv6uiKyeRe8U4AYHKTs0EDUHBpMRR3OOY0/afrY1JCKiWjhTXq05z5TficFoQkpmCZJSzaUuf2RrYRIEyKRidFa7IbK9ByLaqxDkw0Wj1DK15Nm/cmMFDmX+hn3pB1Gi1yJQGYC4oIFsa0iNoiXfK0RNiTPl1CgcpGKEB6sQHqwCHuyIsgojLqUXW0pd1iWmAABcHM2LRiODzZ1dfFROXDRK1Eg0ei32pR/CwczDlraGsyKnIUzVifcdERHVwqS8FXJ2lKJbZy9062xeNFqsq0Ry6p/16McvmheNerjKERlsnkWPDFbBTcFFo0T3Kr+sAHvS9+O37GNsa0hERDZjUt4GuCvk6BPlhz5RfhAEAblF5Ui+Zq5HP3k5H4fOZgMAArxcqhN0D4QFucNJzl8PIluxrSEREd0LZl1tjEgkgp+HM/w8nDGouxomk4DUXK1lJn3/qSzsOZYBsUiEDu2UiAz2QGR7FTq246JRopvVbmvoyLaGRER0V7jQs1pLXujZkAzGKlzJMC8aTbpWhGs5GggCIHMQI1Ttbl40GqxCoK8CYtbFUhNpbveKSTDhdP557ErdhzRthrmtYWB/9A/oDScp2xqS/TS3e4WoueJCT2r2HKQSRLT3QER7D0wcAJRVGHAhrdjcIz21EGv3XQEAKJwcblg0qoK3OxeNUutnaWuYuh955ea2hg+HTUAvtjUkIqJ7xKScbsvZ0QHdQ73RPdRcF1ukrfzzSaOpRTh2IQ8A4OnqaO6PXt0j3c1FZs+wiRpUXW0Nn+jyF3Tz7sK2hkRE1CCYlFO9qJRyPNDFHw908YcgCMgpLENS9ZNGj13Mx8Ez5kWjam8XS6lLaCAXjVLLVFKpRWLGn20Nw1Wd2daQiIgaBTMlumsikQj+ni7w93TBkB5qVJlMSM3RWWbS957IxK7f0yERi9ChnaulP3rHdq6QSji7SM1XXtl1JKTtx285x81tDX2iMSxoIIJc1fYOjYiIWiku9KzGhZ4NT2+owuXMEnM9+rVCpOZoIQCQO0gQGuhuLncJVkHtw0WjdHtNda+kaTOwOzURJ/POVrc1vA9Dgx6ED9saUgvR2v+uEDUULvSkNkXmIEFUew9EtfcAEILSCgMupBYjKbUQydeK8MPeAgCA0tkBEdWz6BHB5kWjRE1FEARcLLqC3amJuFB0mW0NiYjILpiUU5NxcXRAjzBv9AgzzzoWaios/dGTUotwNNm8aNTb3RER1f3Rw4NVcHXmolFqeCbBhFP557A7NRFp2gy4ypQYFzKCbQ2JiMgumJST3Xi4OqJvtD/6RpsXjWYVlFmeNPr7hVwcOJ0FAAjyUZifNNreA6Fqd8hlEjtHTi2ZwWTE0ezj2JNmbmvozbaGRETUDDApp2ZBJBIhwMsFAV4uGHpfIKpMJlzL1iIptQjJ1wqRcDwDPx81LxoNCXCzLBpt76/kolGySU1bw73pB6HRaxHEtoZERNSMcKFnNS70bN4qDVW4nFH9EKNrRUjLrV40KpMgLND8pNHIYBUCvF3Yqq4Vupd7pa62hnHBA9nWkFol/l0hsg0XehLdJbmDBF06eKJLB08AgK7cgAupRUiqrkk/k2JeNOrqIjMvGg02P8jIy421wW0V2xoSEVFLwqScWiSFkwPuC/fBfeE+AIDrJeVIrn7KaFJqEY4k5QIAfFROllKX8GAVFE6sGW7t0jQZ2JWWiFNsa0hERC0Ik3JqFbzcnNA/xgn9Y9pBEARkXi9F0jVzPfrhpFwknsqCCECQr7J60agKndXukDtw0WhrwLaGRETU0jEpp1ZHJBJB7a2A2luBYfcHwlhVs2jU3Nll9+/p2HkkDVKJCJ0C3Cw90tv7KyERc8FfS/JnW8N9SNNmwlWmxPiQkegX0IttDYmIqEVpkIWeRqMRCQkJKCkpwaBBg+Dt3fK+JuZCz7ajUl+FS5ZFo4VIy9MBAJzkEoQFmmvRI4NVaOfFRaPNxc33iqHKgCM5x5GQdsDS1jAuaCB6+nVnW0Nq0/h3hcg2rWKh56JFi3DkyBFs2LABgPlr48ceewzHjh2DIAhwd3fH2rVrERQUdG9REzUSuUyC6I6eiO5oXjSqKdPjQmqR5UFGp65cBwC4uciqE3Tzg4w8XB3tGXabdDTnBLak7ERxZTHc5e6Ibz8YZcZy7Es/xLaGRETUqtQ7KT948CAeeOABy8979+7F77//jieffBIRERF455138Pnnn+P//u//GjRQosbi6ixDzwhf9IzwBQDkF5dbEvTzfxTit/PmRaO+Hs7Vi0bNTxp1ceSMbGM6mnMC31/YAIPJAAAoqizG6osbAQDhqs54JHIa2xoSEVGrUe+kPCcnB8HBwZaf9+3bB7VajZdeegkAcPnyZWzdurXhIiRqYt7uTvB2d8KDMe1gEgRk5pci6VohklOL8Ou5HOw7mQkRgGA/peVJo50D3CDjotEGtSVlhyUhv5GrTIm5sU/ZISIiIqLGU++k3GAwQCr987AjR45YzZwHBgYiPz+/YaIjsjOxSIRAHwUCfRQY3jMIxioTrmZpLDPpu46mY8dvaZBKxOisvmHRqJ8SYjFncOur3FiBc9eTcTL/LIoqS+rcR6NnvSwREbU+9U7K/fz8cPLkSUyZMgWXL19Geno6nn/+ecv2goICODs7N2iQRM2FVCJGaKA7QgPdMa5fB1TojbiUXoyk6ieNbjxwFRsPXIWTXIrwIPOTRiOCVfD3dGaZxS2UGcpx9noSTuafQXLBJRiFKrjJXCGXyFFZVVlrf5Xc3Q5REhERNa56J+WjRo3CZ599hsLCQly+fBkKhQIDBgywbE9OTuYiT2ozHGVSdA3xQtcQLwCAplSP5NQiJFe3Xzx52bxo1F0hQ0T1gtHI9h5QKeX2DNvuSg1lOHM9CSfzzuBC4WVUCVVwl7uhv7oPuvt0RXvXIBzLPWVVUw4ADmIHjA2Jt2PkREREjaPeSfkzzzyD7OxsJCQkQKFQ4D//+Q9cXc0P59Bqtdi7dy8effTRho6TqEVwdZGhV6QvekWaF43mFZeb69GvFeHs1QIcPp8DAPD3dLaUuoQHucO5DSwa1elLcfr6OZzMO4uLRVdgEkzwcFRhYGBfxHp3RbCr2qqDSk+/7gBg1X1lbEi8ZZyIiKg1aZA+5TVMJhNKS0vh6OgIB4eWlWSwTzk1NpMgICNPZy51SS3EpfRi6A0miERAez9X8yx6sAqd1G5wkLaORaNavQ6n8s/hVN5ZXCpOgUkwwcvRA7E+XRHrE40gpdqmsh7eK0S24b1CZJvm2Ke8QZNyvV4PmUzWUKdrUkzKqakZq0xIySypXjRahKtZGpgEAQ5S60Wjwb4ta9FoSaUGp/PNM+KXi69CgAAfJy9LIq5WtKt3fT3vFSLb8F4hsk2rSMr379+PM2fOYO7cuZaxVatW4YMPPkBFRQVGjBiB9957jzPlNuA/nnSj8kojLqZXP2k0tRCZ+aUAABdHKcKDVJb2i74qp2a3aLS4sgQn887iZN5ZXC25BgECfJ190N0nGrE+XdHOxe+eYua9QmQb3itEtmmOSXm9a8q//PJLeHp6Wn5OSUnBu+++i8DAQKjVamzfvh3R0dGsKyeqJye5FN06eaFbJ/Oi0RJdpXkWPbUIydcKcfySudWoSimvLnXxQER7FdwV9lk0WlhRhFN5Z3Ey/yyulqQCANq5+GFkh6GI9ekKfxdfu8RFRETUEtU7Kb969apVt5Xt27dDLpdj/fr1UCgU+Pvf/44ff/yRSTnRPXJTyNE7yg+9o/wgCEL1olFzgn7q8nX8cta8aLSdlwsig80z6WGBKjg71vu2ttn18kKcyjfPiF/TpAEAAhT+GNNxOLp5R8PPxafRXpuIiKg1q/df75KSEqhUKsvPv/76K3r37g2FwjwV37NnT+zfv7/hIiQiiEQi+Kqc4atyxqDYAJgEAem5OiRdK0RSahEOnM7CnuMZEItE6OBf/aTRYA+EBLjBQSq+8wvcRn5ZAU7mn8HJvLNI02YAAIKUARjXYUbmPgAAIABJREFUcQS6+XSBj7N3Q7xFIiKiNq3eSblKpUJWVhYAQKfT4ezZs3jxxRct241GI6qqqhouQiKqRSwSIdhPiWA/JUb0DobBaF40mpRqbr+47XAqfvo1FTKpGJ0D3RFZvWg00FcBsQ213bll+dU14meQoTPf78GugRgfMhKxPtHwcvK8wxmIiIioPuqdlHfr1g1r1qxBp06dcODAAVRVVeHBBx+0bE9NTYWPD7/CJmpKDlIxwoNVCA9WAQ8CZRVGXEw3d3VJTi3CusQUAClwcZQiIliFiPbmBxn5uP+5aDSnNBcn8swz4lml5tKYDq7BmNhpNGK8o+HppLpNBERERHQv6p2UP//885g1axb+9re/AQAeeughdOrUCQAgCAL27NmDXr16NWyURFQvzo5SxHb2Rmxnc2lJkbYSF1LNXV2SrhXh2MV8AAJU3nqoAotQJk9HSVUBRBCho1t7TOo8Ft28u0DlyEfaExERNYV6J+WdOnXC9u3bceLECSiVStx///2WbRqNBo888giTcqJmRqWUo08XP/SO8kWGNguH0k/gVP456ExFyBaAqiIPVBVGwEfcAf7qAKjcVHAU1d2yiYiIiBpegz48qCVjn3JqrQRBQLo201yakn8W18vNM+KhqhDE+kQj2jMKRUVA0rVCJKcW4XJGCQxGEyRiETr4m580GhGsQkiAG6SSe1s0erd4rxDZhvcKkW2aY5/yu07K09LSkJCQgPT0dABAYGAghgwZgqCgIJvPodfr8dFHH2Hz5s3QaDQIDw/HvHnz0KdPn9se98knn2DZsmW1xr28vPDLL7/U741UY1JOrYkgCEjVpuNE3hmcyjuLgooiiEVihKk6IdY7Gl29o6CU1f2PgsFYhSsZJUiqftLotRwNBAGQOYgRGuiOyP/f3r1Hx13X+R9/zkwmk/t9Zto01+YykzSX5kJCRW5tkcLCwiIsChRUZHXBPQsedxE96zk/XQ8uVkTxCuiudHEVsLWIbilYEBVISJo2aXPp/ZKmnZncm3uazO+PhCylt7S0+X6TvB5/ke985zvvCXl3Xvnmc0mfGI+e4prepNELQb0iMj3qFZHpMWMoP68FjZ944gmefvrpk1ZZ+fa3v83nPvc5/vmf/3la1/nyl7/Mpk2buPvuu0lPT2f9+vXcd999rF27lpKSkrM+/+tf/zphYWFTX7//v0Xmm/HgOPt7D07trNk13I3NYsOTkM11GSspdOYTZY8863XsITbyMhLIy0jg41fCwNAozQe7p+6kP//6bgCiwu2Tk0YnVnZxxYVf7LcoIiIyZ51zKH/xxRf5yU9+QklJCZ/97GfJyckBYNeuXfzsZz/jJz/5Campqdxyyy1nvE59fT2///3veeSRR6Y2Grr55pu54YYbWLNmDc8999xZa7nuuuuIiYk517cgMmeMB8fZ23OAOn89WwPb6R7uIcRiIy8xlxsXX0thUh4R9ogP9RoRYXZKc52U5v7fpNHG/Z2TK7t08m6zH4Ck2LDJoS4J5KXHExMZ+qHfn4iIyHxxzqH8l7/8JcXFxaxdu5aQkP97elpaGldeeSV33nkn//3f/33WUL5x40bsdju33Xbb1DGHw8Gtt97Kd7/7Xfx+/1mXVgwGg/T19REZGTm1rJvIXDceHGd39z7q/A1sDTTQO3KMEGsISxI83JR1HYVJeYSHXLy71vHRDi4rXMhlhQsJBoMc7RygcX8Xjfs7ebc5wJvbjgCQ4owiPyOe/Ix4clPjCAu9eDuNioiIzHbn/Cm5Z88evvjFL54QyKcuFhLC9ddfz+OPP37W6zQ1NZGZmUlk5Il/Ti8qKiIYDNLU1HTWUH7VVVcxMDBAZGQk1157LQ8//DBxcVrCTeaesfExdnXvpc5fz7bADo6N9mG32lmS6KXUVciSRC9hITM/fMtisbAwMZKFiZGsKEthbHycA0f7poa6bN7SyqZ3D2GzWlicHEN+xsRd9MXJMYZNGhURETGjcw7ldrudgYGB0z7e39+P3W4/63UCgQBut/uk407nxJ/I/X7/aZ8bExPD6tWrKS4uxm6388477/DrX/+axsZGXnjhBUJD9Wdzmf3Gxsdo6dpNnb+Bbe3b6R8dINRqpyApjxJXEUsSvThs5vpZt1mtLE6OYXFyDDd8JIOR0TF2He6ZCOn7u3jpL/vY8Jd9OEJteFLjyJvcaXSRM3LGJo2KiIiY0TmH8sLCQn79619z2223kZSUdMJjHR0dPP/88xQXF5/1OkNDQ6cM7w6HA4Dh4eHTPveee+454etVq1aRk5PD17/+dX7729/y93//99N5Kyc43UzYi83pjDbkdcWcjo8dp97XzDutW3j38Db6RwYIC3FQnlzEpamlFC/IxxFiriB+NouS47jqknQAjg2M0LC7na27AtTvCvDrzROTRmOjQinOdlKU42RprhN3wsQ4+DdqD/Hs/zbR3jVIUnw4d1+Xx1VlqYa9F5HZQJ8rItNjtl4551B+//3386lPfYrrr7+ej3/841O7ee7evZt169bR39/PmjVrznqdsLAwRkdHTzr+Xhh/L5xP1yc/+Um+/e1v8/bbb59XKNeSiGKU0bFRmrt2UedvoL59B4PHhwizhVHkzKfEWUheQi5228QvsL1dw8Dpf2GdDXIWRpOzMJrbrlhMZ+/Q1ITRbbsCvLn1MADOuDASY8LYfbiH42MTfRnoGuTJ57fSe2yIZUsWGPkWRExLnysi0zMnlkS85JJLePLJJ/nGN77Bf/7nf57wWHJyMv/xH/9BeXn5Wa/jdDpPOUQlEAgAnHU8+QdZrVbcbjc9PT3n9DwRI4yMjdLU2UKdv4GG9kaGxoYJDwmnOKmAElchnoQc7Na5PzEyISaMjxYt5KNFE5NG2zoGpoa6bN3dftL5I8fHWfenPQrlIiIy55zXp/7y5cu56qqr2L59O62trcDE5kFLlizh+eef5/rrr+cPf/jDGa/h9XpZu3Yt/f39J0z23LZt29Tj52J0dJQjR45QUFBwju9GZGaMjI2wvaOZrf4GGjqaGBkbITIkglJXESWuInLjswiZB0H8dCwWC4uSIlmUFMk15al85lubT3leR+8wr9Uc4hKvi9ioc/uLmoiIiFmddwKwWq0UFRVRVFR0wvGuri727dt31uevWrWKn//857zwwgtT65SPjIywbt06SktLpyaBtrW1MTg4SFZW1tRzOzs7SUhIOOF6P/vZzxgeHubyyy8/37ckcsENHR9mR0cTdf4GdnQ0MzI+SpQ9kgp3CSWuInLiFmOz2owu05QSYxx09J48VMdmtfDL13bxP3/chTctnsp8N6W5TqLCzz7BXERExKwMuy1XXFzMqlWrWLNmDYFAgLS0NNavX09bWxuPPvro1HkPP/ww1dXVtLS0TB27+uqruf7668nNzSU0NJSqqipeeeUVysrKuOGGG4x4OyJTBo8Psb29ibpAA40dzYyOHyc6NIpLF5ZT4iokKzZTQXwabrkyi1/8bzMjx8enjoWGWLnnOi9p7miqG31UNfn4r/9tZu0rLRRkJlCR76YkJ0lroouIyKxj6CfXY489xhNPPMGGDRvo6enB4/Hw1FNPUVZWdsbn3XjjjWzZsoWNGzcyOjrKokWLuP/++/nc5z53yvXTRS62gdFBGtobqQvU09Sxk+PBMWJDY/hIciUlzkKy4jKwWrQu97l4b9z4uj/tobN3mIQYB7dcmTV1/O+uWMzNl2dywHeM6kY/VU0+tu3pIDTESlF2EpV5LoqyErGH6BcgERExP0swGLygS478+Mc/5vvf/z5NTU0X8rIXnVZfkXPVPzpAfWAHdYEGmjt3MRYcI84RS4mrkBJnEZmxaQriF8h0emU8GGR3aw9VTT5qmv0cGxglLNRGaa6Tynw3eenx2rBI5jx9rohMz5xYfUVkPusb6Wdb+3bq/A20dO1mPDhOQlg8V6VeRomziPSYFAVxg1gtFnJT48hNjeOOlTk0HeiiutFP7c4Ab20/SlS4nXLPREDPSY3TZkUiImIq0wrlH1z68Ey2bNly3sWImNGxkT62Braz1d/Azu49jAfHSQpLYEXqFZS4CkmLTsGigGcqNquVgsxECjITWX2th+17O6hq8vHWjqO8sbWNuKhQKvLcVOS5yVwYrf9/IiJiuGkNXznX5QktFouGr0yD/sxoXj3DvWwLTNwR39W9lyBBXOFJlLiKKHEVkhKVrCA3gy5UrwyPjLF1dzvVTT4a9nZwfCyIMy6Mijw3lXluUlzG7OwrcqHoc0Vkembt8JVnn332ghYkYkbdwz3U+Ruo8zewt2c/QYK4I1ysylhOiauI5MgFCuKznCPURmW+m8p8NwNDo9TuDFDd6OMP7xzg928fYFFSJBV5Liry3bjjI4wuV0RE5pELPtFzttKd8vmpc6iLrf4G6gIN7O05AEBy5AKWugopdRWxMNJtcIUCF79XevtHqGnxU9XoY1frxK7AGQuiJ4e4uEiICbtory1yIelzRWR6zHinXKF8kkL5/NE+2MnWwMQd8f29BwFYFLWQUlcRS52FLIh0GVyhfNBM9kpn7xDVTRNLLB44OvGauSmxVOS7Kfe6iIkInZE6RM6HPldEpkeh3MQUyuc2/0D7ZBCv5+CxwwCkRS+ixFnEUlcBrginwRXKmRjVK77OAaqafFQ1+jjSMYDVYiEvI57KPDeluUlEhGkXUTEXfa6ITI9CuYkplM89voEAdf566vwNtPa1AZAek0qJs5ASVyFJ4YkGVyjTZXSvBINBWgP9VE8G9PaeIUJsFgoXJ1KZ76Y4KwlHqDYpEuMZ3Ssis4UZQ7nWKZc55Wi/jy2TQbyt/ygAmTHpfDz7BoqdhSSGxxtcocxGFouFVFcUqa4obrliMXuP9FLd6Ke62UfdrnYcdhtLc5KoyHNRkJmIPURr1YuIyLlRKJdZLRgM0tZ/dGLVlEADR/t9WLCwODaDW3P+lqXOAuLD4owuU+YQi8VCVnIsWcmx3L48m52Huqlu8lHTEqCq0UeEI4RSj5PKPDfe9DhsVgV0ERE5O4VymXWCwSCtfUfY6q+nLtCAbyCABQvZcZlckXszxc4lxDlijS5T5gGr1YI3PR5vejx3XJNL4/6uiYDe7Ocv9UeIibBT7nVRme8ma1GsdhEVEZHTUiiXWSEYDHLo2OGJoSmBBtoHO7BgITc+i6tTP0qxs4CY0Gijy5R5LMRmpSgrkaKsREZGx2jY20FVo48/1x9h85bDJMQ4qPBOrJGe5o7SmvciInIChXIxrWAwyP7eQ9QF6tnqb6BjqAurxYonPpuPpV1FkXMJ0aHagVHMJ9Ruo8zjoszjYnD4OFt3tVPV5OPVmkNsrD6IOyGCyjwXFXlukpMijS5XRERMQKuvTNLqK+YwHhxnf+/BqZ01u4a7sVlseBKyKXUWUejMJ8quEDPfzJVe6RscpbbFT3WTn+YDXQSBFGcUlfkTAd0ZF250iTLLzZVeEbnYzLj6ikL5JIVy44wHx9nbc4A6fz1bA9vpHu4hxGIjLzGXEmcRhUl5RNi15fl8Nhd7pbtvmHeb/VQ3+dhzuBeArOQYKvLcXJLnIi7KYXCFMhvNxV4RuRgUyk1MoXxmjQfH2d29jzp/A1sDDfSOHCPEGsKSBA9LXYUUJuURHqK7hjJhrvdKe/cg1c1+qhp9HPL3YQE8aXETu4h6XESFa5MimZ653isiF4pCuYkplF98Y+Nj7OreS52/nm2BHRwb7cNutbMk0UuJq5CCRC9hIWFGlykmNJ96pa19cpOiJj++zgFsVgtLMhOoyHNRkuMk3KGpQHJ686lXRD4MM4Zy/esuF9XY+BgtXbup8zewrX07/aMDhFrtFCTlUeIqYkmiF4ct1OgyRUwjOSmSmy9fzE0fzeSgr4+qJh/VTT7q93RgD2mhKCuRyjw3RVmJhNq1i6iIyFyhUC4X3PHx4zR37qIu0EB9YAcDxwdx2EIpTMqnxFVEfkIuoQriImdksVhIXxBN+oJobr0qi72He6lq9PFus4/algBhoTZKcpxU5rvIz0ggxKZNikREZjOFcrkgRsdGae7axRZ/PQ3tjQweHyLMFkaRM58SZyF5CbnYbRoXK3I+rBYL2SmxZKfE8omV2TQf7Ka6cSKcv73jKJFhIZR7J1Zw8aTGYbVqDXQRkdlGoVzO28jYKI2dLdT569ne3sTQ2DDhIeEUJxVQ4irEk5CD3aofMZELyWa1siQjgSUZCay+1sP2vZ1UN/l4Z4ePP21tIzYqlEu8Lirz3CxOjtEmRSIis4QSk5yTkbERtnc0s9XfQENHEyNjI0SGRFDqKqLEVURufBYhCuIiMyLEZmVpThJLc5IYHhlj2552qhp9vFF3mNdqWkmKDaMiz01FnotUl3YRFRExM6UnOauh48Ps6Giizt/Ajo5mRsZHibJHcom7hFJXETlxi7FZNeFMxEiOUNtkAHczMHScul0Bqhp9bKw6yB/eOcDCxAgq89xU5LtZkKB1/0VEzEZLIk7SkognGjw+xPb2JuoCDTR2NDM6fpzo0ChKnIWUuArJis1UEJcZY+ZeMbvegRFqWyYC+q5D3QSBdHc0lfluLvG6SIzVMqRziXpFZHrMuCSiQvkkhXIYGB2kob2RukA9TR07OR4cIzY0hqWuQkqchWTFZWC1aIUHmXlm65XZqrN3aGoX0X1HJr6f2SmxVOa5Kfe6iI3UqkiznXpFZHoUyk1svoby/tEB6gM7qAs00Ny5i7HgGHGOWEpchZQ4i8iMTVMQF8OZoVfmGl/XANVNEwH9cKAfiwXy0uOpzHNT6nESGabVkmYj9YrI9CiUm9h8CuV9I/1sa99Onb+Blq7djAfHSQiLnwri6TEpCuJiKgoaF1droG9iF9FGH4HuIWxWC4WLE6nId1GS7cQRqqFqs4V6RWR6zBjKNdFznjg20sfWwHa2+hvY2b2H8eA4SWEJrEi9ghJXIWnRKVqZQWSeSnFGkeKM4u8uX8z+o8cmNynys3V3O6F2K0uzk6jIc1O4OBF7iH5hFxG5GBTK57Ce4V62BSbuiO/q3kuQIK7wJK5Ju4oSVyEpUckK4iIyxWKxkLkwhsyFMfz98mx2HeqmqslPTbOf6iY/4Y4QSnOTqMxzk5cRj82qgC4icqEolM8x3cM91PkbqPM3sLdnP0GCuCNcrMpYTomriOTIBQriInJWVosFT1o8nrR47liZQ/OBLqoafWzZGeCvDUeJjrBT7nFRme8mOyUWq/5dERH5UBTK54DOoS62+huoCzSwt+cAAMmRC7gucyWlriIWRroNrlBEZrMQm5WCxYkULE7k7uNj1O+Z2EX0rw1HeL3uMPHRDiryXFTkuclYEK1f/EVEzoNC+SzVPtjJ1sDEHfH9vQcBWBS1kBsXX8tSZyELIl0GVygic5E9xEaZx0mZx8nQyHG27mqnusnPazWtvFJ9CFd8OBV5birzXCxynnoyk4iInEyrr0yaDauv+AfaJ4N4PQePHQYgLXoRJc4ilroKcEU4L1apIobSihLm1zc4ypadAaqbfDQd6CIYhBRn5MQuo/luXHHhRpc4L6hXRKbHjKuvKJRPMmso9w0EqPPXU+dvoLWvDYD0mNSpnTWTwhNnolQRQylozC49fcPUTO4iuvtwDwCZC2OozHNxSZ6b+GiHwRXOXeoVkelRKDcxM4XyI/2+qSDe1n8UgMyYdEpchSx1FpIYHj+jdYoYTUFj9mrvGeTdJj9VTT4O+vqwALmpcVTmuynzOImO0C6iF5J6RWR6FMpNbCZDefXRLby0ZyPdw93EOeL428XXsig6eWLVlEADR/t9WLCwODadElcRS50FxIfFzUhtImakoDE3HOnop7rJT1Wjj6OdA1gtFvIzJ3cRzXUS7tA0pw9LvSIyPQrlJjZTobz66BZ+2fwbRsdHT3rMgoXsuExKXEUUO5cQ54i96PWIzAYKGnNLMBjkkL+PqiYf1Y1+OnqHCLFZKc5KpCLfTVFWIg67dhE9H+oVkekxYyjXbYkZ9tKejacM5BEh4fzbpV8iJjTagKpERGaOxWIhzR1NmjuaW6/MYk9bL9WTu4jW7gzgCLVRkjOxi2hBZgIhNm1SJCJzn0L5DOsa7j7l8YHjgwrkIjLvWCwWshfFkr0olk+syKHlYBdVTX5qW/y8s8NHZFgIZR4nFXluvGnxWK1aA11E5iaF8hkW74g7ZTCPd2jMuIjMb1arhbyMBPIyErjrY7ns2DexSVFVk583tx0hJjKUS7wTu4hmJcdokyIRmVMUymfY32atOmlMud1q52+zVhlYlYiIuYTYrBRnJ1GcncTw6BgNezqoavTxp61t/LG2lcSYMCryJgJ6qitKAV1EZj1N9Jxk6OorWauoWFA6I68tMhtp8pq8Z3D4+OQmRX4a93cyNh5kQULEVEBfmBhpdImGUq+ITI8ZJ3oqlE8y0zrlInIi9YqcyrGBEWpbJnYRbTnYTRBIc0VRme/mkjwXSbHzbxdR9YrI9CiUm5hCuYh5qVfkbLqODfNus5/qJh9723oByF4US0Wei0u8LmKj5scuouoVkelRKDcxhXIR81KvyLnwdw/ybpOPqkY/rYE+LBbwpsVTmT+xSVFUuN3oEi8a9YrI9CiUm5hCuYh5qVfkfB1u76e60UdVkw9/1yA2q4WCzAQq8t2U5CQRFjq31jtQr4hMjxlD+dz610hEROR9FiVF8ndXLObmyzM54DtGVaOP6iY/2/Z0EBpipSg7ico8N0VZCdhDtIuoiBhHoVxEROY8i8VCxoIYMhbEcNvV2exu7aGqyUdNs5+aZj9hoTZKc51U5rvJS4/XLqIiMuMMDeUjIyN873vfY8OGDfT29uL1ennooYdYtmzZOV3nvvvu48033+Tuu+/mq1/96kWqVkRE5gKrxUJuahy5qXHcsTKHpgNdVDf6qd0Z4K3tR4kKt1PudVGZ5yInNQ6r1kAXkRlgaCj/8pe/zKZNm7j77rtJT09n/fr13Hfffaxdu5aSkpJpXeONN96gpqbmIlcqIiJzkc1qpSAzkYLMRFZf62H73g6qmny8tf0Ib9QdJi4qlIo8NxV5bjIXRmuTIhG5aAwL5fX19fz+97/nkUce4VOf+hQAN998MzfccANr1qzhueeeO+s1RkZGePTRR7n33nt58sknL3LFIiIyl9lDrJTkOinJdTI8MsbW3e1UN/nYvKWVTe8ewhkXRkWem8p8NynOU0/UEhE5X4aF8o0bN2K327ntttumjjkcDm699Va++93v4vf7cblcZ7zGs88+y9DQkEK5iIhcUI5QG5X5EwF8YGiU2p0Bqht9/OGdA/z+7QMsSoqkIs9FRb4bd3yE0eWKyBxgWChvamoiMzOTyMgTt0QuKioiGAzS1NR0xlAeCAT40Y9+xNe+9jXCw+ffrm0iIjIzIsLsXF6UzOVFyfT2j1DT4qeq0cf6P+9j/Z/3kbEgemIXUa+LhJgwo8sVkVnKsFAeCARwu90nHXc6nQD4/f4zPv/xxx8nMzOTm2666aLUJyIi8kExkaEsL01heWkKnb1DVDf5qWry8evNu/n15t3kpsRSme+mzOsiJiLU6HJFZBYxLJQPDQ1ht5+8q5rDMbEV8vDw8GmfW19fz29/+1vWrl17wSbdnG4h94vN6Yw25HVFZhv1ipiN0xmNJ8vJ6huW0Bbo482th3mzrpW1m3by3Gu7KM5O4oqSFC4tXDiju4iqV0Smx2y9YlgoDwsLY3R09KTj74Xx98L5BwWDQb75zW/ysY99jPLy8gtWj3b0FDEv9YqYnR1YsTSZ5cULaQ30U93ko6rRx/d+XccPX9xK4eJEKvPdFGcn4bBfvE2K1Csi06MdPd/H6XSecohKIBAAOO148ldffZX6+noeeughWltbT3isr6+P1tZWkpKSCAvTuD4REZlZFouFVFcUqa4obrliMXuP9FLd6Ke62UfdrnYcdhtLc5KoyHNRkJmIPUSbFInIBMNCudfrZe3atfT3958w2XPbtm1Tj59KW1sb4+Pj3HPPPSc9tm7dOtatW8fTTz/NFVdccXEKFxERmQaLxUJWcixZybHcvjybnYe6qW7yUdMSoKrRR4QjhFLPxC6i3rQ4bFYFdJH5zLBQvmrVKn7+85/zwgsvTK1TPjIywrp16ygtLZ2aBNrW1sbg4CBZWVkALF++nJSUlJOu98ADD3D11Vdz6623smTJkhl7HyIiImdjtVrwpsfjTY/njmtyadzfRVWjj5pmP3+pP0JMxOQuovlushbFahdRkXnIsFBeXFzMqlWrWLNmDYFAgLS0NNavX09bWxuPPvro1HkPP/ww1dXVtLS0AJCWlkZaWtopr5mamsrKlStnpH4REZHzEWKzUpSVSFFWIiOjYzTs7aCq0cef64+wecthEmMcXJLnpjLPTZo7SruIiswThoVygMcee4wnnniCDRs20NPTg8fj4amnnqKsrMzIskRERGZEqN1GmcdFmcfF4PBxtu5qp6rJx6vvHmJj1UHcCRFU5rmoyHOTnBR59guKyKxlCQaDM7vkiElp9RUR81KvyHzTNzhKbYuf6iY/zQe6CAKprigq8lxU5rlJijv1pnnqFZHpMePqKwrlkxTKRcxLvSLzWXffMO82+6lu8rHncC8AWckxVOS5uSTPRVyUg7d3HGXdn/bQ2TtMQoyDW67MYtmSBQZXLmJeCuUmplAuYl7qFZEJ7d2DVDf7qWr0ccjfhwVYkBCOv3uIsfd9hoWGWLnnOq+CuchpmDGUGzqmXERERKYvKS6c6y9N5/pL02lrn9ik6OW3D5x0U2nk+Djr/rRHoVxkFtGiqCIiIrNQclIkN1+++LR/5e3oHeZPWw/TOzAyw5WJyPnQnXIREZFZLDHGQUfv8EnHrRYLv9jYwrOvtOBNi6fM46Q010lclMOAKkXkbBTKRUREZrFbrsziF//bzMjx8aljoSFW7l7lIcUZRU1LgJpmP/+9aSfPbdq3/dUwAAAZyklEQVRJTkosZV4XZblOEmLCDKxcRN5PEz0naaKniHmpV0TO7GyrrwSDQdra+ycCeoufw4F+ALIWxVDucVHmcZIUe+plFkXmIjNO9FQon6RQLmJe6hWR6Zlurxzp6Kd2MqAf9PUBkLEgmnLvREB3x0dc7FJFDKVQbmIK5SLmpV4RmZ7z6RV/18BUQN93ZOK5aa4oyrwuyj1OFiZqJ1GZexTKTUyhXMS81Csi0/Nhe6W9Z3AqoL+3UdEiZyTlnomAnpwUicViuVDlihhGodzEFMpFzEu9IjI9F7JXOnuH2LIzQE1LgF2HugkCCxIiKPc6Kfe4SHVFKaDLrKVQbmIK5SLmpV4RmZ6L1Ss9fcNTAb35YBfBILjiwimbDOgZC6IV0GVWMWMo15KIIiIickaxUQ6uLk3h6tIUegdGqNsZoLYlwKbqQ/zvOwdJjAmjzOOk3OticXIMVgV0kXOmUC4iIiLTFhMRypVLF3Hl0kX0DY6ydVc7NS1+/ljbyqZ3DxEf7aAsdyKgZy+KxWpVQBeZDoVyEREROS9R4XY+WrSQjxYtZGBolG27O6hp8fPG1jZeq20lNjKUUs/EEJfc1FhsVqvRJYuYlkK5iIiIfGgRYXaWFSxgWcECBoeP07C3g5pmP3+tP8LrWw4THWGnNNdJmceJNy2eEJsCusj7KZSLiIjIBRXuCKEiz01FnpvhkbGJgN7i551GH3/a2kZkWAglOU7KvU7yMxIU0EVQKBcREZGLyBFqo9zrotzrYmR0jB37Oqlp8VO7089fGo4Q7ghhaXYS5V4nBZkJ2ENsRpcsYgiFchEREZkRoXYbJblOSnKdjB4fp3F/J7UtAep2BXh7x1EcoTaKsxIp97gozErEYVdAl/lDoVxERERmnD3ESnF2EsXZSRwf89B8sIua5gBbdgaobvITardStDiRcq+LoqxEwkIVWWRu00+4iIiIGCrEZqUgM5GCzERWX5vLzoPd1LQEqJ3csMgeYqUgM4Fyr4virCQiwhRfZO7RT7WIiIiYhs1qJS8jgbyMBO68Jpfdh3uoafZTuzNA3a52QmwW8jMSKPe4WJqTRFS43eiSRS4IhXIRERExJavVQm5qHLmpcXxiZQ5723onAnqLn/o9HdisFvLS4yn3uijJSSI6ItTokkXOmyUYDAaNLsIMOjr6GB+f2W+F0xlNIHBsRl9TZDZSr4hMz3zplWAwyP6jx6hp9lPT4ifQPYTVYsGTFke510VprpPYSAV0OT2jesVqtZCYGHXKxxTKJymUi5iXekVkeuZjrwSDQQ75+6hp8fNucwBf5wAWICc1jnKPkzKPi/hoh9FliskolJuYQrmIealXRKZnvvdKMBjkcHv/5BCXAIfb+wHIXhQ7FdATY8MMrlLMQKHcxBTKRcxLvSIyPeqVEx3p6J9YxaXZz0F/HwCZC2MmArrXhSsu3OAKxSgK5SamUC5iXuoVkelRr5yer2uA2pYANc1+9h+d+B6luaMo90zsNrogIcLgCmUmKZSbmEK5iHmpV0SmR70yPe3dgxN30Fv87GnrBSDFGUm5x0WZ18WipEiDK5SLTaHcxBTKRcxLvSIyPeqVc9fZO0TtzokhLrtaewgCCxMjKPO4KPc4SXVFYbFYjC5TLjCFchNTKBcxL/WKyPSoVz6c7r5htuycGOLScqibYBBc8eGTQ1ycpLujFdDnCDOGcm0eJCIiIgLERTlYXprC8tIUevtH2LJr4g76xqqD/OGdAyTFhk0OcXGyeGGMArpcUArlIiIiIh8QExnKVUsXcdXSRfQNjlK3K0BtS4BXaw6xsfogCTEOSnOdlHtcZKfEYlVAlw9JoVxERETkDKLC7VxelMzlRckMDI2ydXc7Nc0B3qhr47WaVmKjQimbDOi5qXFYrQrocu4UykVERESmKSLMzkcKFvKRgoUMDh9n2552apsD/KX+CJu3HCYmwk5p7sQ66J7UOEJsVqNLlllCoVxERETkPIQ7Qrg0fwGX5i9geGSMhr0d1LT4eXuHjze2thEVbmdpThLlHhf5GfEK6HJGCuUiIiIiH5Ij1Ea5d2IjopHRMbbv66SmxU9Ns5+/1B8h3BFCyWRAX5IZjz3EZnTJYjIK5SIiIiIXUKjdRmmuk9JcJ6PHx9mxv5PaZj91u9p5a/tRwkJtLM1OoszjpGBxIg67AroolIuIiIhcNPYQK0uzk1iancTxsXGaD3RR0+Jny8523mn0EWq3UpSVRLnHSVFWImGhimbzlf7Pi4iIiMyAEJuVgsWJFCxOZPW147Qc7KamJcCWyWEu9hArhYsTKfc4Kc5OItyhmDaf6P+2iIiIyAyzWa3kZySQn5HAXdfksqt1IqDXtvjZsjNAiM3CkowEyr0uluYkERlmN7pkucgUykVEREQMZLVa8KTF40mL55Mrc9h7uHdikmiLn217OrBZLeRlxFPucVGSk0R0RKjRJctFYAkGg0GjizCDjo4+xsdn9lvhdEYTCByb0dcUmY3UKyLTo16ZW4LBIPuOHJtaxaW9ZwirxYI3PW4ioOc6iY1UQD8fRvWK1WohMTHqlI8plE9SKBcxL/WKyPSoV+auYDDIQV/fVED3dQ1isYAnNY4yj4vSXCfx0Q6jy5w1FMpNTKFcxLzUKyLTo16ZH4LBIIcD/ZNDXAK0tfdjAbJSYin3uCj3OEmICTO6TFNTKDcxhXIR81KviEyPemV+OtzeT22Ln5rmAK2BPgAWJ8dQ7nFR5nHijAs3uELzUSg3MYVyEfNSr4hMj3pFfJ0DU3fQDxyd+FlIXxBNucdJuceFOyHC4ArNQaHcxBTKRcxLvSIyPeoVeb9A9yC1LQFqWvzsbesFIMUZRbl3IqAnJ0UaXKFxFMpNTKFcxLzUKyLTo16R0+noGaJ250RA39PaQxBIToqcuoO+yBmJxWIxuswZo1D+ASMjI3zve99jw4YN9Pb24vV6eeihh1i2bNkZn/fSSy/x4osvsmfPHnp6enC5XFRWVvKFL3yBRYsWnVctCuUi5qVeEZke9YpMR9exYbbsnNioqOVQN8EguOPDKfe6KPe4SHNHzfmArlD+AV/84hfZtGkTd999N+np6axfv57t27ezdu1aSkpKTvu8xx57jEAggNfrJTY2lra2Np5//nnGxsZ46aWXcDqd51yLQrmIealXRKZHvSLnqqd/hLrJO+jNB7oZDwZJig2bCuiZC6PnZEBXKH+f+vp6brvtNh555BE+9alPATA8PMwNN9yAy+XiueeeO6fr7dixg1tuuYV//dd/5d577z3nehTKRcxLvSIyPeoV+TCODYxQt6ud2pYAjfs7GRsPkhDjmFrFJWtRLNY5EtDNGMpDZriWKRs3bsRut3PbbbdNHXM4HNx6661897vfxe/343K5pn295ORkAHp7ey94rSIiIiJzXXREKFcUJ3NFcTL9Q6NsnQzom7e0sundQ8RFhVKW66Lc6yQnJQ6rdW4EdLMwLJQ3NTWRmZlJZOSJM3+LiooIBoM0NTWdNZR3d3czNjZGW1sbP/zhDwHOOh5dRERERM4sMszOZYULuaxwIYPDx9m2u52algBv1rfxxy2txETYKZ3cqMiTFofNajW65FnPsFAeCARwu90nHX9vPLjf7z/rNa699lq6u7sBiIuL42tf+xqXXnrphS1UREREZB4Ld4Rw6ZIFXLpkAUMjx2nY20lNs5+3th/hjbrDRIXbKc1NoszjIi89nhCbAvr5MCyUDw0NYbfbTzrucDiAifHlZ/ODH/yAgYEB9u3bx0svvUR/f/9513O68T0Xm9MZbcjrisw26hWR6VGvyMWWuiie6y/PYmjkOHUtfv667QjVjUd5c9sRIsPtVC5ZwGXFyZTkOrGH2Iwu97TM1iuGhfKwsDBGR0dPOv5eGH8vnJ/JJZdcAsCVV17JihUruPHGG4mIiOCuu+4653o00VPEvNQrItOjXpGZlr0gmuwF0dyxIosd+7qoafHzdsMRNtccItxhozg7iXKPi4LMBELt5gnomuj5Pk6n85RDVAKBAMA5TfIESE1NZcmSJfzud787r1AuIiIiIufHHmJjaU4SS3OSOD42TuP+Lmpb/GzZGeCdHT4cdhtFWYmUe10ULU7EEWqegG4WhoVyr9fL2rVr6e/vP2Gy57Zt26YeP1dDQ0MMDg5esBpFRERE5NyE2KwUZSVSlJXI6ms9tBzqprbZT+3OAO82+wkNsVK4OJEyr5PirCTCHYbFUVMx7LuwatUqfv7zn/PCCy9MrVM+MjLCunXrKC0tnZoE2tbWxuDgIFlZWVPP7ezsJCEh4YTrbd++nebmZq6//voZew8iIiIicnohNitLMhJYkpHAXR/zsPNQNzUtfmpbAtTuDBBis1KQmUC518nS7CQiwk6ebzhfGBbKi4uLWbVqFWvWrCEQCJCWlsb69etpa2vj0UcfnTrv4Ycfprq6mpaWlqljV199Nddddx25ublERESwe/dufvOb3xAZGcn9999vxNsRERERkTOwWi140+PxpsdzxzW57G7tobZlYjfRrbvbsVktLMlMoCzXSUmuk6jw+RXQDf17wWOPPcYTTzzBhg0b6OnpwePx8NRTT1FWVnbG591xxx28/fbbvPbaawwNDeF0Olm1ahX3338/qampM1S9iIiIiJwPq8VCbmocualx3L4im31Heqltngjo9Xs6+MXGFvLS4yjzuijNcRITGWp0yRedJRgMzuySIyal1VdEzEu9IjI96hWZ7YLBIAd8x6iZDOj+rkEsFvCkxlHudVGa6yQu6uwr9J2NGVdfUSifpFAuYl7qFZHpUa/IXBIMBmkN9FPT7Kemxc+RjgEsQHZKLOUeF2UeJwkxYed1bYVyE1MoFzEv9YrI9KhXZC473N5P7WRAbw1MbBiZlRxDmcdFucdJUlz4tK+lUG5iCuUi5qVeEZke9YrMF0c7B6ht8VPTHOCAb+JnPmNBNGUeJ+VeF+74iDM+X6HcxBTKRcxLvSIyPeoVmY/83YNTAX3fkV4AUl1RlE8G9IWJ/7cfzts7jrLuT3vo7B0mIcbBLVdmsWzJghmrVaF8GhTKRcxLvSIyPeoVme/aewbZ0hKgpiXA7sM9ACxKiqTM48QeYuV3f93PyPHxqfNDQ6zcc513xoL5mUK5tlASERERkTkhKTacj1Wk8bGKNLqODVM7uVHR7/66n1Pdeh05Ps66P+2Z0bvlp6NQLiIiIiJzTny0g5XlqawsT6Wnb5iHfvDXU57X0Ts8w5WdmtXoAkRERERELqbYKAeJMade3/x0x2eaQrmIiIiIzHm3XJlFaMiJ0Tc0xMotV2YZVNGJNHxFREREROa898aNG7n6ypkolIuIiIjIvLBsyQKWLVlgypWKNHxFRERERMRgCuUiIiIiIgZTKBcRERERMZhCuYiIiIiIwRTKRUREREQMplAuIiIiImIwhXIREREREYMplIuIiIiIGEyhXERERETEYNrRc5LVaplXrysy26hXRKZHvSIyPUb0yple0xIMBoMzWIuIiIiIiHyAhq+IiIiIiBhMoVxERERExGAK5SIiIiIiBlMoFxERERExmEK5iIiIiIjBFMpFRERERAymUC4iIiIiYjCFchERERERgymUi4iIiIgYTKFcRERERMRgIUYXMN/4/X6effZZtm3bxvbt2xkYGODZZ5+lsrLS6NJETKO+vp7169dTVVVFW1sbcXFxlJSU8OCDD5Kenm50eSKm0dDQwE9+8hMaGxvp6OggOjoar9fLAw88QGlpqdHliZja008/zZo1a/B6vWzYsMHochTKZ9q+fft4+umnSU9Px+PxUFdXZ3RJIqbzzDPPsGXLFlatWoXH4yEQCPDcc89x88038+KLL5KVlWV0iSKmcOjQIcbGxrjttttwOp0cO3aM3/3ud9x11108/fTTXHbZZUaXKGJKgUCAH//4x0RERBhdyhRLMBgMGl3EfNLX18fo6Cjx8fG89tprPPDAA7pTLvIBW7ZsoaCggNDQ0Klj+/fv58Ybb+Rv/uZv+Na3vmVgdSLmNjg4yMqVKykoKOCnP/2p0eWImNKXv/xl2traCAaD9Pb2muJOucaUz7CoqCji4+ONLkPE1EpLS08I5AAZGRnk5OSwZ88eg6oSmR3Cw8NJSEigt7fX6FJETKm+vp6XXnqJRx55xOhSTqBQLiKzQjAYpL29Xb/UipxCX18fnZ2d7N27l8cff5ydO3eybNkyo8sSMZ1gMMg3vvENbr75ZvLy8owu5wQaUy4is8JLL72Ez+fjoYceMroUEdP5yle+wiuvvAKA3W7nE5/4BJ///OcNrkrEfH7729+ye/dufvjDHxpdykkUykXE9Pbs2cPXv/51ysrKuOmmm4wuR8R0HnjgAW6//XaOHj3Khg0bGBkZYXR09KRhYCLzWV9fH9/5znf4h3/4B1wul9HlnETDV0TE1AKBAJ/73OeIjY3le9/7Hlar/tkS+SCPx8Nll13Gxz/+cX72s5+xY8cO042XFTHaj3/8Y+x2O5/+9KeNLuWU9OkmIqZ17Ngx7rvvPo4dO8YzzzyD0+k0uiQR07Pb7axYsYJNmzYxNDRkdDkipuD3+/nFL37BHXfcQXt7O62trbS2tjI8PMzo6Citra309PQYWqOGr4iIKQ0PD/P5z3+e/fv381//9V8sXrzY6JJEZo2hoSGCwSD9/f2EhYUZXY6I4To6OhgdHWXNmjWsWbPmpMdXrFjBfffdx5e+9CUDqpugUC4ipjM2NsaDDz7I1q1b+dGPfsTSpUuNLknElDo7O0lISDjhWF9fH6+88goLFy4kMTHRoMpEzCUlJeWUkzufeOIJBgYG+MpXvkJGRsbMF/Y+CuUG+NGPfgQwtd7yhg0bqK2tJSYmhrvuusvI0kRM4Vvf+habN2/m6quvpru7+4RNHSIjI1m5cqWB1YmYx4MPPojD4aCkpASn08mRI0dYt24dR48e5fHHHze6PBHTiI6OPuVnxy9+8QtsNpspPle0o6cBPB7PKY8vWrSIzZs3z3A1IuazevVqqqurT/mY+kTk/7z44ots2LCB3bt309vbS3R0NEuXLuUzn/kMFRUVRpcnYnqrV682zY6eCuUiIiIiIgbT6isiIiIiIgZTKBcRERERMZhCuYiIiIiIwRTKRUREREQMplAuIiIiImIwhXIREREREYMplIuIiIiIGEyhXEREDLN69WqWL19udBkiIoYLMboAERG5sKqqqrj77rtP+7jNZqOxsXEGKxIRkbNRKBcRmaNuuOEGrrjiipOOW636I6mIiNkolIuIzFH5+fncdNNNRpchIiLToNslIiLzVGtrKx6PhyeffJKXX36ZG2+8kcLCQq666iqefPJJjh8/ftJzmpubeeCBB6isrKSwsJDrr7+ep59+mrGxsZPODQQC/Pu//zsrVqygoKCAZcuW8elPf5q//vWvJ53r8/n44he/yCWXXEJxcTH33nsv+/btuyjvW0TEjHSnXERkjhocHKSzs/Ok46GhoURFRU19vXnzZg4dOsSdd95JUlISmzdv5gc/+AFtbW08+uijU+c1NDSwevVqQkJCps59/fXXWbNmDc3NzXznO9+ZOre1tZVPfvKTdHR0cNNNN1FQUMDg4CDbtm3jrbfe4rLLLps6d2BggLvuuovi4mIeeughWltbefbZZ7n//vt5+eWXsdlsF+k7JCJiHgrlIiJz1JNPPsmTTz550vGrrrqKn/70p1NfNzc38+KLL7JkyRIA7rrrLr7whS+wbt06br/9dpYuXQrAN7/5TUZGRvjVr36F1+udOvfBBx/k5Zdf5tZbb2XZsmUA/L//9//w+/0888wzXH755Se8/vj4+Alfd3V1ce+993LfffdNHUtISODb3/42b7311knPFxGZixTKRUTmqNtvv51Vq1addDwhIeGErz/ykY9MBXIAi8XCZz/7WV577TVeffVVli5dSkdHB3V1dVxzzTVTgfy9c//xH/+RjRs38uqrr7Js2TK6u7v585//zOWXX37KQP3BiaZWq/Wk1WIuvfRSAA4cOKBQLiLzgkK5iMgclZ6ezkc+8pGznpeVlXXSsezsbAAOHToETAxHef/x91u8eDFWq3Xq3IMHDxIMBsnPz59WnS6XC4fDccKxuLg4ALq7u6d1DRGR2U4TPUVExFBnGjMeDAZnsBIREeMolIuIzHN79uw56dju3bsBSE1NBSAlJeWE4++3d+9exsfHp85NS0vDYrHQ1NR0sUoWEZlzFMpFROa5t956ix07dkx9HQwGeeaZZwBYuXIlAImJiZSUlPD666+zc+fOE8596qmnALjmmmuAiaEnV1xxBW+++SZvvfXWSa+nu98iIifTmHIRkTmqsbGRDRs2nPKx98I2gNfr5Z577uHOO+/E6XTyxz/+kbfeeoubbrqJkpKSqfO++tWvsnr1au68807uuOMOnE4nr7/+On/5y1+44YYbplZeAfi3f/s3Ghsbue+++7j55ptZsmQJw8PDbNu2jUWLFvEv//IvF++Ni4jMQgrlIiJz1Msvv8zLL798ysc2bdo0NZZ7+fLlZGZm8tOf/pR9+/aRmJjI/fffz/3333/CcwoLC/nVr37F97//ff7nf/6HgYEBUlNT+dKXvsRnPvOZE85NTU3lN7/5DT/84Q9588032bBhAzExMXi9Xm6//faL84ZFRGYxS1B/RxQRmZdaW1tZsWIFX/jCF/inf/ono8sREZnXNKZcRERERMRgCuUiIiIiIgZTKBcRERERMZjGlIuIiIiIGEx3ykVEREREDKZQLiIiIiJiMIVyERERERGDKZSLiIiIiBhMoVxERERExGAK5SIiIiIiBvv/TJidS0S6dlMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZ4Tx8PNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a430c1b6-8f41-43e2-c8ca-5b183fbea8e9"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.58</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:02:57</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:02:55</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:02:53</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:02:52</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.58         0.43           0.83       0:02:57         0:00:07\n",
              "2               0.50         0.53           0.86       0:02:55         0:00:07\n",
              "3               0.38         0.69           0.85       0:02:53         0:00:07\n",
              "4               0.28         0.75           0.84       0:02:52         0:00:07"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrRQFllONxsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9b604c-6e75-4a61-abca-b07e28ea7274"
      },
      "source": [
        "evaluation(y_val_fake, y_pred_val_fake)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine Grained Accuracy = 0.8443271767810027\n",
            "\n",
            "\n",
            "Fine Grained Metrics\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87       225\n",
            "           1       0.80      0.82      0.81       154\n",
            "\n",
            "    accuracy                           0.84       379\n",
            "   macro avg       0.84      0.84      0.84       379\n",
            "weighted avg       0.85      0.84      0.84       379\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHgr-fodo8e"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_val_fake, index = val_data.index, columns=['fake'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_val_fake.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HWdCRDNxs0"
      },
      "source": [
        "**Training for Fake Class (Using Train +Val Data and Test Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwvcdNspi294"
      },
      "source": [
        "train_val_labels_fake = y_train_val_fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-RaRs7Nxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92336f07-d6e7-4c65-9a83-a89e76300970"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_val_sentences)\n",
        "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_fake)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wfwVeBNxs0"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_val_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmjATAqNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290603ee-b89b-4b5d-f2b8-ff8cc6c5b223"
      },
      "source": [
        "training_stats, y_pred_test_fake = train_fn_test(train_val_dataloader, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    764.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    764.    Elapsed: 0:00:52.\n",
            "  Batch   240  of    764.    Elapsed: 0:01:02.\n",
            "  Batch   280  of    764.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    764.    Elapsed: 0:01:23.\n",
            "  Batch   360  of    764.    Elapsed: 0:01:33.\n",
            "  Batch   400  of    764.    Elapsed: 0:01:43.\n",
            "  Batch   440  of    764.    Elapsed: 0:01:53.\n",
            "  Batch   480  of    764.    Elapsed: 0:02:04.\n",
            "  Batch   520  of    764.    Elapsed: 0:02:14.\n",
            "  Batch   560  of    764.    Elapsed: 0:02:24.\n",
            "  Batch   600  of    764.    Elapsed: 0:02:35.\n",
            "  Batch   640  of    764.    Elapsed: 0:02:45.\n",
            "  Batch   680  of    764.    Elapsed: 0:02:55.\n",
            "  Batch   720  of    764.    Elapsed: 0:03:06.\n",
            "  Batch   760  of    764.    Elapsed: 0:03:16.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:03:17\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:15\n",
            "[{'epoch': 1, 'Training Loss': 0.3598010794796581, 'Training Time': '0:03:17', 'Validation Time': '0:00:15'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    764.    Elapsed: 0:00:21.\n",
            "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    764.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    764.    Elapsed: 0:01:02.\n",
            "  Batch   280  of    764.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    764.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    764.    Elapsed: 0:01:33.\n",
            "  Batch   400  of    764.    Elapsed: 0:01:43.\n",
            "  Batch   440  of    764.    Elapsed: 0:01:53.\n",
            "  Batch   480  of    764.    Elapsed: 0:02:04.\n",
            "  Batch   520  of    764.    Elapsed: 0:02:14.\n",
            "  Batch   560  of    764.    Elapsed: 0:02:24.\n",
            "  Batch   600  of    764.    Elapsed: 0:02:35.\n",
            "  Batch   640  of    764.    Elapsed: 0:02:45.\n",
            "  Batch   680  of    764.    Elapsed: 0:02:55.\n",
            "  Batch   720  of    764.    Elapsed: 0:03:05.\n",
            "  Batch   760  of    764.    Elapsed: 0:03:16.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:03:17\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:15\n",
            "[{'epoch': 1, 'Training Loss': 0.3598010794796581, 'Training Time': '0:03:17', 'Validation Time': '0:00:15'}, {'epoch': 2, 'Training Loss': 0.2846016598112195, 'Training Time': '0:03:17', 'Validation Time': '0:00:15'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    764.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    764.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    764.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    764.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    764.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    764.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    764.    Elapsed: 0:01:42.\n",
            "  Batch   440  of    764.    Elapsed: 0:01:53.\n",
            "  Batch   480  of    764.    Elapsed: 0:02:03.\n",
            "  Batch   520  of    764.    Elapsed: 0:02:13.\n",
            "  Batch   560  of    764.    Elapsed: 0:02:24.\n",
            "  Batch   600  of    764.    Elapsed: 0:02:34.\n",
            "  Batch   640  of    764.    Elapsed: 0:02:44.\n",
            "  Batch   680  of    764.    Elapsed: 0:02:54.\n",
            "  Batch   720  of    764.    Elapsed: 0:03:05.\n",
            "  Batch   760  of    764.    Elapsed: 0:03:15.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:03:16\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:15\n",
            "[{'epoch': 1, 'Training Loss': 0.3598010794796581, 'Training Time': '0:03:17', 'Validation Time': '0:00:15'}, {'epoch': 2, 'Training Loss': 0.2846016598112195, 'Training Time': '0:03:17', 'Validation Time': '0:00:15'}, {'epoch': 3, 'Training Loss': 0.177641931508914, 'Training Time': '0:03:16', 'Validation Time': '0:00:15'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    764.    Elapsed: 0:00:20.\n",
            "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
            "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
            "  Batch   200  of    764.    Elapsed: 0:00:51.\n",
            "  Batch   240  of    764.    Elapsed: 0:01:01.\n",
            "  Batch   280  of    764.    Elapsed: 0:01:12.\n",
            "  Batch   320  of    764.    Elapsed: 0:01:22.\n",
            "  Batch   360  of    764.    Elapsed: 0:01:32.\n",
            "  Batch   400  of    764.    Elapsed: 0:01:42.\n",
            "  Batch   440  of    764.    Elapsed: 0:01:52.\n",
            "  Batch   480  of    764.    Elapsed: 0:02:03.\n",
            "  Batch   520  of    764.    Elapsed: 0:02:13.\n",
            "  Batch   560  of    764.    Elapsed: 0:02:23.\n",
            "  Batch   600  of    764.    Elapsed: 0:02:33.\n",
            "  Batch   640  of    764.    Elapsed: 0:02:44.\n",
            "  Batch   680  of    764.    Elapsed: 0:02:54.\n",
            "  Batch   720  of    764.    Elapsed: 0:03:04.\n",
            "  Batch   760  of    764.    Elapsed: 0:03:14.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:03:15\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:15\n",
            "[{'epoch': 1, 'Training Loss': 0.3598010794796581, 'Training Time': '0:03:17', 'Validation Time': '0:00:15'}, {'epoch': 2, 'Training Loss': 0.2846016598112195, 'Training Time': '0:03:17', 'Validation Time': '0:00:15'}, {'epoch': 3, 'Training Loss': 0.177641931508914, 'Training Time': '0:03:16', 'Validation Time': '0:00:15'}, {'epoch': 4, 'Training Loss': 0.09004351268600914, 'Training Time': '0:03:15', 'Validation Time': '0:00:15'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlAyssNRJ2S"
      },
      "source": [
        "**Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhWwhMUNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "79542988-5b03-4876-fa2b-7f00b8bfe16a"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-171-91155c2a8903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_stats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-150-6f844b95e724>\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(df_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Plot the learning curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valid. Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Label the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54illM8xNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "810f4891-92a5-4a45-fd21-2641a6113325"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0:03:17</td>\n",
              "      <td>0:00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0:03:17</td>\n",
              "      <td>0:00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0:03:16</td>\n",
              "      <td>0:00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.09</td>\n",
              "      <td>0:03:15</td>\n",
              "      <td>0:00:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss Training Time Validation Time\n",
              "epoch                                             \n",
              "1               0.36       0:03:17         0:00:15\n",
              "2               0.28       0:03:17         0:00:15\n",
              "3               0.18       0:03:16         0:00:15\n",
              "4               0.09       0:03:15         0:00:15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnTc0kEYthUm"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_fake, index = test_data.index, columns=['fake'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_test_fake.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jaHtVsc8Bww"
      },
      "source": [
        "torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, 'fake_test.tar')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}