{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model_1c.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyjuPoOPjJq"
      },
      "source": [
        "**Model Specifications**\n",
        "Detect Hate Using indic BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWMvHep3B7C"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOS1Mp42yMw",
        "outputId": "5236ed4c-fcf3-44bc-eb90-3946378cd414"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBBc1EW3F4v"
      },
      "source": [
        "**Required Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPNhzGe3A_-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import ast\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ958U2_3YnT"
      },
      "source": [
        "**Reading Data and Rearranging into DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJalNxA3Xqj"
      },
      "source": [
        "train_file = 'train.csv'\n",
        "val_file = 'val.csv'\n",
        "test_file = 'test.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDH9cHl3fjU"
      },
      "source": [
        "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
        "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
        "non_hostile_val_data = pd.read_csv('y_pred_val_non_hostile.csv', header=0, index_col=0)\n",
        "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
        "train_val_data = train_data.append(val_data, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6tPwxYgijPd"
      },
      "source": [
        "non_hostile_test_data = pd.read_csv('y_pred_test_non_hostile.csv', header=0, index_col=0)\n",
        "val_data_orig = val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Y-IcvgC1DK"
      },
      "source": [
        "train_data.drop(train_data[train_data['Labels Set']=='non-hostile'].index, inplace = True)\n",
        "val_data.drop(non_hostile_val_data[non_hostile_val_data['non-hostile']==1].index, inplace=True)\n",
        "train_val_data.drop(train_val_data[train_val_data['Labels Set']=='non-hostile'].index, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mtwrtNEig5N"
      },
      "source": [
        "test_data.drop(non_hostile_test_data[non_hostile_test_data['non-hostile']==1].index, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "mL-Yczph4Chg",
        "outputId": "0625f002-66a9-4ce6-ac26-48a5331a866f"
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ... Unnamed: 13\n",
              "Unique ID                                                     ...            \n",
              "1          मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "4          @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "6          चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "11         RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "12         RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "nSxggvRQ4EGE",
        "outputId": "1ecbce2a-89be-4049-f084-6a1c50b3bb8c"
      },
      "source": [
        "print(val_data.shape)\n",
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(379, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>defamation</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "2          भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...  ...  भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...\n",
              "8          अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...  ...  अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...\n",
              "13         भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...  ...  भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...\n",
              "14         यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...  ...  दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...\n",
              "15         सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...  ...  सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JHNlD7M44Esg",
        "outputId": "efe789b1-8225-4fc3-d070-714bae095f96"
      },
      "source": [
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(783, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '😂', '👍']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['👇', '😂', '😂', '😂', '😂']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>इन पंचर छापों को कोन समझाए कि उनके रोजगार मे...</td>\n",
              "      <td>पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@BasudebaTripat4:', '@Rajanspsingh1']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अच्छा किया साले का सर फोड़ दिया,, गर्दन तोड़...</td>\n",
              "      <td>अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...  ...  कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...\n",
              "3          कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...  ...  कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...\n",
              "4          अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...  ...  अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।\n",
              "5          RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...  ...  पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...\n",
              "8          @BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...  ...  अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hMC_GwsU8-Sm",
        "outputId": "56412f59-6936-415c-88b6-b8b23b6ebbbf"
      },
      "source": [
        "print(train_val_data.shape)\n",
        "train_val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3054, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Post  ... Unnamed: 13\n",
              "0   मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "3   @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "5   चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "10  RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "11  RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTg69u-b4wDw"
      },
      "source": [
        "**Transforming the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPoz0-5P4IsD"
      },
      "source": [
        "labels_set = {'defamation',\n",
        " 'fake',\n",
        " 'hate',\n",
        " 'non-hostile',\n",
        " 'offensive'}\n",
        "\n",
        "labels_mapping = {'defamation':0,\n",
        " 'fake':1,\n",
        " 'hate':2,\n",
        " 'non-hostile':3,\n",
        " 'offensive':4}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1OzBY4MKF"
      },
      "source": [
        "train_y = np.empty((0, 5))\n",
        "for index, row in train_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_y = np.vstack((train_y, y))\n",
        "\n",
        "\n",
        "val_y = np.empty((0, 5))\n",
        "for index, row in val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  val_y = np.vstack((val_y, y))\n",
        "\n",
        "train_val_y = np.empty((0, 5))\n",
        "for index, row in train_val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_val_y = np.vstack((train_val_y, y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBa01jcE4NWo",
        "outputId": "bf0c68ac-d1c5-4709-a8c8-f8f2cf71a3da"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(train_val_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 5)\n",
            "(379, 5)\n",
            "(3054, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCtXMKS64VT"
      },
      "source": [
        "**Modelling Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AzCgmM40un"
      },
      "source": [
        "def X_process(sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FZSOIJ5Ua2"
      },
      "source": [
        "def train_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    return train_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AFD9Fs5aOw"
      },
      "source": [
        "def val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return validation_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fjVV8d5a5f"
      },
      "source": [
        "def test_load(input_ids, attention_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMF_Pg-9XYn"
      },
      "source": [
        "def train_val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_validation_dataloader = DataLoader(\n",
        "                train_val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return train_validation_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBErql77BAv"
      },
      "source": [
        "def train_fn(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask,\n",
        "                                       labels=b_labels)\n",
        "                loss = state.loss\n",
        "                logits = state.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17SD78fGdXtx"
      },
      "source": [
        "def train_fn_test(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask)\n",
        "                logits = state.logits\n",
        "\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBONPGg77Clo"
      },
      "source": [
        "def stats(training_stats):\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    return df_stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhcuXIG7Dpk"
      },
      "source": [
        "def plot_stats(df_stats):\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evcCcgjA7FTu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MSQH9l7GSm"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHqtP0nElkb"
      },
      "source": [
        "def evaluation(y_true, y_pred):\n",
        "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEu7-vTNxst"
      },
      "source": [
        "\n",
        "**Training for Hate Class (Using Train Data and Val Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxBtbX61Nxsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7dada3b-53fa-4a6f-9d63-72d26d2a960f"
      },
      "source": [
        "MODEL_NAME = 'ai4bharat/indic-bert'\n",
        "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(26)\n",
        "np.random.seed(26)\n",
        "torch.manual_seed(26)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device) # Send the model to the GPU if we have one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'sop_classifier.classifier.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForSequenceClassification(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (attention_dropout): Dropout(p=0, inplace=False)\n",
              "                (output_dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UumXdB9Nxsx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Nr_05qNxsy"
      },
      "source": [
        "**TODO: Tryout different batchsize and length (80, 100)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2RNGhpNxsy"
      },
      "source": [
        "batch_size = 4\n",
        "max_length = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPL2bLLvOWzr"
      },
      "source": [
        "# train_sentences = train_data['Filtered_Post'].values\n",
        "# val_sentences = val_data['Filtered_Post'].values\n",
        "# test_sentences = test_data['Filtered_Post'].values\n",
        "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
        "\n",
        "train_sentences = train_data['Post'].values\n",
        "val_sentences = val_data['Post'].values\n",
        "test_sentences = test_data['Post'].values\n",
        "train_val_sentences = train_val_data['Post'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbgOIjuQffx"
      },
      "source": [
        "y_train_hate = train_y[:,2].astype(int)\n",
        "y_val_hate = val_y[:,2].astype(int)\n",
        "y_train_val_hate = train_val_y[:,2].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzuEr8LedH7Y"
      },
      "source": [
        "train_labels_hate = y_train_hate\n",
        "val_labels_hate = y_val_hate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8t3Bc3Nxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7edd6070-c68d-4f06-a05a-89e04a1109d9"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_sentences)\n",
        "train_dataloader = train_load(input_ids, attention_masks, train_labels_hate)\n",
        "\n",
        "input_ids, attention_masks = X_process(val_sentences)\n",
        "validation_dataloader = val_load(input_ids, attention_masks, val_labels_hate)\n",
        "\n",
        "input_ids, attention_masks = X_process(test_sentences)\n",
        "test_dataloader = test_load(input_ids, attention_masks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2p6AI3Nxsy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JzyqSFNxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0890e6c4-82ab-4b96-f947-dede6f4bed2e"
      },
      "source": [
        "training_stats, y_pred_val_hate = train_fn(train_dataloader, validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:55.\n",
            "  Batch   320  of    335.    Elapsed: 0:03:21.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:03:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:11\n",
            "[{'epoch': 1, 'Training Loss': 0.609149102221674, 'Valid. Loss': 0.5871751209100088, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:30', 'Validation Time': '0:00:11'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:06.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:31.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:56.\n",
            "  Batch   320  of    335.    Elapsed: 0:03:21.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epcoh took: 0:03:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:11\n",
            "[{'epoch': 1, 'Training Loss': 0.609149102221674, 'Valid. Loss': 0.5871751209100088, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:30', 'Validation Time': '0:00:11'}, {'epoch': 2, 'Training Loss': 0.597883953976987, 'Valid. Loss': 0.5862720993657907, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:30', 'Validation Time': '0:00:11'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:41.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:06.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:31.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:57.\n",
            "  Batch   320  of    335.    Elapsed: 0:03:22.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:03:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:11\n",
            "[{'epoch': 1, 'Training Loss': 0.609149102221674, 'Valid. Loss': 0.5871751209100088, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:30', 'Validation Time': '0:00:11'}, {'epoch': 2, 'Training Loss': 0.597883953976987, 'Valid. Loss': 0.5862720993657907, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:30', 'Validation Time': '0:00:11'}, {'epoch': 3, 'Training Loss': 0.5874049700462997, 'Valid. Loss': 0.5726200565695763, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:32', 'Validation Time': '0:00:11'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:16.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:41.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:07.\n",
            "  Batch   240  of    335.    Elapsed: 0:02:32.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:58.\n",
            "  Batch   320  of    335.    Elapsed: 0:03:23.\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epcoh took: 0:03:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.56\n",
            "  Validation took: 0:00:11\n",
            "[{'epoch': 1, 'Training Loss': 0.609149102221674, 'Valid. Loss': 0.5871751209100088, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:30', 'Validation Time': '0:00:11'}, {'epoch': 2, 'Training Loss': 0.597883953976987, 'Valid. Loss': 0.5862720993657907, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:30', 'Validation Time': '0:00:11'}, {'epoch': 3, 'Training Loss': 0.5874049700462997, 'Valid. Loss': 0.5726200565695763, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:32', 'Validation Time': '0:00:11'}, {'epoch': 4, 'Training Loss': 0.5580819265611137, 'Valid. Loss': 0.5638356332977613, 'Valid. Accur.': 0.7118055555555555, 'Training Time': '0:03:33', 'Validation Time': '0:00:11'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoV30azNxsz"
      },
      "source": [
        "**Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvWJNE7YNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "320feb8d-52dc-42d3-d3cf-2bb7150e6a72"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZ4Tx8PNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7c4911bb-9098-47a6-9ea1-fe6117660452"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.61</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0:03:30</td>\n",
              "      <td>0:00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0:03:30</td>\n",
              "      <td>0:00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0:03:32</td>\n",
              "      <td>0:00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0:03:33</td>\n",
              "      <td>0:00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.61         0.59           0.71       0:03:30         0:00:11\n",
              "2               0.60         0.59           0.71       0:03:30         0:00:11\n",
              "3               0.59         0.57           0.71       0:03:32         0:00:11\n",
              "4               0.56         0.56           0.71       0:03:33         0:00:11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrRQFllONxsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a73629-a696-491f-acb4-cb15a1a935aa"
      },
      "source": [
        "evaluation(y_val_hate, y_pred_val_hate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine Grained Accuracy = 0.712401055408971\n",
            "\n",
            "\n",
            "Fine Grained Metrics\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83       270\n",
            "           1       0.00      0.00      0.00       109\n",
            "\n",
            "    accuracy                           0.71       379\n",
            "   macro avg       0.36      0.50      0.42       379\n",
            "weighted avg       0.51      0.71      0.59       379\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHgr-fodo8e"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_val_hate, index = val_data.index, columns=['hate'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_val_hate.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HWdCRDNxs0"
      },
      "source": [
        "**Training for Hate Class (Using Train +Val Data and Test Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwvcdNspi294"
      },
      "source": [
        "train_val_labels_hate = y_train_val_hate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-RaRs7Nxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebe5e34-94df-49ed-8be7-748ec902c858"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_val_sentences)\n",
        "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_hate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wfwVeBNxs0"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_val_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmjATAqNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3965e3e0-750b-4707-f913-3ac3cf35824f"
      },
      "source": [
        "training_stats, y_pred_hate = train_fn_test(train_val_dataloader, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:16.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:42.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:07.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:33.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:58.\n",
            "  Batch   320  of    382.    Elapsed: 0:03:24.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:49.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:04:03\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:23\n",
            "[{'epoch': 1, 'Training Loss': 0.5717827705032539, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:16.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:42.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:07.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:33.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:58.\n",
            "  Batch   320  of    382.    Elapsed: 0:03:24.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:49.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:04:03\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:23\n",
            "[{'epoch': 1, 'Training Loss': 0.5717827705032539, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}, {'epoch': 2, 'Training Loss': 0.5937109512535377, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:16.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:42.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:07.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:33.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:58.\n",
            "  Batch   320  of    382.    Elapsed: 0:03:24.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:49.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:04:03\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:23\n",
            "[{'epoch': 1, 'Training Loss': 0.5717827705032539, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}, {'epoch': 2, 'Training Loss': 0.5937109512535377, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}, {'epoch': 3, 'Training Loss': 0.5515607326481667, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:51.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:16.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:42.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:07.\n",
            "  Batch   240  of    382.    Elapsed: 0:02:33.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:58.\n",
            "  Batch   320  of    382.    Elapsed: 0:03:24.\n",
            "  Batch   360  of    382.    Elapsed: 0:03:49.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:04:03\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:23\n",
            "[{'epoch': 1, 'Training Loss': 0.5717827705032539, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}, {'epoch': 2, 'Training Loss': 0.5937109512535377, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}, {'epoch': 3, 'Training Loss': 0.5515607326481667, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}, {'epoch': 4, 'Training Loss': 0.5113178030319551, 'Training Time': '0:04:03', 'Validation Time': '0:00:23'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlAyssNRJ2S"
      },
      "source": [
        "**Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhWwhMUNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "a87abf04-1410-4975-8207-b3bd287099f6"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-91155c2a8903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_stats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-77-6f844b95e724>\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(df_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Plot the learning curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valid. Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Label the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54illM8xNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "11eb2fb5-aac6-4e12-bf07-42496368b6a0"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0:04:03</td>\n",
              "      <td>0:00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0:04:03</td>\n",
              "      <td>0:00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0:04:03</td>\n",
              "      <td>0:00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0:04:03</td>\n",
              "      <td>0:00:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss Training Time Validation Time\n",
              "epoch                                             \n",
              "1               0.57       0:04:03         0:00:23\n",
              "2               0.59       0:04:03         0:00:23\n",
              "3               0.55       0:04:03         0:00:23\n",
              "4               0.51       0:04:03         0:00:23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amqNhvhitcLw"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_hate, index = test_data.index, columns=['hate'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_test_hate.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXWnp_AW_HDo"
      },
      "source": [
        "torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, 'hate_test.tar')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
