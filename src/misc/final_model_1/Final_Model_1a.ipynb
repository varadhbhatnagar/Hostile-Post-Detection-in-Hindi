{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxyjuPoOPjJq"
   },
   "source": [
    "**Model Specifications**\n",
    "Detect Non Hostile Using verloop Bert -> Detect Fake Using verloop Bert ->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCWMvHep3B7C"
   },
   "source": [
    "**Installing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlOS1Mp42yMw",
    "outputId": "c91a3925-d6da-4900-f6a4-bf5cc3dab65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMBBc1EW3F4v"
   },
   "source": [
    "**Required Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aPNhzGe3A_-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import ast\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ958U2_3YnT"
   },
   "source": [
    "**Reading Data and Rearranging into DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWJalNxA3Xqj"
   },
   "outputs": [],
   "source": [
    "train_file = 'train.csv'\n",
    "val_file = 'val.csv'\n",
    "test_file = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woDH9cHl3fjU"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
    "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
    "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
    "train_val_data = train_data.append(val_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "mL-Yczph4Chg",
    "outputId": "0a42b4d1-ad6c-4e6c-96fd-9729619f41c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5727, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>hate,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üôè', 'üôè']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/8iy2MJSBAs']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
       "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡§Æ‡§æ‡§à ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§®‡§à-‡§®‡§à ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡•á‡§Ç ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/G945HvzM0Z', 'https://t.co/KfH7...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['LIVE']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
       "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§•‡•Ä, ‡§°‡•Ä‡§≤ ‡§¶‡•Ä‡§™‡•á‡§∂ ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§π...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
       "      <td>defamation,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@prabhav218']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/4e6lysg0VR']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['unlock4guidelines']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä\\n\\n- 7 ‡§∏‡§ø‡§§‡§Ç‡§¨...</td>\n",
       "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä - 7 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§¶‡•á‡§∂‡§≠‡§∞ ‡§Æ‡•á‡§ü...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Post  ... Unnamed: 13\n",
       "Unique ID                                                     ...            \n",
       "1          ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
       "2          ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...  ...         NaN\n",
       "3          ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...  ...         NaN\n",
       "4          @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
       "5          #unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...  ...         NaN\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "nSxggvRQ4EGE",
    "outputId": "090eeae8-268d-496b-a246-3f13d95b4411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(811, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§∏‡•á ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•á...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§∏‡•á ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•á...</td>\n",
       "      <td>‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§¶‡•á‡§∂‡§π‡§ø‡§§ ‡§∏‡§∞‡•ç‡§µ‡•ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
       "      <td>defamation</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•á‡§Ç 10 ‡§π‡§ú‡§æ...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/9rlQowAsFh']</td>\n",
       "      <td>['@ArvindKejriwal', '@rajnathsingh', '@AmitSha...</td>\n",
       "      <td>['Delhi']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•á‡§Ç 10 ‡§π‡§ú‡§æ...</td>\n",
       "      <td>‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä 10 ‡§π‡§ú‡§æ‡§∞ ‡§¨‡•á‡§° ‡§µ‡§æ‡§≤‡§æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ ‡§Æ‡•á‡§Ç PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/ZvKgxk6dbd']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ ‡§Æ‡•á‡§Ç PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§...</td>\n",
       "      <td>‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø ‡§∏‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ ‡§Æ‡•á‡§Ç Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§µ ‡§∏‡§ö‡§ø‡§µ...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/hxM1uNNmX2']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['UP']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ ‡§Æ‡•á‡§Ç Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§µ ‡§∏‡§ö‡§ø‡§µ...</td>\n",
       "      <td>‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§∏‡§ö‡§ø‡§µ ‡§≤‡§æ‡§ñ‡•ã‡§Ç...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
       "Unique ID                                                     ...                                                   \n",
       "1          ‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§∏‡•á ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•á...  ...  ‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§¶‡•á‡§∂‡§π‡§ø‡§§ ‡§∏‡§∞‡•ç‡§µ‡•ã...\n",
       "2          ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...  ...  ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...\n",
       "3          ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•á‡§Ç 10 ‡§π‡§ú‡§æ...  ...  ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä 10 ‡§π‡§ú‡§æ‡§∞ ‡§¨‡•á‡§° ‡§µ‡§æ‡§≤‡§æ...\n",
       "4          ‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ ‡§Æ‡•á‡§Ç PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§...  ...  ‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø ‡§∏‡§∞...\n",
       "5          ‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ ‡§Æ‡•á‡§Ç Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§µ ‡§∏‡§ö‡§ø‡§µ...  ...  ‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§∏‡§ö‡§ø‡§µ ‡§≤‡§æ‡§ñ‡•ã‡§Ç...\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_data.shape)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "JHNlD7M44Esg",
    "outputId": "4ee2a17a-7100-45c7-a1d8-94b39452d65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1653, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
       "      <td>‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§®‡•á...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/Dq05hREifM']</td>\n",
       "      <td>['@kumarprakash4u']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§®‡•á...</td>\n",
       "      <td>‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§ó‡•ã‡§≤‡•Ä ‡§Æ‡§æ‡§∞‡§ï...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üôè', 'üòÇ', 'üëç']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
       "      <td>‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
       "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@_Pb_swain_:']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üëá', 'üòÇ', 'üòÇ', 'üòÇ', 'üòÇ']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['RT']</td>\n",
       "      <td>‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡•á...</td>\n",
       "      <td>‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
       "Unique ID                                                     ...                                                   \n",
       "1          ‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...  ...  ‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...\n",
       "2          ‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§®‡•á...  ...  ‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§ó‡•ã‡§≤‡•Ä ‡§Æ‡§æ‡§∞‡§ï...\n",
       "3          ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...  ...  ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...\n",
       "4          ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...  ...  ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§\n",
       "5          RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...  ...  ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "hMC_GwsU8-Sm",
    "outputId": "998084fb-5477-417f-f98e-cbf3670379e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6538, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>hate,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üôè', 'üôè']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/8iy2MJSBAs']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
       "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡§Æ‡§æ‡§à ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§®‡§à-‡§®‡§à ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡•á‡§Ç ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/G945HvzM0Z', 'https://t.co/KfH7...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['LIVE']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
       "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§•‡•Ä, ‡§°‡•Ä‡§≤ ‡§¶‡•Ä‡§™‡•á‡§∂ ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§π...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
       "      <td>defamation,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@prabhav218']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/4e6lysg0VR']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['unlock4guidelines']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä\\n\\n- 7 ‡§∏‡§ø‡§§‡§Ç‡§¨...</td>\n",
       "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä - 7 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§¶‡•á‡§∂‡§≠‡§∞ ‡§Æ‡•á‡§ü...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Post  ... Unnamed: 13\n",
       "0  ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
       "1  ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...  ...         NaN\n",
       "2  ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...  ...         NaN\n",
       "3  @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
       "4  #unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...  ...         NaN\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_val_data.shape)\n",
    "train_val_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTg69u-b4wDw"
   },
   "source": [
    "**Transforming the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPoz0-5P4IsD"
   },
   "outputs": [],
   "source": [
    "labels_set = {'defamation',\n",
    " 'fake',\n",
    " 'hate',\n",
    " 'non-hostile',\n",
    " 'offensive'}\n",
    "\n",
    "labels_mapping = {'defamation':0,\n",
    " 'fake':1,\n",
    " 'hate':2,\n",
    " 'non-hostile':3,\n",
    " 'offensive':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1e1OzBY4MKF"
   },
   "outputs": [],
   "source": [
    "train_y = np.empty((0, 5))\n",
    "for index, row in train_data.iterrows():\n",
    "  y = np.zeros((1, 5))\n",
    "  for label in row['Labels Set'].split(','):\n",
    "    y[0, labels_mapping[label]] = 1\n",
    "\n",
    "  train_y = np.vstack((train_y, y))\n",
    "\n",
    "\n",
    "val_y = np.empty((0, 5))\n",
    "for index, row in val_data.iterrows():\n",
    "  y = np.zeros((1, 5))\n",
    "  for label in row['Labels Set'].split(','):\n",
    "    y[0, labels_mapping[label]] = 1\n",
    "\n",
    "  val_y = np.vstack((val_y, y))\n",
    "\n",
    "train_val_y = np.vstack((train_y, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBa01jcE4NWo",
    "outputId": "7617abbb-86e7-4c89-e2ab-74e22442775e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5727, 5)\n",
      "(811, 5)\n",
      "(6538, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(val_y.shape)\n",
    "print(train_val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aL98-Vi5wyt"
   },
   "outputs": [],
   "source": [
    "y_train_non_hostile = train_y[:,3].astype(int)\n",
    "y_val_non_hostile = val_y[:,3].astype(int)\n",
    "y_train_val_non_hostile = train_val_y[:,3].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWHaIm146GRw"
   },
   "source": [
    "**Results using different levels of filtering** \n",
    "1. Original Data (97% f1 score with 4 epochs)\n",
    "2. Filtered Data (91% f1 score with 4 epochs)\n",
    "3. Stopword removed Filterd Data (91% f1 score with 4 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZ6H2Bmk6BWP"
   },
   "outputs": [],
   "source": [
    "# train_sentences = train_data['Filtered_Post'].values\n",
    "# val_sentences = val_data['Filtered_Post'].values\n",
    "# test_sentences = test_data['Filtered_Post'].values\n",
    "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
    "\n",
    "train_sentences = train_data['Post'].values\n",
    "val_sentences = val_data['Post'].values\n",
    "test_sentences = test_data['Post'].values\n",
    "train_val_sentences = train_val_data['Post'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvCtXMKS64VT"
   },
   "source": [
    "**Modelling Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34AzCgmM40un"
   },
   "outputs": [],
   "source": [
    "def X_process(sentences):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_length,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    return input_ids, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4FZSOIJ5Ua2"
   },
   "outputs": [],
   "source": [
    "def train_load(input_ids, attention_masks, labels):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,  # The training samples.\n",
    "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
    "                batch_size = batch_size # Trains with this batch size.\n",
    "            )\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1AFD9Fs5aOw"
   },
   "outputs": [],
   "source": [
    "def val_load(input_ids, attention_masks, labels):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_dataset, # The validation samples.\n",
    "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    \n",
    "    return validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_fjVV8d5a5f"
   },
   "outputs": [],
   "source": [
    "def test_load(input_ids, attention_masks):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
    "    test_dataloader = DataLoader(\n",
    "                test_dataset, # The validation samples.\n",
    "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    \n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvMF_Pg-9XYn"
   },
   "outputs": [],
   "source": [
    "def train_val_load(input_ids, attention_masks, labels):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_validation_dataloader = DataLoader(\n",
    "                train_val_dataset, # The validation samples.\n",
    "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    \n",
    "    return train_validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRBErql77BAv"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_dataloader, validation_dataloader):\n",
    "    \n",
    "    seed_val = 42\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every 40 batches.\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "            # `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Always clear any previously calculated gradients before performing a\n",
    "            # backward pass. PyTorch doesn't do this automatically because \n",
    "            # accumulating the gradients is \"convenient while training RNNs\". \n",
    "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "            model.zero_grad()        \n",
    "\n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            state = model(b_input_ids, \n",
    "                                 token_type_ids=None, \n",
    "                                 attention_mask=b_input_mask, \n",
    "                                 labels=b_labels)\n",
    "            loss = state.loss\n",
    "            logits = state.logits\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can\n",
    "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "            # single value; the `.item()` function just returns the Python value \n",
    "            # from the tensor.\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "            # modified based on their gradients, the learning rate, etc.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        y_pred_val = []\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                state = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       attention_mask=b_input_mask,\n",
    "                                       labels=b_labels)\n",
    "                loss = state.loss\n",
    "                logits = state.logits\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            \n",
    "#             labels = label_ids\n",
    "            preds = logits\n",
    "            \n",
    "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#             labels_flat = labels.flatten()\n",
    "#             y_true.extend(labels_flat)\n",
    "            y_pred_val.extend(pred_flat)\n",
    "\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        print(training_stats)\n",
    "        \n",
    "    return training_stats, y_pred_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKn1eKZFaMsQ"
   },
   "outputs": [],
   "source": [
    "def train_fn_test(train_dataloader, validation_dataloader):\n",
    "    \n",
    "    seed_val = 42\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every 40 batches.\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "            # `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Always clear any previously calculated gradients before performing a\n",
    "            # backward pass. PyTorch doesn't do this automatically because \n",
    "            # accumulating the gradients is \"convenient while training RNNs\". \n",
    "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "            model.zero_grad()        \n",
    "\n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            state = model(b_input_ids, \n",
    "                                 token_type_ids=None, \n",
    "                                 attention_mask=b_input_mask, \n",
    "                                 labels=b_labels)\n",
    "            loss = state.loss\n",
    "            logits = state.logits\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can\n",
    "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "            # single value; the `.item()` function just returns the Python value \n",
    "            # from the tensor.\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "            # modified based on their gradients, the learning rate, etc.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        y_pred_val = []\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                state = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       attention_mask=b_input_mask)\n",
    "                logits = state.logits\n",
    "\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            \n",
    "#             labels = label_ids\n",
    "            preds = logits\n",
    "            \n",
    "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#             labels_flat = labels.flatten()\n",
    "#             y_true.extend(labels_flat)\n",
    "            y_pred_val.extend(pred_flat)\n",
    "\n",
    "\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        print(training_stats)\n",
    "        \n",
    "    return training_stats, y_pred_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBONPGg77Clo"
   },
   "outputs": [],
   "source": [
    "def stats(training_stats):\n",
    "    pd.set_option('precision', 2)\n",
    "\n",
    "    # Create a DataFrame from our training statistics.\n",
    "    df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "    # Use the 'epoch' as the row index.\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "    # A hack to force the column headers to wrap.\n",
    "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "    # Display the table.\n",
    "    return df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwhcuXIG7Dpk"
   },
   "outputs": [],
   "source": [
    "def plot_stats(df_stats):\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "    # Plot the learning curve.\n",
    "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "    # Label the plot.\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evcCcgjA7FTu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57MSQH9l7GSm"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaHqtP0nElkb"
   },
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred):\n",
    "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
    "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
    "  print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXD8myPu4bsE"
   },
   "source": [
    "**Training for Non Hostile Class (Using Train Data and Val Data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwYMVP0b4d7q",
    "outputId": "e3485952-4e61-4c79-ffbd-84286bed0baf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
    "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.to(device) # Send the model to the GPU if we have one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihIQJe4H4n6Z"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqBM-STd7kgd"
   },
   "source": [
    "**TODO: Tryout different batchsize and length (80, 100)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aS8h43pH4ptH"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BEIQPiC7NWt"
   },
   "outputs": [],
   "source": [
    "train_labels_non_hostile = y_train_non_hostile\n",
    "val_labels_non_hostile = y_val_non_hostile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxuUUWlN7Tka",
    "outputId": "05b16919-b34c-4d91-c706-aa4dda0a873b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = X_process(train_sentences)\n",
    "train_dataloader = train_load(input_ids, attention_masks, train_labels_non_hostile)\n",
    "\n",
    "input_ids, attention_masks = X_process(val_sentences)\n",
    "validation_dataloader = val_load(input_ids, attention_masks, val_labels_non_hostile)\n",
    "\n",
    "input_ids, attention_masks = X_process(test_sentences)\n",
    "test_dataloader = test_load(input_ids, attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4zE18ua79Gc"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tq2sv8GZ8Byy",
    "outputId": "d0951d31-f09a-4794-fef9-a8b29506c6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    179.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    179.    Elapsed: 0:01:58.\n",
      "  Batch   120  of    179.    Elapsed: 0:02:57.\n",
      "  Batch   160  of    179.    Elapsed: 0:03:56.\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:04:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation Loss: 0.14\n",
      "  Validation took: 0:00:14\n",
      "[{'epoch': 1, 'Training Loss': 0.20472170661760275, 'Valid. Loss': 0.1404637097595976, 'Valid. Accur.': 0.9424169580419581, 'Training Time': '0:04:24', 'Validation Time': '0:00:14'}]\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    179.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    179.    Elapsed: 0:01:58.\n",
      "  Batch   120  of    179.    Elapsed: 0:02:57.\n",
      "  Batch   160  of    179.    Elapsed: 0:03:55.\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.11\n",
      "  Validation took: 0:00:14\n",
      "[{'epoch': 1, 'Training Loss': 0.20472170661760275, 'Valid. Loss': 0.1404637097595976, 'Valid. Accur.': 0.9424169580419581, 'Training Time': '0:04:24', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.10455956593592906, 'Valid. Loss': 0.11005260902815141, 'Valid. Accur.': 0.9652534965034966, 'Training Time': '0:04:23', 'Validation Time': '0:00:14'}]\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    179.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    179.    Elapsed: 0:01:58.\n",
      "  Batch   120  of    179.    Elapsed: 0:02:57.\n",
      "  Batch   160  of    179.    Elapsed: 0:03:55.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.09\n",
      "  Validation took: 0:00:14\n",
      "[{'epoch': 1, 'Training Loss': 0.20472170661760275, 'Valid. Loss': 0.1404637097595976, 'Valid. Accur.': 0.9424169580419581, 'Training Time': '0:04:24', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.10455956593592906, 'Valid. Loss': 0.11005260902815141, 'Valid. Accur.': 0.9652534965034966, 'Training Time': '0:04:23', 'Validation Time': '0:00:14'}, {'epoch': 3, 'Training Loss': 0.0738357853940454, 'Valid. Loss': 0.09083796802979822, 'Valid. Accur.': 0.9699519230769231, 'Training Time': '0:04:23', 'Validation Time': '0:00:14'}]\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    179.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    179.    Elapsed: 0:01:58.\n",
      "  Batch   120  of    179.    Elapsed: 0:02:56.\n",
      "  Batch   160  of    179.    Elapsed: 0:03:55.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:04:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.12\n",
      "  Validation took: 0:00:14\n",
      "[{'epoch': 1, 'Training Loss': 0.20472170661760275, 'Valid. Loss': 0.1404637097595976, 'Valid. Accur.': 0.9424169580419581, 'Training Time': '0:04:24', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.10455956593592906, 'Valid. Loss': 0.11005260902815141, 'Valid. Accur.': 0.9652534965034966, 'Training Time': '0:04:23', 'Validation Time': '0:00:14'}, {'epoch': 3, 'Training Loss': 0.0738357853940454, 'Valid. Loss': 0.09083796802979822, 'Valid. Accur.': 0.9699519230769231, 'Training Time': '0:04:23', 'Validation Time': '0:00:14'}, {'epoch': 4, 'Training Loss': 0.04186624958825053, 'Valid. Loss': 0.12158251817051607, 'Valid. Accur.': 0.9676573426573427, 'Training Time': '0:04:23', 'Validation Time': '0:00:14'}]\n"
     ]
    }
   ],
   "source": [
    "training_stats, y_pred_val_non_hostile = train_fn(train_dataloader, validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVZcJgJo8EXS"
   },
   "source": [
    "**Evaluation on Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "h2lRXn3a8HAH",
    "outputId": "5d1d6028-b0f6-4682-e765-5bf153d27a40"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd0CUx7oG8GcXtkgXBEGwohRpAsYSSVRURMWGKEZFjYkttqMxUaPeGM8xRU2wRU8sSQxWQOxoVCzRxGhEBQtYsEREiihdWGD3/uFh4wroAgsL+Pz+uZfZ75t5d2VO3h3eb0agUCgUICIiIiKiOkGo7QCIiIiIiEh9TOCJiIiIiOoQJvBERERERHUIE3giIiIiojqECTwRERERUR3CBJ6IiIiIqA5hAk9Eb7zExETY29tj9erVle5j7ty5sLe312BU9Vd5n7e9vT3mzp2rVh+rV6+Gvb09EhMTNR5fREQE7O3tce7cOY33TUSkCbraDoCI6GUVSYSjoqJgY2NTjdHUPXl5efjvf/+LyMhIpKamwtTUFJ6envjoo49ga2urVh/Tp0/Hr7/+ij179sDR0bHMaxQKBXr06IGsrCycOXMGUqlUk2+jWp07dw7nz5/HmDFjYGRkpO1wSklMTESPHj0wcuRI/N///Z+2wyGiWoYJPBHVOkuXLlX5OTo6Gjt37kRgYCA8PT1VXjM1Na3yeNbW1oiNjYWOjk6l+/j3v/+NL774osqxaMKCBQtw8OBB+Pn5oUOHDkhLS8Px48cRExOjdgIfEBCAX3/9Fbt27cKCBQvKvObPP//Ew4cPERgYqJHkPTY2FkJhzfxh+Pz581izZg0GDx5cKoEfOHAg+vXrB5FIVCOxEBFVFBN4Iqp1Bg4cqPJzcXExdu7ciXbt2pV67WU5OTkwMDCo0HgCgQASiaTCcb6otiR7z549w+HDh+Hl5YVvv/1W2T516lTIZDK1+/Hy8oKVlRX279+PTz/9FGKxuNQ1ERERAJ4n+5pQ1X8DTdHR0anSlzkiourGGngiqrO8vb0RFBSE69ev44MPPoCnpycGDBgA4HkiHxwcjKFDh6Jjx45wdnZGr169sHz5cjx79kyln7Jqsl9sO3HiBIYMGQIXFxd4eXnhm2++QVFRkUofZdXAl7RlZ2fj888/R+fOneHi4oLhw4cjJiam1Pt5+vQp5s2bh44dO8Ld3R2jR4/G9evXERQUBG9vb7U+E4FAAIFAUOYXirKS8PIIhUIMHjwYGRkZOH78eKnXc3JycOTIEdjZ2cHV1bVCn3d5yqqBl8vl+OGHH+Dt7Q0XFxf4+flh3759Zd6fkJCARYsWoV+/fnB3d4ebmxv8/f0RFhamct3cuXOxZs0aAECPHj1gb2+v8u9fXg38kydP8MUXX6Br165wdnZG165d8cUXX+Dp06cq15Xcf/bsWWzatAk9e/aEs7Mzevfujd27d6v1WVREfHw8pkyZgo4dO8LFxQV9+/bFhg0bUFxcrHLdo0ePMG/ePHTv3h3Ozs7o3Lkzhg8frhKTXC7Hzz//jP79+8Pd3R0eHh7o3bs3PvvsMxQWFmo8diKqHK7AE1GdlpSUhDFjxsDX1xc+Pj7Iy8sDAKSkpCA8PBw+Pj7w8/ODrq4uzp8/j40bNyIuLg6bNm1Sq/9Tp05h27ZtGD58OIYMGYKoqCj8+OOPMDY2xqRJk9Tq44MPPoCpqSmmTJmCjIwM/PTTT5gwYQKioqKUfy2QyWR4//33ERcXB39/f7i4uODGjRt4//33YWxsrPbnIZVKMWjQIOzatQsHDhyAn5+f2ve+zN/fH+vWrUNERAR8fX1VXjt48CDy8/MxZMgQAJr7vF/21Vdf4ZdffsFbb72FsWPHIj09HYsXL0bTpk1LXXv+/HlcuHAB3bp1g42NjfKvEQsWLMCTJ08wceJEAEBgYCBycnJw9OhRzJs3Dw0bNgTw6mcvsrOz8d577+H+/fsYMmQI2rZti7i4OGzfvh1//vknwsLCSv3lJzg4GPn5+QgMDIRYLMb27dsxd+5cNGvWrFQpWGVduXIFQUFB0NXVxciRI9GoUSOcOHECy5cvR3x8vPKvMEVFRXj//feRkpKCESNGoEWLFsjJycGNGzdw4cIFDB48GACwbt06rFq1Ct27d8fw4cOho6ODxMREHD9+HDKZrNb8pYnojacgIqrldu3apbCzs1Ps2rVLpb179+4KOzs7RWhoaKl7CgoKFDKZrFR7cHCwws7OThETE6Nse/DggcLOzk6xatWqUm1ubm6KBw8eKNvlcrmiX79+ii5duqj0O2fOHIWdnV2ZbZ9//rlKe2RkpMLOzk6xfft2ZduWLVsUdnZ2irVr16pcW9LevXv3Uu+lLNnZ2Yrx48crnJ2dFW3btlUcPHhQrfvKM3r0aIWjo6MiJSVFpX3YsGEKJycnRXp6ukKhqPrnrVAoFHZ2doo5c+Yof05ISFDY29srRo8erSgqKlK2X716VWFvb6+ws7NT+bfJzc0tNX5xcbFi1KhRCg8PD5X4Vq1aVer+EiW/b3/++aey7bvvvlPY2dkptmzZonJtyb9PcHBwqfsHDhyoKCgoULYnJycrnJycFDNnziw15stKPqMvvvjildcFBgYqHB0dFXFxcco2uVyumD59usLOzk7xxx9/KBQKhSIuLk5hZ2enWL9+/Sv7GzRokKJPnz6vjY+ItIslNERUp5mYmMDf379Uu1gsVq4WFhUVITMzE0+ePMHbb78NAGWWsJSlR48eKrvcCAQCdOzYEWlpacjNzVWrj7Fjx6r83KlTJwDA/fv3lW0nTpyAjo4ORo8erXLt0KFDYWhoqNY4crkcM2bMQHx8PA4dOoR3330Xs2fPxv79+1WuW7hwIZycnNSqiQ8ICEBxcTH27NmjbEtISMDly5fh7e2tfIhYU5/3i6KioqBQKPD++++r1KQ7OTmhS5cupa7X09NT/v8FBQV4+vQpMjIy0KVLF+Tk5ODOnTsVjqHE0aNHYWpqisDAQJX2wMBAmJqa4tixY6XuGTFihErZUuPGjdGyZUvcu3ev0nG8KD09HZcuXYK3tzccHByU7QKBAJMnT1bGDUD5O3Tu3Dmkp6eX26eBgQFSUlJw4cIFjcRIRNWDJTREVKc1bdq03AcOt27dih07duD27duQy+Uqr2VmZqrd/8tMTEwAABkZGdDX169wHyUlGxkZGcq2xMREWFhYlOpPLBbDxsYGWVlZrx0nKioKZ86cwbJly2BjY4OVK1di6tSp+PTTT1FUVKQsk7hx4wZcXFzUqon38fGBkZERIiIiMGHCBADArl27AEBZPlNCE5/3ix48eAAAaNWqVanXbG1tcebMGZW23NxcrFmzBocOHcKjR49K3aPOZ1iexMREODs7Q1dX9T+burq6aNGiBa5fv17qnvJ+dx4+fFjpOF6OCQBat25d6rVWrVpBKBQqP0Nra2tMmjQJ69evh5eXFxwdHdGpUyf4+vrC1dVVed+sWbMwZcoUjBw5EhYWFujQoQO6deuG3r17V+gZCiKqXkzgiahOa9CgQZntP/30E77++mt4eXlh9OjRsLCwgEgkQkpKCubOnQuFQqFW/6/ajaSqfah7v7pKHrp86623ADxP/tesWYPJkydj3rx5KCoqgoODA2JiYrBkyRK1+pRIJPDz88O2bdtw8eJFuLm5Yd++fbC0tMQ777yjvE5Tn3dVfPzxxzh58iSGDRuGt956CyYmJtDR0cGpU6fw888/l/pSUd1qaktMdc2cORMBAQE4efIkLly4gPDwcGzatAkffvghPvnkEwCAu7s7jh49ijNnzuDcuXM4d+4cDhw4gHXr1mHbtm3KL69EpF1M4ImoXtq7dy+sra2xYcMGlUTqt99+02JU5bO2tsbZs2eRm5ursgpfWFiIxMREtQ4bKnmfDx8+hJWVFYDnSfzatWsxadIkLFy4ENbW1rCzs8OgQYPUji0gIADbtm1DREQEMjMzkZaWhkmTJql8rtXxeZesYN+5cwfNmjVTeS0hIUHl56ysLJw8eRIDBw7E4sWLVV77448/SvUtEAgqHMvdu3dRVFSksgpfVFSEe/fulbnaXt1KSrtu375d6rU7d+5ALpeXiqtp06YICgpCUFAQCgoK8MEHH2Djxo0YN24czMzMAAD6+vro3bs3evfuDeD5X1YWL16M8PBwfPjhh9X8rohIHbVreYCISEOEQiEEAoHKym9RURE2bNigxajK5+3tjeLiYvzyyy8q7aGhocjOzlarj65duwJ4vvvJi/XtEokE3333HYyMjJCYmIjevXuXKgV5FScnJzg6OiIyMhJbt26FQCAotfd7dXze3t7eEAgE+Omnn1S2RLx27VqppLzkS8PLK/2pqamltpEE/qmXV7e0p2fPnnjy5EmpvkJDQ/HkyRP07NlTrX40yczMDO7u7jhx4gRu3rypbFcoFFi/fj0AoFevXgCe76Lz8jaQEolEWZ5U8jk8efKk1DhOTk4q1xCR9nEFnojqJV9fX3z77bcYP348evXqhZycHBw4cKBCiWtNGjp0KHbs2IEVK1bg77//Vm4jefjwYTRv3rzUvvNl6dKlCwICAhAeHo5+/fph4MCBsLS0xIMHD7B3714Az5Ox77//Hra2tujTp4/a8QUEBODf//43Tp8+jQ4dOpRa2a2Oz9vW1hYjR47Eli1bMGbMGPj4+CA9PR1bt26Fg4ODSt25gYEBunTpgn379kEqlcLFxQUPHz7Ezp07YWNjo/K8AQC4ubkBAJYvX47+/ftDIpGgTZs2sLOzKzOWDz/8EIcPH8bixYtx/fp1ODo6Ii4uDuHh4WjZsmW1rUxfvXoVa9euLdWuq6uLCRMmYP78+QgKCsLIkSMxYsQImJub48SJEzhz5gz8/PzQuXNnAM/LqxYuXAgfHx+0bNkS+vr6uHr1KsLDw+Hm5qZM5Pv27Yt27drB1dUVFhYWSEtLQ2hoKEQiEfr161ct75GIKq52/peMiKiKPvjgAygUCoSHh2PJkiUwNzdHnz59MGTIEPTt21fb4ZUiFouxefNmLF26FFFRUTh06BBcXV3x888/Y/78+cjPz1ernyVLlqBDhw7YsWMHNm3ahMLCQlhbW8PX1xfjxo2DWCxGYGAgPvnkExgaGsLLy0utfvv374+lS5eioKCg1MOrQPV93vPnz0ejRo0QGhqKpUuXokWLFvi///s/3L9/v9SDo8uWLcO3336L48ePY/fu3WjRogVmzpwJXV1dzJs3T+VaT09PzJ49Gzt27MDChQtRVFSEqVOnlpvAGxoaYvv27Vi1ahWOHz+OiIgImJmZYfjw4Zg2bVqFT/9VV0xMTJk7+IjFYkyYMAEuLi7YsWMHVq1ahe3btyMvLw9NmzbF7NmzMW7cOOX19vb26NWrF86fP4/9+/dDLpfDysoKEydOVLlu3LhxOHXqFEJCQpCdnQ0zMzO4ublh4sSJKjvdEJF2CRQ18WQRERFVSnFxMTp16gRXV9dKH4ZERET1C2vgiYhqibJW2Xfs2IGsrKwy9z0nIqI3E0toiIhqiQULFkAmk8Hd3R1isRiXLl3CgQMH0Lx5cwwbNkzb4RERUS3BEhoiolpiz5492Lp1K+7du4e8vDyYmZmha9eumDFjBho1aqTt8IiIqJZgAk9EREREVIewBp6IiIiIqA5hAk9EREREVIfwIdYKevo0F3J5zVcdmZkZID09p8bHJaprOFeI1MO5QqQebcwVoVCAhg31y32dCXwFyeUKrSTwJWMT0etxrhCph3OFSD21ba6whIaIiIiIqA5hAk9EREREVIcwgSciIiIiqkOYwBMRERER1SFM4ImIiIiI6hDuQkNERESkAc+e5SInJxPFxYXaDoU0KDVVCLlcrrH+dHREMDAwRoMG5W8T+TpM4ImIiIiqqLBQhuzspzAxaQSRSAKBQKDtkEhDdHWFKCrSTAKvUChQWFiAjIzH0NUVQSQSV6ofltAQERERVVF2dgYMDIwhFkuZvFO5BAIBxGIp9PWNkZOTUel+mMATERERVVFRkQwSSQNth0F1hFTaAIWFskrfzxKaWu7stWREnErAk6wCmBpJ4N/VFp2dLLUdFhEREb1ALi+GUKij7TCojhAKdSCXF1f6fibwtdjZa8nYfCgesv/VXaVnFWDzoXgAYBJPRERUy7B0htRV1d8VltDUYhGnEpTJewlZkRwRpxK0FBERERERaRsT+FosPaugQu1EREREdc3UqRMwdeqEGr+3LmMJTS1mZiQpM1k3NZRoIRoiIiJ6k3h5tVfrurCwfbCyalLN0dCLmMDXYv5dbVVq4Evo6gqR86wQBg1EWoqMiIiI6ruFCxer/Bwauh0pKY8wbdoslXYTk4ZVGic4+Hut3FuXaTWBl8lkWLlyJfbu3YusrCw4ODhg5syZ6Ny58yvvO3LkCCIjIxEbG4v09HRYWVmhe/fu+Oijj2BoaFjq+rCwMPz4449ITExEkyZNMHr0aIwcObK63pbGlDyo+uIuNO3amOPU5Yf4eutFzBrmBlMjqZajJCIiovqod+++Kj+fPBmFzMyMUu0vy8/Ph1Sqfn4iElV+QbIq99ZlWk3g586diyNHjmD06NFo3rw5du/ejfHjxyMkJATu7u7l3rdw4UJYWFhg4MCBaNKkCW7cuIGQkBCcPn0au3btgkTyT4nJjh078Pnnn8PX1xfvv/8+Lly4gMWLF6OgoADjxo2ribdZJZ2dLNHZyRLm5oZIS8sGAHjamWN1RCyWhERj1jA3WJsbaDlKIiIiehNNnToBOTk5+PTTz7B6dTBu3IjHyJGj8cEHE3H69Ens27cbN2/eQFZWJszNLdC3b38EBb0PHR0dlT4AYM2a9QCAixcvYPr0SViyZCnu3r2DPXt2ISsrEy4ubvjkk89gY9NUI/cCwK5dodixYyvS0x/D1tYWU6fOxIYN61T6rI20lsDHxsbi4MGDmDdvHsaOHQsAGDRoEPz8/LB8+XJs3bq13HtXrVqFjh07qrQ5Oztjzpw5OHjwIPz9/QE8/wYYHByMHj16YOXKlQCAYcOGQS6XY82aNRg6dGiZK/a1nUPzhpgzwgPBYTH4astFTA9whV1TE22HRURERBpUchZMelYBzGrxWTAZGU/x6acz4ePjC1/ffmjc+HmMkZEH0KCBHgIDR0JPrwGioy9g48b/Ijc3F1OmzHhtv5s3b4JQqIMRI0YjOzsL27eH4IsvFmDDhs0auXf37nAEBy9Fu3YeCAx8D48ePcK8ebNhaGgIc3OLyn8gNUBrCfzhw4chEokwdOhQZZtEIkFAQACCg4ORmpoKC4uyP7yXk3cA6NmzJwAgIeGfLRbPnTuHjIwMjBgxQuXakSNHYv/+/fjtt9/Qr18/TbydGtessSHmj/LEd6ExWL7jMiYOcIKnvbm2wyIiIiINqEtnwTx+nIa5cxfCz2+gSvuiRf+BRPJPKc2gQQFYtuxL7N4dhvHjJ0MsFr+y36KiIvz442bo6j5PV42MjLFy5XLcuXMbrVq1rtK9hYWF2LhxHZycXLBixVrlda1bt8GSJYuYwJcnLi4OLVu2hL6+vkq7q6srFAoF4uLiyk3gy/L48WMAQMOG/zxIcf36dQDPV+df5OTkBKFQiOvXr9fZBB4AGpk0wLxRHlgZHou1e65glI89urtbazssIiIi+p/frzzCmdhHFb4vISkTRcUKlTZZkRw/Rcbht8tJFe7Py9UKXVysKnyfOqRSKXx9S+dTLybveXm5kMkK4ebmjr17I3D//j20aWP3yn779RugTKwBwM2tHQAgKenhaxP4190bH38dmZmZ+OijwSrX9erli1Wrvntl37WB1hL4tLQ0NG7cuFS7ufnzVeTU1NQK9bdhwwbo6OjAx8dHZQyxWAwTE9XykpK2io5RGxnqifHJcHes23sVIb/eQGZOAQZ6teRpcERERHXYy8n769q1ydzcQiUJLnHnTgI2bFiHixf/Qm5ursprubk5r+23pBSnhKGhEQAgOzu7yvcmJz//UvVyTbyuri6srKrni44maS2Bz8/PL/PJ4ZIHUAsK1D+saP/+/QgPD8fEiRPRrFmz145RMk5FxihhZqa9B0bNzcuv11888W18Hx6Dfb/fQ36RAh8NcYWODs/pojfTq+YKEf2Dc0VzUlOF0NUt/d/dru7W6FqJv47PXH0G6Zn5pdrNjKWYP0a9/dk1rWRx8MX3KRAIIJVKS7337OxsTJs2Efr6+pgwYTKsrW0gFktw40Ycvv9+FQSCf/p5ud+S/EUk0lXpt6RdE/eW/KyjIyjj300AgUC1vax/26oSCoWVnoNaS+ClUikKCwtLtZck1S/uJPMqFy5cwPz589GtWzfMmKH6QIRUKoVMJivzvoKCArXHeFF6eg7k8pr/9vviLjTlGd7dFhJdIQ78cQ+p6bmYONAJEpHOK+8hqm/UmStExLmiaXK5HEUvndtSFf7vtip1FoxYVwj/d1tpdJyKUCie5z8vjq9QKKBQoFRMf/31FzIzM7BkyfOHREskJiYCAIqL//m8Xu63uLjk/ypU+i1pl8sVVb7X3Px5Fcj9+3/D2bmd8rqioiI8epQEW9vWyvt1dYXV8pnL5fJy56BQKHjlorHWlmjNzc3LLGFJS0sDALXq3+Pj4zF58mTY29sjODhYZUuikjEKCwuRkZGh0i6TyZCRkVGhGvu6QCAQwP/dVhjlY4eY24+xfMcl5Dwr/SWJiIiIarfOTpYY08cBZkbPFxvNjCQY08eh1j3AWh6h8HmKWZJgA0BhYSF27w7TVkgqHBzawtjYGPv27UZRUZGy/ejRw8jOztJiZOrR2gq8g4MDQkJCkJubq/Iga0xMjPL1V/n777/x4YcfwtTUFD/88AP09PRKXePo6AgAuHr1Kry8vJTtV69ehVwuV75e33h72MBIT4z1+6/jqy3RmDnMDY2MG2g7LCIiIqqAkrNg6iIXF1cYGhphyZJFCAgIhEAgwK+/RkJRS0r4RSIRxo2bgODgZfjXvz5C9+498OjRIxw6tB/W1ja1/llCra3A+/r6orCwEGFh/3wTk8lkiIiIgIeHh/IB16SkJJWtIYHnq/Tjxo2DQCDApk2bYGpqWuYYnTp1gomJCbZt26bSvn37dujp6eHdd9/V8LuqPdo7WODjQDdk5MjwZUg0ElNf/7AIERERkSYYG5tg6dJgmJk1woYN67B9+xa0b98RH300XduhKQ0ZEoh//Ws2kpMf4fvvVyIm5hK+/vo7GBgYQiyueJl1TRIoFNr7LjRjxgxERUVhzJgxaNasGXbv3o2rV69i8+bN8PT0BAAEBQXh/PnzuHHjhvK+gQMHIj4+Hh9++CHs7FS3IGrWrJnKKa5bt27F4sWL4evrCy8vL1y4cAF79uzB7NmzMX78+ArHXJtr4MuSmJqD4LAY5MuKMX2IC+ybNXz9TUR1GOt6idTDuaJZycn3YWnZXNthUBXJ5XL4+fVC167dMWfOAgDVVwP/qt+Z19XAa62EBgCWLl2KFStWYO/evcjMzIS9vT3Wr1+vTN7LEx///CCDjRs3lnpt8ODBKgn8yJEjIRKJ8OOPPyIqKgpWVlaYP38+Ro8erdk3U0vZWBjgs1Ge+C70Mr7dGYMJ/duivUP9qv0nIiIiqqiyNjQ5fPggsrIy4e7+6lxU27S6Al8X1bUV+BI5zwqxKjwWCQ8zMaKXHXp42mgwOqLag6uKROrhXNEsrsDXPX/9dQ7r1q1Gt27eMDIyxs2b8Th4cB+aN2+BTZu2KLci5wo8aY1BAxFmD2+H/+69hq1HbyIjpwD+77aq9Q9pEBEREVWHJk2s0aiROcLDdyIrKxNGRsbw9e2HSZOmlnuOUG3BBP4NIhbpYIq/M0J+vYmDZ+8jM0eG0b720OWBT0RERPSGsba2wdKlwdoOo1KYwL9hdIRCjPG1h4mBGPt+v4esPBkmD3SGRMwDn4iIiIjqAi69voEEAgEGvdMKo3vb48qddCzbcQnZeWWfWEtEREREtQsT+DdYN3drTBnsggepOfhyy0U8znim7ZCIiIiI6DWYwL/hPOzM8XFgO2TnyrAkJBp/p3BHAiIiIqLajAk8wa6pCeaN8oBQKMA32y4i7v5TbYdEREREROVgAk8AAGtzA8wP8oSpoRTBoZdxPi5F2yERERERURmYwJOSqZEUc0d5oKWVEX7Yew1HLzzQdkhERERE9BIm8KRCXyrCx4Ht4G5nju3HbiH8ZAJ4WC8RERFVVWTkfnh5tcejR0nKtoCA/liyZFGl7q2qixcvwMurPS5evKCxPmsKE3gqRSzSwUeDnNHN3RqRf97HpoNxKCrW/BHCREREVHt9+ulM9OzphWfPyt+lbtasqejduysKCgpqMLKKOXbsV4SGbtN2GBrFg5yoTEKhAEE+dmhoIMbu03eRlSfDR4OcIRXzV4aIiOhN0KtXb/zxx2mcOXMKvXr5lnr96dMniI7+Cz4+fSCRSCo1xrZtuyAUVu96clTUEdy6dRPDho1QaW/XzgNRUb9DJBJV6/jVgSvwVC6BQID+XVpibB8HXLv7BMu2X0IWD3wiIiJ6I7zzTjc0aKCHY8d+LfP148ePobi4GD4+pZN7dYnFYujqamdxUCgUQiKRVPsXiOrA5VR6rXfdmsBIT4x1e6/iy5BozApsBwuTBtoOi4iIiKqRVCrFO+90xYkTx5CVlQUjIyOV148d+xVmZmZo2rQ5li//GtHR55GSkgKpVAoPj/aYMmUGrKyavHKMgID+cHf3xPz5i5Rtd+4kYMWKZbh69QqMjY0xcKA/GjUyL3Xv6dMnsW/fbty8eQNZWZkwN7dA3779ERT0PnR0dAAAU6dOwOXLFwEAXl7tAQCWllYID9+PixcvYPr0SVi16r/w8Giv7Dcq6gi2bPkZ9+/fg56ePt55511MnDgNJiYmymumTp2AnJwc/N//LcZ33y1FXNw1GBoaYejQ4Rg5ckzFPuhKYAJPamnXphE+Ge6OleEx+DIkGjOHuqG5paG2wyIiIqq3zidfxL6Ew3hakIGGEhMMsPVFB0uPGo2hVy9fHDlyCCdPRmHAgMHK9uTkR7h6NRYBAcMRF3cNV6/GomfP3jA3t8CjR0nYs2cXpk2biC1bwiCVStUeLz39MaZPnz7fMy8AACAASURBVAS5XI5Ro8ZAKm2Afft2l1miExl5AA0a6CEwcCT09BogOvoCNm78L3JzczFlygwAwJgx4/Ds2TOkpDzCtGmzAAANGuiVO35k5H58+eUXcHJyweTJ05GamoJdu3bi2rWr2LDhF5U4srIy8fHH09G9ew/06OGDEyeOYd261WjVqjU6d+6i9nuuDCbwpLbWNsaYN8oTwaGX8fW2i5jq7wKnFqbaDouIiKjeOZ98Edvid6FQXggAeFqQgW3xuwCgRpP4t97qCBOThjh27FeVBP7YsV+hUCjQq1dv2Nq2RvfuPVXu69LlXUya9D5OnoyCr28/tcfbunUzMjMzsHFjCOztHQAAffr44b33Bpe6dtGi/0Ai+efLwaBBAVi27Evs3h2G8eMnQywW4623OiEiIgyZmRno3bvvK8cuKirCunWr0bq1HVav/gFisRgA0LZtWyxcOA/79+9GQMBw5fWpqSn4/PP/KJ8P8PMbiIAAPxw8uJcJPNUuTRrp47Og9ggOvYwVoTH4wM8RndpaajssIiKiWunco2icffRXhe+7m/k3ihRFKm2F8kJsjQvHH0nnK9xfZ6u30NHKs8L36erqwtu7J/bs2YXHjx+jUaNGAIBjx47AxqYp2rZ1Vrm+qKgIubk5sLFpCgMDQ9y8GV+hBP7s2d/h4uKmTN4BoGHDhujVqw927w5TufbF5D0vLxcyWSHc3Nyxd28E7t+/hzZt7Cr0XuPjr+Pp0yfK5L9Ejx69sGpVMP7443eVBN7AwAA9e/ZW/iwSieDo6ISkpIcVGrcymMBThTU0lGDuSA+s3nUF6/ddR1aODD4dmmk7LCIionrj5eT9de3VqVcvX0REhOH48SMYNmwE7t27i9u3b+L998cDAAoK8hES8jMiI/cjLS1V5fyYnJycCo2VkpIMFxe3Uu3NmjUv1XbnTgI2bFiHixf/Qm5ursprubkVGxd4XhZU1lhCoRA2Nk2RkvJIpd3CojEEAoFKm6GhERISbld47IpiAk+VoicVYVagGzbsv44dx28jI0eGgO62EL70i0xERPQm62jlWamV7wW/f4mnBRml2htKTPAvj0maCE1tLi5usLKyxtGjhzFs2AgcPXoYAJSlI8HByxAZuR9Dh74HZ2cXGBgYABBg0aLPqu0wyOzsbEybNgF6egb44INJsLa2gVgsxs2b8Vi3bjXk8uo/v0Yo1CmzvSYOwGQCT5Um0tXBpIHO2HbsJg6f/xsZuQUY19cRujp1bzsmIiKi2mSAra9KDTwAiIQiDLCt/JaNVdGzpw9CQn5CYuIDREUdgb29o3KluqTOfdq0mcrrCwoKKrz6DgCNG1siMfFBqfa//76v8vOlS9HIzMzEkiXL0K7dP88ElH1Sq3qLi5aWVsqxXuxToVAgMfEBWra0VaufmsBMi6pEKBRgZC87+L/bCn9eS8HKsBg8K6j5P+8RERHVJx0sPTDCYQgaSp5vXdhQYoIRDkNqfBeaEj4+fQAAa9YEIzHxgcre72WtRO/atRPFxcUVHqdz5y64ciUGN27EK9uePn2Ko0cPqVxXsnf7i6vdhYWFperkAaBBgwZqfZlwcGiLhg1NsWdPOAoL//nidPz4MaSlpeLtt6v3wdSK4Ao8VZlAIIDf2y1gbCDG5kM3sHT7JfxrqBuM9cWvv5mIiIjK1MHSQ2sJ+8tatmyF1q3tcObMbxAKhejR45+HN99+2wu//hoJfX0DtGjREteuXcGFC+dhbGxc4XFGjBiDX3+NxKxZUxAQMBwSiRT79u1G48ZWyMm5pbzOxcUVhoZGWLJkEQICAiEQCPDrr5Eoq3rF3t4BR44cwurV38HBoS0aNNCDl9e7pa7T1dXF5MnT8OWXX2DatIno2dMHqakpCA/fiVatbNG/f+mdcLRFqwm8TCbDypUrsXfvXmRlZcHBwQEzZ85E586dX3lfbGwsIiIiEBsbi5s3b6KwsBA3btwo89rU1FSsWrUKf/zxB9LT09G4cWP4+PhgwoQJpQ4koKp5x/V/Bz7tuYqvQqIxK9ANFg3L32uViIiI6g4fH1/cvn0T7u6eyt1oAGDGjNkQCoU4evQQCgpkcHFxw4oV32PWrGkVHqNRo0ZYteoHBAcvRUjIzyoHOX399b+V1xkbm2Dp0mCsWbMCGzasg6GhEXx8+qB9+w6YNWuqSp8DBw7BzZvxiIw8gJ07t8HS0qrMBB4A+vbtD7FYjK1bN+P771dCX18fvXv3wYQJU8vci15bBIqaqLQvx6xZs3DkyBGMHj0azZs3x+7du3H16lWEhITA3d293PtWr16N//73v7C3t8ezZ89w586dMhP4vLw8+Pn5IS8vDyNHjoSlpSWuX7+O0NBQuLm5Ydu2bRWOOT09B3J5zX9k5uaGSEvLrvFxKyMhKRMrw2IhFAD/GuaGFpb8okQ1py7NFSJt4lzRrOTk+7C0LL1TCtV9urpCFBVp/qHYV/3OCIUCmJkZlB+TxqNRU2xsLA4ePIh58+Zh7NixAIBBgwbBz88Py5cvx9atW8u997333sP48eMhlUqxZMkS3Llzp8zrTp48iYcPH+KHH35At27dlO1SqRQ//vgjHjx4gKZNm2rybREA2ybGmDfKA8GhMfhm6yVM8XeGc0szbYdFREREVC9o7SHWw4cPQyQSYejQoco2iUSCgIAAREdHIzU1tdx7GzVqpNaxvCUPLJiZqSaPJX/2qcjRvlQxVmb6+CzIExYNG2BlWCzOXk3WdkhERERE9YLWEvi4uDi0bNkS+vr6Ku2urq5QKBSIi4ur8hienp4QCoVYsmQJLl++jOTkZBw/fhw//fQT/P39YW5uXuUxqHwmBhLMGeGBNjbG2HDgOg6f+7tG9kYlIiIiqs+0VkKTlpaGxo0bl2ovSapftQKvLltbWyxevBhLly5FYGCgsj0wMBCLFi2qcv/0enpSXcwc1g4bD1xH6InbyMgpwDDv1jzwiYiIiKiStJbA5+fnQyQSlWovecK3oKBAI+NYWlrCzc0N7777Lpo0aYILFy4gJCQExsbG+Pjjjyvc36seKKhu5uaGWhu7qhZ80Akb913F/tN3kF8kx7+Gu0OkW/YJZkRVVZfnClFN4lzRnNRUIXR1ebxOfVUd/7ZCobDSc1BrCbxUKlXZJL9ESeKuia16oqOjMWnSJISHh8PR0REA0LNnTxgYGGDNmjUYPHgwWrVqVaE+uQtN5Q16uzmkOgKEnUxA2pM8TPV3QQMJjyIgzaoPc4WoJnCuaJZcLq+WnUpI+6prFxq5XF7uHHzdLjRa+6pobm5eZplMWloaAMDCwqLKY+zcuRMWFhbK5L2Et7c3FAoFLl++XOUxSH0CgQB9OjXHB/0ccfNBBr7ZehGZOZr5SwsRERHRm0JrCbyDgwPu3r2L3NxclfaYmBjl61WVnp5e5jG+RUVFAFCpI36p6rq4WGF6gCuSn+ZhSUg0kp/kaTskIiKiKuNGDaSuqv6uaC2B9/X1RWFhIcLCwpRtMpkMERER8PDwUD7gmpSUhISEhEqN0aJFC6SkpODChQsq7QcOHACAUivzVHNcWpnh0/c8kC8rxpch0biTlKXtkIiIiCpNR0cXhYUybYdBdURhoQw6OpUvI9bqSawzZsxAVFQUxowZg2bNmilPYt28eTM8PT0BAEFBQTh//rzKSasPHz7E3r17AQC//fYbLl26hBkzZgB4vnLv7e0NALhz5w6GDBkCoVCIUaNGwcrKCn/99RcOHDiAd955Bxs3bqxwzKyB16yUJ3n4dudlZOXJ8NEgF7ja8sAnqpr6OleINI1zRbOePctFdvZTmJiYQyQSQ8Dd1uoNTdbAKxQKFBbKkJGRBkPDhmjQQL/M615XA6/VBL6goAArVqzA/v37kZmZCXt7e8yaNQtvv/228pqyEvhz585h9OjRZfY5ePBgfP3118qf79y5gxUrViA2NhaPHz+GhYUF+vTpg2nTplXqICcm8JqXmVOA4LAYPEzLxdg+DujiYqXtkKgOq89zhUiTOFc079mzXOTkZKC4uEjboZAGCYVCyOWae4hVR0cXBgYm5Sbvz8esxQl8XcQEvno8KyjCmogriLv/FAHdbNGnYzOuXlCl1Pe5QqQpnCtE6tHGXKm1u9AQvaiBRBczh7mhY9vGCD+ZgO3HbkHO75ZEREREpXATbqo1dHWEGN+/LYz1xTjy1wNk5srwoV9biHgwBhEREZESE3iqVYQCAYb3aAMTAwlCT9xGdp4MU/1doSflryoRERERwBIaqqV8OzbD+P5tcSsxE19vvYin2TzwiYiIiAhgAk+1WGcnS8wY6oq0zGf4MiQaj9JzX38TERERUT3HBJ5qNeeWZpgzwh2FRcX4astFJCRlajskIiIiIq1iAk+1XgtLI3wW5Ak9iS6WbbuEmNuPtR0SERERkdYwgac6waKhHj4L8oRVI32s3nUFp2OStB0SERERkVYwgac6w0hfjDkj3OHYoiF+OhSP/X/cA88hIyIiojcNE3iqU6RiXcwIcEUnp8bY/dsdbDl6Uysn4xIRERFpCzfXpjpHV0eID/3awsRAgsPn/kZWrgwT+reFSFdH26ERERERVTuuwFOdJBQIMKx7awz3bo3oG2n4dmcM8vILtR0WERERUbVjAk91mk+HZpg4wAkJDzPxFQ98IiIiojcAE3iq8zq2bYyZw9yQnpmPJSEXkPSYBz4RERFR/cUEnuqFti1MMWeEB4qKFfhqSzRuJ/LAJyIiIqqfmMBTvdHc0hCfBXnCoIEIy3ZcwqVbadoOiYiIiEjjmMBTvWJh0gDzgjxhY66PNRFX8BsPfCIiIqJ6hgk81TtGemJ88p47nFua4edD8dj3+10e+ERERET1BhN4qpekYl1MG+KCLs6W2HP6LkKO8MAnIiIiqh94kBPVW7o6Qozr5wgTQwkOnr2PzJwCTBzgBLGIBz4RERFR3cUVeKrXBAIBhnS1xYiebXD51mMs33kZOc944BMRERHVXUzg6Y3Qs31TTBzohHuPsvD11ot4kpWv7ZCIiIiIKkXrCbxMJsOyZcvg5eUFV1dXDBs2DGfPnn3tfbGxsVi0aBH8/f3h7OwMe3v7V15/9+5d/Otf/0KnTp3g6uqKPn36YMOGDZp6G1QHdHBsjJnD2uFpdj6WhETjYVqOtkMiIiIiqjCtJ/Bz587F5s2bMWDAAMyfPx9CoRDjx4/HpUuXXnnfqVOnEBYWBgBo2rTpK6+9du0aAgIC8PDhQ0ycOBELFixAz549kZycrLH3QXWDY/OGmDPCA3KFAl9tuYibDzK0HRIRERFRhQgUWtxfLzY2FkOHDsW8efMwduxYAEBBQQH8/PxgYWGBrVu3lnvv48ePYWBgAKlUiiVLluCXX37BjRs3Sl1XXFyMAQMGoGXLlli1ahWEwqp9Z0lPz9HKbibm5oZIS8uu8XHrq8cZz/BdaAzSs/IxcYATPOzMtR0SaQjnCpF6OFeI1KONuSIUCmBmZlD+6zUYSymHDx+GSCTC0KFDlW0SiQQBAQGIjo5Gampqufc2atQIUqn0tWOcOXMGt2/fxsyZMyEUCpGbmwu5XK6R+KnuamTSAPNGeaCphQG+330FJy491HZIRERERGrRagIfFxeHli1bQl9fX6Xd1dUVCoUCcXFxVR7j7NmzMDAwQEpKCnr37g0PDw94eHhgwYIFePbsWZX7p7rLUE+MT4a7w6WVGUJ+vYE9p+/wwCciIiKq9bSawKelpcHCwqJUu7n583KGV63Aq+v+/fsoLi7GRx99BC8vL6xevRrvvfcewsPD8fHHH1e5f6rbJGIdTPV3gZeLFfb9fg+bD8ejmH+hISIiolpMqwc55efnQyQSlWqXSCQAntfDV1VeXh6ePXuG4cOHY+HChQAAHx8fCAQCbNq0CfHx8XBwcFC7v1fVI1U3c3NDrY1d33065i00ORyP0GM3kV+owCdBnpCKec5ZXcW5QqQezhUi9dS2uaLVDEUqlaKwsPShOiWJe0kiX9UxAMDPz0+lfcCAAdi0aROio6MrlMDzIdb6y7e9DcRCYOuRm5i75jRmBLjBoEHpL5hUu3GuEKmHc4VIPXyI9SXm5uZllsmkpaUBQJnlNZUZAwDMzMxU2kt+zsrKqvIYVH94e9hg8iBn3E/OwVdbopGeyQOfiIiIqHbRagLv4OCAu3fvIjc3V6U9JiZG+XpVOTk5AQBSUlJU2kv2gDc1Na3yGFS/tHewwMeBbsjIkWFJyAUkpvLAJyIiIqo9tJrA+/r6orCwUHkgE/D8ZNaIiAh4eHigcePGAICkpCQkJCRUagxvb2+IRCKEh4ertIeFhUEgEKBTp06VfwNUb9k3a4h5Iz0AAF9tvYgbfz/VckREREREz2m1Bt7NzQ2+vr5Yvnw50tLS0KxZM+zevRtJSUn46quvlNfNmTMH58+fVzmo6eHDh9i7dy8A4MqVKwCAtWvXAni+cu/t7Q0AaNy4MSZMmIDvv/8ehYWF6NSpEy5duoR9+/ZhxIgRaN68eU29XapjbCwMMD+oPb4LvYxvd8ZgQv+2aO9Q9bIuIiIioqrQ6kmswPMHVlesWIH9+/cjMzMT9vb2mDVrFt5++23lNUFBQaUS+HPnzmH06NFl9jl48GB8/fXXyp8VCgU2b96Mbdu2ISkpCRYWFhg6dCgmTpxY4ZNZ+RDrmyfnWSFWhsfgzsMsjOhlhx6eNtoOiV6Bc4VIPZwrROqpjQ+xaj2Br2uYwL+ZCgqL8cPea7h8+zH83m6Owe+0gkAg0HZYVAbOFSL1cK4Qqac2JvBarYEnqiskIh1M8XfGu25NcOCP+/jpEA98IiIiIu3gSTVEatIRCjHG1x4mBmLs+/0esnJlmDzQGRKxjrZDIyIiojcIV+CJKkAgEGDQO60wurc9rtxJx7Idl5CdJ9N2WERERPQGYQJPVAnd3K0xZbAL/k7JwZdbLuJxxjNth0RERERvCCbwRJXkYWeO2cPbITtXhiUh0fg7hQ+DERERUfVjAk9UBXZNTTBvlAeEQgG+2XYRcfd54BMRERFVLybwRFVkbW6A+UGeaGgoRXDoZZyPS9F2SERERFSPMYEn0gBTIynmjfJASysj/LD3Go5deKDtkIiIiKieYgJPpCH6UhE+DmwHdztzbDt2C+EnE8Bz0oiIiEjTmMATaZBYpIOPBjmjW7smiPzzPjYdjENRMQ98IiIiIs3hQU5EGiYUChDU2x4mhhLsOX0XWXkyfDTIGVIxpxsRERFVHVfgiaqBQCDAgC4tMbaPA67dfYJl2y8hiwc+ERERkQYwgSeqRu+6NcFUfxckpuXiq5BopPLAJyIiIqoiJvBE1cy9jTk+Ge6OnGeF+DIkGveTeeATERERVR4TeKIa0NrGGPNGeUKk8/zAp2v3nmg7JCIiIqqjmMAT1ZAmjfTxWVB7mBlLsSI0Bn9eT9Z2SERERFQHMYEnqkENDSWYN9IDttbGWL/vOo6c/1vbIREREVEdwwSeqIbpSUX4ONANnvbm2HH8NkKP34acBz4RERGRmpjAE2mBSFcHkwc6w9vDGofP/42NB67zwCciIiJSC0+WIdISoVCAkb3sYGIgQcRvd5CdV4iPBjmjgYTTkoiIiMrHFXgiLRIIBPB7uwXe7+uAuHtPsXT7JWTm8sAnIiIiKh8TeKJa4B3XJpg2xAWPHv/vwKenedoOiYiIiGopJvBEtYRb60b45D135BUU4cuQaNxLztJ2SERERFQLaTWBl8lkWLZsGby8vODq6ophw4bh7Nmzr70vNjYWixYtgr+/P5ydnWFvb6/WeJGRkbC3t0f79u2rGjpRtbC1Nsa8UR4Q6ergm62XcPVuurZDIiIiolpGqwn83LlzsXnzZgwYMADz58+HUCjE+PHjcenSpVfed+rUKYSFhQEAmjZtqtZY+fn5WLZsGfT09KocN1F1sjLTx2dBnrBo2AArw2Jx9hoPfCIiIqJ/aC2Bj42NxcGDBzF79mx8+umnCAwMxObNm2FlZYXly5e/8t733nsP0dHRiIiIgJeXl1rjbdiwAWKxGN7e3poIv8acT76IBb9/icCdk7Hg9y9xPvmitkOiGtDQUII5IzzQxsYYG/Zfx+FzPPCJiIiIntNaAn/48GGIRCIMHTpU2SaRSBAQEIDo6GikpqaWe2+jRo0glUrVHispKQkbN27EnDlzIBKJqhR3TTqffBHb4nfhaUEGFACeFmRgW/wuJvFvCD2pLmYOa4e3HCwQeuI2dkTd4oFPREREpL0EPi4uDi1btoS+vr5Ku6urKxQKBeLi4jQ21jfffAN3d/c6t/q+L+EwCuWFKm2F8kLsSzispYiopol0hZg40Ak9PW1w5K8H2LD/OgqLeOATERHRm0xrJ8akpaWhcePGpdrNzc0B4JUr8BVx/vx5HD16FBERERrpryY9Lcgotz385j44mLZBm4a2kOiIazgyqklCgQDv9WwDE0MJwk8mICtXhqn+LjzwiYiI6A2ltQwgPz+/zHIWiUQCACgoKKjyGMXFxfjPf/4Df39/ODg4VLk/ADAzM9BIP+popGeKx3lPSrWLhLo48+gcTiSegY5QBw6NbOFm2RaujR3QomFTCAXcHbQ+GtPfGTaWRlgVehnf7ozBovGd0NBI/VKyN4m5uaG2QyCqEzhXiNRT2+aK1hJ4qVSKwsLCUu0liXtJIl8VO3fuRGJiIn788ccq91UiPT0HcnnN1CH3a+GDbfG7VMpoREIRRjgMQTtzFyRk3kX8k1uIe3IT22L3YBsAA5E+7Bu2hqOpHRxM26Ch1KRGYqWa4dqiIaYPccXaPVcwa8UpfBzYDo1NubPSi8zNDZGWlq3tMIhqPc4VIvVoY64IhYJXLhprLYE3Nzcvs0wmLS0NAGBhYVGl/mUyGVatWgV/f3/k5+cjMTERAJCXlwe5XI7ExETo6enB1NS0SuNUpw6WHgCe18JnFGTARGKCAba+ynZHUzs4mtphMPohsyAbN54+T+bjntxEdGoMAMBSvzEcTdvA0dQOrU1asdymHnC1NcOn73lgRVgMloREY+YwN7S0MtJ2WERERFRDtJbAOzg4ICQkBLm5uSoPssbExChfr4r8/Hw8ffoUISEhCAkJKfV6jx490LdvXwQHB1dpnOrWwdIDHSw9Xvvtz1hiqLxWoVAgKTcZcU9uIv7JLZx5+CdOPDgDXYEOWhm3eL46b9YGNgZNWG5TR7VqYoT5QZ74dudlfLPtIqYMdoFLKzNth0VEREQ1QGsJvK+vL3788UeEhYVh7NixAJ6vmkdERMDDw0P5gGtSUhKePXsGW1vbCvXfoEEDfP/996Xaf/nlF8TGxmL58uVlPkRbHwgEAlgbWMHawAo9m3WFrLgQCZl3lQn93juHsPfOIZbb1HGNTfUwP8gTwaExWBUei7F9HNDFxUrbYREREVE101oC7+bmBl9fXyxfvhxpaWlo1qwZdu/ejaSkJHz11VfK6+bMmYPz58/jxo0byraHDx9i7969AIArV64AANauXQvg+cq9t7c3RCIRevbsWWrcY8eO4fr162W+Vl+JdUTKchsAyCzI+l/t/C3EP2W5TV1mbCDBnJEeWBNxBZsOxiEzV4Y+HZtBIBBoOzQiIiKqJlrdh27p0qVYsWIF9u7di8zMTNjb22P9+vXw9PR85X2JiYlYuXKlSlvJz4MHD65z+73XNGOJETpaeaKjladKuU1c+k2cfrHcxqQlHBu2YblNLddAoouZw9yw6WAcwk8mICO7AMN7toGQSTwREVG9JFAoeLRjRdTkLjQvqqknoF8ut3mY8wjA891tHEzbwMHUDo6mbWAiMa72WKhi5AoFQo/fxpG/HuAtBwt86NcWIt0370sXd9YgUg/nCpF6uAsN1XqvK7e5kHIZAGCl31hZO89ym9pBKBBgeI82MDGQIPTEbWTnyTDV3xV6Uk5zIiKi+oQr8BVU31fgX0WukCMpJxnxT28hLv0mbmfeRZG86J9ym//Vz1sbWLHcRsvOXkvGjwfj0KSRPmYOc4OJQdXPVagrasNcIaoLOFeI1FMbV+CZwFfQm5zAv0xWXIiEjLvKveeTcpMBsNymtrh6Nx3f774KA6kIswLdYGWm//qb6oHaOFeIaiPOFSL1MIGvB5jAl0+l3ObJTWQX5gB4sdzGDm1MWkLMcpsacy85C8GhMVAogBlDXWHbpP5/maoLc4WoNuBcIVIPE/h6gAm8ekrKbUoehmW5jfakPM1D8M4YZOQUYPIgZ7i1bqTtkKpVXZsrRNrCuUKkHibw9QAT+Mp5XblNyQOxLLepHpm5MqwIi8GDlByM8bXHO25NtB1Stanrc4WopnCuEKmnNibwGtmeoqioCFFRUcjMzET37t1hbm6uiW6pHhHriOBoZgdHs+e722QUZOLGk9vKFfrSu9uw3EaTjPXF+PQ9d6zdcxU/HYpHRq4Mfp2b88AnIiKiOqjCK/BLly7FuXPnsGvXLgCAQqHA6NGjceHCBSgUCpiYmCA0NBTNmjWrloC1jSvwmveqchtbk5bK1XmW21RdUbEcP0bG4c9rKfD2sMaInnYQCutXEl+f5wqRJnGuEKmnXqzAnz59Gm+//bby5+PHj+Ovv/7Chx9+CEdHR/z73//G+vXr8Z///KdyEdMbRygQwsawCWwMm6BX826QFctwO+Ofw6T2JEQCCSy30QRdHSE+9GsLEwMJDp/7G5m5Mkzo3xYiXR1th0ZERERqqnACn5ycjObNmyt/PnHiBGxsbDB79mwAwK1bt7B//37NRUhvHLGOGG3N7NHWzB5A+eU2TfQtldtVstxGfUKBAMO6t4aJvhg7jt/Gt3kxmD7EBXpSkbZDIyIiIjVUOIEvLCyEru4/t507d05lRb5p06ZIS0vTTHREAEwkxuho5YmOVp6QK+R4mJOM+P8l8789PIvjD06/VG5jB2sDS5bbvIZPh2YwMhBj04E4fLX1ImYNa4eGhm/OgU9ERER1VYUTeEtLrLTl9QAAIABJREFUS1y6dAnDhg3DrVu38ODBA0yfPl35enp6OvT09DQaJFEJoUCIpoZN0PSV5TaRMBQZqJTbGEuMtB16rdSprSUM9cRYE3EFS0IuYNawdmjS6M048ImIiKiuqnAC369fP6xduxZPnjzBrVu3YGBggK5duypfj4uLq7cPsFLtU1a5TfyTW/87UOom/kq5BOCfchtHUzu0ZrmNCqcWppg7wgPBYTH4aks0ZgS4obUNny8gIiKqrSqcwE+cOBGPHj1CVFQUDAwM8M0338DI6PnqZnZ2No4fP46xY8dqOk4itZhIjNHJqj06WbVXKbeJe3ITvyX+8bzcRqiL1sYtlfXzLLcBmlsa4rMgTwTvvIzlOy5h0kBntGtTvw98IiIiqqs0epCTXC5Hbm4upFIpRKL6+UAct5Gsu14utyk5TIrlNv/IypNhZVgM7iVnY4yvA96tgwc+ca4QqYdzhUg9tXEbSY0m8DKZDGJx/S5NYAJff5SU25Qk9DmFuQBYbpMvK8LaPVdx9c4TDHqnJfq/3aJOHfjEuUKkHs4VIvXUiwT+1KlTiI2NxbRp05RtW7duxbfffov8/Hz06dMHX3/9NVfgNYz/Q1u9Xi63Sci4iyJFsUq5jaOpHZq8IeU2RcVy/HwoHn9cTUY3d2uM6lV3DnziXCFSD+cKkXpqYwJf4Rr4TZs2wczMTPlzQkICvvzySzRt2hQ2NjaIjIyEi4sL6+CpTilrd5tbGXeVCf2ehEjsSYiEodgADg3t4Gjapl6X2+jqCPFBP0eYGEgQ+ed9ZOYUYOIAJ4hFPPCJiIhI2yqcwN+5c0dl15nIyEhIJBKEh4fDwMAAH3/8Mfbs2cMEnuo0sY4YTmb2cHppd5u4JzcR9+QG/kq5COB5uY2jqR0cTe1ga9ISYp3685cngUCAgG62MDYQY8exW/h252VM/3/27jw66irP//+zKqlU9qUqO2SHLBDCprLYuAAqY+OG0jYqqN1tO639HYXu+dm0M3NmuqfVGXFBZ2z3QWiXFgyiqIii7QIKrSghCwGSsBmykIWQtZJU/f6opCQmgUSTVCV5Pc7pw+HW51OfW7SXevPO+77vdVkE6MAnERERt+p3AH/y5EnCwsJcv9+xYwczZ84kMNCZ5j/vvPP46KOPBm6GIh6ge3eb467a+Y+ObWfb0Y+7lduMCYwZVrXjvbnknDhCAnx4dnM+D/xlN8t/MhlLsK+7pyUiIjJq9TuADwsLo7S0FID6+nr27t3LihUrXK+3tbXR3t4+cDMU8TDOcpsxxAWN4dKEi0dFuc15GVEdBz7l8Kd1X7LiJ5MZE9F7bZ6IiIgMnn4H8FOmTOGVV15h3LhxfPzxx7S3t3PBBRe4Xj98+DCRkZEDOkkRT9ZTuU1B9YGOgH7klNtkJIRxzw3TeOTVPdz/l93803VZpMaFuntaIiIio06/u9AcPHiQZcuWUV1dDcA111zD/fffD4DD4WDevHnMmDHDNXYmNpuN1atXs2nTJurq6khPT2f58uXMmjXrjPfl5OSQnZ1NTk4O+/fvp7W1lcLCwm7XFRUV8dprr7F9+3aOHDlCQEAAEydO5J/+6Z+YOHFifz62i7rQSH+cXm5TUH2A4u90t8mwOgP62IDoYVNuc6K2iYde3UN1XTO3XzmRaakR7p5SF1orIn2jtSJyZrvKdvNG0RZqW2oJNYdyZcoCzoueNiTPHpQ+8LW1tezevZugoCDOPfdc1/jJkyd5/fXXmTFjBunp6Wd9nxUrVrB161aWLVtGQkICGzduJDc3l3Xr1jF16tRe73v88cd58sknSUtLo6mpieLi4h4D+P/6r/9iw4YNXHrppWRlZXHq1Cn++te/UlpaynPPPcfMmTP7+9EVwMsP0tJu42Btsat+/nhDOcB3ym1SCTEHuXmmZ3aq0cbqDTmUHK/jpkvTuHjqGHdPyUVrRaRvtFZEererbDcv7XuNVnura8xkNHFD+rVDEsQP6UFO/ZGTk8PixYtZuXKlq2NNS0sLCxcuJDIykhdffLHXe0+cOEFgYCC+vr786U9/Yu3atT0G8Lm5uSQlJREQEOAaq6mp4fLLL2fcuHGsW7eu3/NWAC8D6fRym9MPkxoTGOPaDJsS4pnlNi22dv68KZecoiquPD+Rq36U5BE/RdBaEekbrRWR3v3L9vuoaantNh5mDuU/z//9oD9/wPvAdzpy5Ajbtm3j6NGjAMTFxTFv3jzi4+P7dP+WLVswmUwsXrzYNWY2m7nuuut45JFHqKio6LWWPjw8vE/PyMzM7DYWFhbGOeecw5dfftmn9xAZTKHmEGbFnMOsju42x+pLO9pVHuCjo9vZduRjTEZvUjyw3Mbs48WvF01i7ZZC3th+iNp6G0svS8XLOPIPuhIRkZGnqa2Z/TVFFFTv7zF4B3odH2rfK4B/9NFHeeaZZ7p1m3nwwQe5/fbbueuuu876HgUFBd2y4wBZWVk4HA4KCgoGbTNsZWVll1aYIp7AaDASHzSW+KCxXJpwcZdym4LqA2w8+BYbeYtgnyBXdj4tbLxby228vYzcenk6oUE+bN5xmLoGG7dfNRGzDnwSEREPZ3fYOXrqG/KrnF3kSuoOY3fY8fHywWT0ptXe1u2eMLNnNG/odwC/YcMGnnzySaZOncovfvELxo8fD8CBAwd47rnnePLJJ4mLi2PRokVnfJ/KykqioqK6jUdEODfEVVRU9HdqffLFF1/w9ddf8+tf/3pQ3l9koJi9fJhoTWei1bmfpKa5ln01B9lXvZ/8qkJ2lTm727i73MZgMLDoghRCAsy89N5+HnrFeeBToJ/nlf2IiMjoVttykoKOgH1fzQEaWhsBiAsaw/z4C5lgSSUpJIHdFTk91sBfmbLAXVPvot8B/EsvvcTkyZNZt24d3t7f3h4fH8+FF17IjTfeyF/+8pezBvDNzc2YTN2/4M1mM+Cshx9oVVVV/OY3vyE+Pp6f/exn3+s9zlSPNNgiIjx7Y6MMrgiCSI2L40ouxu6wc6jmGDnlBewpy+dvxzrKbbxMTIgYR1bUBLKi04kPGTNk5TY/XZBBXEwIq178kgdf+Yp/v20WkWH+Q/Ls79JaEekbrRUZ6WxtNvIrD5JTls+esnyO1h0HINQ3mHPGZDE5OoOsqAyCfbuuhR9HXUhwsB8v52yiqrEaq7+FJVlXMSfhPHd8jG76HcAXFRWxYsWKLsG76828vbn88st5+OGHz/o+vr6+tLa2dhvvDNw7A/mB0tjYyO23305TUxPPPfcc/v7fL7DQJlbxFEGEcX74bM4Pn92t3GZd2WuwhyEvt0mNDeI310/msdf28ptHP2LFT6YwNnJo/9GrtSLSN1orMhI5HA6ON5STX13IvuoDHKwtptXe5mrffM24H3fbT9ZyCipPdV8L6f4Z/MfMjC5rZajWzIBvYjWZTDQ2Nvb6ekNDQ4+Z9e+KiIjosUymsrISYEDr3202G//v//0/9u/fz/PPP8+4ceMG7L1FPEGP5TbVByjoodwmw5JKumX8oJXbpMWHsfLGaTz86tfc/+Ju/unaSaTFa8+JiIgMjnpbA/tqDrhKY07a6gCIDojiR2NmkmFJY3xoEj5ePm6e6cDpdwA/adIk/vrXv7J48eJu3WCqqqp49dVXmTx58lnfJz09nXXr1tHQ0NBlI+uePXtcrw8Eu93OPffcw2effcZjjz3GOeecMyDvK+LJwnxDmRV7LrNiz/22u02VM6D/8OinvH/kI0xGb8aFJrsy9APZ3WZsZCD3Lj2Hh1/9mof+uodfXjGBc9J1QrOIiPxw7fZ2ik8edu4Jq97P0VPf4MCBv7ef6zstw5JKmK9nbDgdDP0O4O+44w5uueUWLr/8cq699lpXNvvgwYNkZ2fT0NDAqlWrzvo+CxYs4Pnnn2f9+vWuPvA2m43s7GymTZvm2uBaWlpKU1MTKSkp/Z0qAH/84x95++23+cMf/sD8+fO/13uIDGddutskOrvbHKgpcmXoT+9u05mdT7eMJ9jnh5XbWEN8WXnTdFZv2MOfX8/lxktTmTtt7AB9KhERGU0qG6soqC4kv3o/B2qKaG5vwWgwkhgcz4+TLiHDmkp80FiMhtHRyvh7HeT0wQcf8Mc//pHjx493GY+NjeXf/u3fuOiii/r0PnfddRfbtm3j5ptvJj4+3nUS6wsvvMD06dMBWLp0Kbt27epyUNM333zDpk2bAPj444/56quvXK0r09PTmTt3LgBr1qzh/vvvZ+rUqSxZsqTb86+66qr+fnTVwMuIc3q5zek78jvLbZzdbRIxfc9ym5bWdp7alMfXB0+wcHYC18xJHtSNtVorIn2jtSKe7PSe7AVVhZxorgbA6hvm/G6yppEWloKft9+gz8Uda2XQTmK12+3k5uZy7NgxwHmQ08SJE3n11VdZu3Ytb7/99lnfo6WlhUcffZQ333yTkydPkpaWxooVK5g9e7brmp4C+J07d7Js2bIe3/Oaa67hgQceAOB3v/sdGzdu7PX5PZ3eejYK4GUkszvsHDtV6gzmqw9QdPIQ7Y72H1xu0263s+7dQj7ec5wfZcVw84K0QTvwSWtFpG+0VsSTnKkne1pYChmWNDIs44nwCx/ywwxHVADfmz//+c889thjFBQUDOTbegwF8DKaNLe1cLC22JWhL2t0bjwP8QkivZ/lNg6Hg02flvDG9kNkpVj51VWZmH0G/sAnrRWRvtFaEXc7U0/2DEuqqye7t/F7nTs6YDwxgHfvn4iIeDRfbzOZ4RlkhmcAznKbguoD7KveT25VATvLvgRgbGDsaYdJ9VxuYzAYuHpOMiGBZv6ytZAHX/mKu67LIsh/5HQFEBGR3tnaW09rebyf4w3lgLPlcaY1w7UPK8jHfWfuDBcK4EWkz8J8Q5kdey6zO7vbdJTb9NTdprN+PiYgqsuPOy+eOoZgfx+eeiOP+/+ymxU/mUx46ODXMIqIyNA6W0/2mTHnDHgXtNFCAbyIfC9Gg5H44LHEB4/lssS53cptsg9uBnout5meFsFvfzqFxzbk8Ke/fMnyxZOJj9KJkCIiw91o7MnuDgrgRWRA9KfcpvPHpP98QxaPbcjjv17aza8XZZGRoAOfRESGE/Vkd48+BfD/93//1+c33L179/eejIiMHGcqt/ng6Ce8d+RvmIwmEmYk8E2JH4+8cZKfzzuPGROi3T11ERE5A/Vkd78+daHp76moBoNBXWgGmLoFyEjSWW7jDOgPUN7R3cZhM5MQkMTc8VO/90YmrRWRvtFakb7ypJ7s7jBsu9CsXbt2wCYkItJTuU1uZSFv5X3B4aYi1uTvA7qW2/yQw6RERKTvztaTfW78BW7ryS5OA94HfqRTBl5k8NjtDtZtLeDjA4UkjW8hIKKGkrojHYdJmRgfmkyGZTzpPXS32VW2mzeKtlDbUkuoOZQrUxZwXvQ0N34aEc+m7xU53XDpye4OwzYDLyIyFIxGA8suyyAsyI/XPylhUnIG/3nFzRxpOOwqt3nN1d0m2LVBqqmtmeyDm2m1twJQ01LLS/teA1AQLyLSA/VkH94UwIuIRzEYDFx5fhKhgWZe2LKP1a/auGvxZFe5TXVzjatVZe6Jb7vbfFervZU3irYogBcRQT3ZRxqV0PSTSmhEhs5XByp5clMeliAzy6+fQuR3DnzqrNP87y8e7/U9ZkRPJzYwmpiAaGIDogg1h+jLSQR9r4wGZ+rJnmEZr57sfeSJJTQK4PtJAbzI0Dp47CSrN+zBy8vI8sWTSYjufuDTv2y/j5qW2m7j3kZvArz9OGn7du34efsRGxBFTGA0sR1BfUxgNIGmgEH9HCKeRt8rI496sg8OBfAjgAJ4kaFXeqKBh1/9msbmNu5cNImJiZYur+8q281L+15z1cADmIwmbki/lvOip1Hf2sDx+nKON5RR2lBOaf1xShvKaWprcl0f7BPkDOg7s/WBUUT7R+HrbR6yzykylPS9MjKcqSf7BEuqerIPAAXwI4ACeBH3qDnVwsOvfk1ZVSO/WDiBGROiurze3y40DoeDk7Y6SuvLKG0o43h9ufPXhvIu/xCw+lqIDYwiNiDGla2P8o8YlZ0YZGTR98rwNNp7sruDAvgRQAG8iPs0Nrfy2Gt72X+0lp/OG8+l58Z1u+aHrhW7w86Jpmpntt6VtS+jvLESu8MOgNFgJNI/gtiAKGIDol3lOOF+FmW5ZNjQ98rwcLae7BmWNPVkH2QK4EcABfAi7tXa1s7Tb+bzZWElC2bEc91FKRhP+9IarLXSZm+jvLGS4/UdZTgNZRyvL3Nlv8BZthMTENlRgqONs+LZ9L3iudST3bN4YgCv/+dFZFgxeXvxq6syefH9/WzZeYST9S3cenkG3l6Dm/n2NnozJjCGMYExXcab21oob6xwleKU1pexr3p/l/aW2jgrImeinuzSXwrgRWTYMRoN3HRJKqGBZjZ+XExdYyvnpEWwecchqutasASbWXRhCrMmRg/6XHy9zSQEx5EQ3LWcp6eNs1+W7+HTts9d12jjrMjodHpP9oKq/Rw8WUKberJLP6iEpp9UQiPiWT7ZU8r/vbMPA3D6yvTxNnLzP6QPSRDfV9o4K55E3ytDq97WwL6OE6W79GT3jyTDmqqe7B5MJTQiIgNszuRYNnxUxKnG1i7jtjY72R8VeVQAbzAYCDWHEGoOYYI1zTXe28bZvKpCbZwVGaY6e7J3lsWoJ7sMJAXwIjLsfTd471RV18LxqgaiLf4e/WNoZ3AeTqR/OJMjMl3jPW2cPVJ3jN0VOa5rtHFWxHNUNJ5wHaK0v+YgLe02V0/2HyddQrollYRg9WSXH04BvIgMe9ZgM1V1LT2+du8zO7EGm5mYZCUzyUJGYhgBvqYhnuH3o42zIp7N2ZP9oLMs5js92c+NmkqGNY3U0BT8TerJLgNLNfD9pBp4Ec/zWV4ZL7yzD1ub3TXm423kmguTMXt7kVdSTf7hGppa2jAYIDkmmIlJFjKTrCTFBuFlHBnZMJ04K/2h75X+O1tP9vSOFo/qyT6yeGINvFsDeJvNxurVq9m0aRN1dXWkp6ezfPlyZs2adcb7cnJyyM7OJicnh/3799Pa2kphYWGP19rtdp577jlefvllKisrSUxM5Fe/+hWXX37595qzAngRz/RZXhnZHxX12oWm3W6nuLSOvJJqckuqKTleh8MB/mZvMhLDOgJ6C+EhIytT1t+NszEB0YzpqLHXxtmRTd8rfXO2nuwZllSS1ZN9RFMA/x0rVqxg69atLFu2jISEBDZu3Ehubi7r1q1j6tSpvd73+OOP8+STT5KWlkZTUxPFxcW9BvAPPfQQTz/9NNdffz2ZmZls27aNv/3tb6xevZoFCxb0e84K4EU8W1/XSn1TKwWHa8grqSK3pJrqjhKcKIs/mUkWJiZZSI8PxddnZH4p68RZ0fdKz87Uk70zYFdP9tFFAfxpcnJyWLx4MStXruSWW24BoKWlhYULFxIZGcmLL77Y670nTpwgMDAQX19f/vSnP7F27doeA/jy8nLmzZvHkiVLuPfeewFnNuqmm27i+PHjvP/++xj7+aNzBfAinu37rBWHw8HxqkZXdr7wSA22NjteRgPjx4a4ym3iogK7nPo6EunE2dFD3ytOZ+vJnm4ZzwRrmnqyj2KeGMC7LbW0ZcsWTCYTixcvdo2ZzWauu+46HnnkESoqKoiMjOzx3vDw8D494/3336e1tZUbbrjBNWYwGFiyZAm/+c1vyMnJYcqUKT/sg4jIsGcwGIgNDyA2PIBLzo2jta2dA8dOkltSTV5JNa99VMxrHxUT7G9iQkepzcRECyGBI69uXBtnZTQ4U0/2OWNmqie7eDy3BfAFBQUkJSUREND1L/asrCwcDgcFBQW9BvD9eUZgYCBJSUndngGQn5+vAF5EujF5ezEh0cKERAtcDCfrW8g7VO0K6D/Pc/5IPS4y0FU7P35sCCZvLzfPfPDoxFkZztSTXUYatwXwlZWVREVFdRuPiIgAoKKiYkCe0VO2fiCfISIjX0igmdmZMczOjMHucHC0vJ7ckirySqp57+9H2bLzCD7eRtLiw1z18zFWz+49P1ACTQGMD0tmfFiya6y3jbOffPN5rxtnOwN8bZyVgaKe7DKSue1vyebmZkym7r2YzWZnRqalpeeezv19ho9P9x9//ZBnnKkeabBFRAS57dkiw8lgr5WoyGDOmRQLQFNLG7lFJ9hdWMFXhZW8vO0AAOGhfkxNjWBaeiSTx0cQ5D+6fhQfSTDjGdtlzG63U9FwgiMnSzl62v/yqwpp79g462UwEhMURVxILHEhscR3/BoVEN7vPUtydiPpe6WxtYnc8kJyygrYU5ZPecMJACICrMxJnMGU6AlMjEwlwMffzTOV4cjT1orbAnhfX19aW7ufntgZVHcG2T/0GTabbUCfoU2sIp7NHWslMSKAxIgkFv0oiRO1TeQecpbafLqnlPd2HcFggKSYYFd2Pjk2eMT0nu8vL/xIMqeQFJkCHVWSPW2cPVBZwmdHv62v18bZgTfcv1fO1pP9gjHnd+vJ3niynUaG72cW99Am1tNERET0WMJSWVkJ8IPr3zuf8cUXXwzqM0REThce6sdFU8Zw0ZQxtNvtlBw/RW5xFXmHqnlzxyHe2H4IP7MXGQkWV0AfETqyes/3lzbOSl+dqSf7/PgL1ZNdRg23/Reenp7OunXraGho6LKRdc+ePa7Xf6iMjAzWr19PSUlJl42snc/IyMj4wc8QEemNl9HIuDEhjBsTwtVzkmlobqXgUE3HZtgqdu93JhOiwvzITLI6e88njNze8/2ljbNypp7smdYM9WSXUctt3xILFizg+eefZ/369a4+8DabjezsbKZNm+ba4FpaWkpTUxMpKSn9fsa8efO4//77eemll7r0gX/llVeIjY1l8uTJA/Z5RETOJsDXxDnpkZyTHonD4aCsutHV2eaTvaVs230ML6OBcWNCyEwePb3n+0sbZ0eus/VknxE9XT3ZRXBjAD958mQWLFjAqlWrqKysJD4+no0bN1JaWsr999/vuu6ee+5h165dXQ5q+uabb9i0aRMAe/fuBeCJJ54AnJn7uXPnAhAdHc2yZct4/vnnaWlpYdKkSbz//vt88cUXPPLII9oQJSJuYzAYiLEGEGMN4JJz4mhts3PwWK2zfr74297zQf4mJiY6S20mJlkIHYG95weCwWAg1BxCqDmECdY013hvJ87mVRWe5cTZKML9rOpQMgTUk12k/9x2Eis4N5M++uijvPnmm5w8eZK0tDRWrFjB7NmzXdcsXbq0WwC/c+dOli1b1uN7XnPNNTzwwAOu39vtdp555hn++te/UlFRQVJSErfffjsLFy78XnPWJlYRzzZS1srJBhv5JdWudpV1jc4s8tiIAGe5TbKF1BHee34w6cRZ960V9WSX4cYTN7G6NYAfjhTAi3i2kbhW7A4HxyrqyStxHiZ14Fgtbe0OfLyNpMaHkploYWKyldhR0nt+MPW0cfZ4Qxknbd/+N+Xn7esK6ofzxtmhXCtn6sk+wZKqnuzi0RTAjwAK4EU822hYKy22dgqP1pBbXE3eoWqOVzk7cYQFmV0nw05ItBDo1/2sDfl+eto4W9pQTlNbk+ua4bZxdjDXSlNbM/trDjrLYqoKXT/ZsPqGOTPs1jRSQ1PwN43uDkwyPCiAHwEUwIt4ttG4Vk6cbCL/UA25xVXkH6qhsaUNA5AYE+wK6JNjg/H2UnZzIPW2cfZ4Q/mw2Dg7kGvlbD3Z0y2p3XqyiwwXCuBHAAXwIp5ttK8Vu91ByfE6V3ebotKTOBzgZ/YiPT6MzGRnu8rIUd57fjD1tnG2vLHSozbO/tC1cqae7J117OrJLiOBAvgRQAG8iGfTWumqsbmVgsPO3vO5xdVU1TUDEBnm58rOp8eH4WdWkDXYPG3jbH/Xypl6sncG7OrJLiORAvgRQAG8iGfTWumdw+GgvKbJeTJsSTX7jtTS0tqOl9FAypgQ18mwCdFB6j0/hNy1cfZsa+VsPdnTLePVk11GBQXwI4ACeBHPprXSd61tdoq+OenMzpdUcaS8HoBAPxMTEsNcp8OGBXnmJsyRrj8bZ2MCo4gNiOnTxtldZbt5o2gLtS21hJpDuTJlAedFT3M+8ww92TOsqerJLqOSAvgRQAG8iGfTWvn+6hps5B1y1s7nlVRzssEGwJiIAFd2PnVsKD4m9Z53lx+6cXZ3RQ4v7Xuty7XeBm8yLKmctNWpJ7tIDxTAjwAK4EU8m9bKwHA4HByrbHAdJLX/qLP3vMnbSGpcKJkd9fOx4QEqn/AAfd0423ltT5JDEtWTXaQHCuBHAAXwIp5Na2VwtLS2U3iktuMwqaquvecTndn5iUnqPe9pvrtx9t3DH/R67f/O/e8hnJnI8OGJAbzaDoiIyFmZTV5kpVjJSrEC46mua+6ona/mqwOVfLr3eEfv+aCO7jZW9Z73AN5Gb8YExjAmMAZw1r/XtNR2uy7MrBIZkeFEGfh+UgZexLNprQw9u91BSVldR3a+muJv6rA7HPj6eJGREOZqVxkZ5u/uqY56u8p2d6uBNxlN3JB+rWsjq4h0pQy8iIiMOEajgZTYEFJiQ7jy/KSO3vO15JVUdWToTwAQGXpa7/kE9Z53h84gvbcuNCIyPCgD30/KwIt4Nq0Vz+JwOKioaXKdDFtwuObb3vOxwc6APtlKQlQQRqM2ww4lrRWRvlEGXkRERhWDwUCUxZ8oiz/zpo+lrf303vPVbPykhI2flLh6z3fWz6v3vIhI7xTAi4jIkPH2MpIWH0ZafBjXXphCXaON/EPV5BVXk3uoml0FFQCMCQ9wldukxqn3vIjI6RTAi4iI2wT7+zBzQjQzJ0TjcDj4prKho9ymig92f8PWvx91Bv1xIUxMspKZZGFMhHrPi8jophr4flINvIhn01oZOVpa2zlwtNZVblN6ogGA0EAfV9/5iYkWgvx93DzT4UlHY1QiAAAgAElEQVRrRaRvVAMvIiLSR2aTF5nJVjKTrQBU1zWTV1JN3qFqvj5wgu17yzAA8dFBrpNhU8aEqPe8iIx4CuBFRGRYsAT7MmdyLHMmx2K3OzhUdsrVqvKdz4/w1meHMft4kRHfsRk22UJkqJ/KbURkxFEALyIiw47RaCA5Npjk2GCuOD+JppY2Cg7XdBwmVcXXB52958NDfMlMtjIx0UJGQhj+vvraE5HhT3+TiYjIsOdn9mZaagTTUiMAqKhpdNbOF1fzWV4Zf/vqG4wGAyljgl2tKhOj1XteRIYnbWLtJ21iFfFsWivyXZ295/MOOQP6w2WncAABvt5MSLS42lVagn3dPdUhpbUi0jfaxPodNpuN1atXs2nTJurq6khPT2f58uXMmjXrrPeWl5dz3333sX37dux2OzNnzmTlypXExcV1ue7UqVM88cQTbNu2jbKyMsLDw/nRj37EnXfeSVRU1GB9NBER8RCn955fdEEKpxpt5B+qIbekirySav6+z9l7PjY8gImJztr51LhQzOo9LyIeyq0Z+BUrVrB161aWLVtGQkICGzduJDc3l3Xr1jF16tRe72toaGDRokU0NDRwyy234O3tzZo1azAYDLz++uuEhIQAYLfb+elPf8qBAwdYsmQJSUlJlJSU8PLLLxMREcHmzZvx8elf+zFl4EU8m9aK9IfD4eCbEw0dtfPV7D9aS2ubHW8vI6lxIa5ym7EjsPe81opI3ygDf5qcnBzeeustVq5cyS233ALA1VdfzcKFC1m1ahUvvvhir/e+9NJLHD58mOzsbCZMmADAnDlzuOKKK1izZg133XUXAHv37mXPnj3827/9GzfeeKPr/tjYWP74xz+ye/duZs6cOXgfUkREPJrBYGBsRCBjIwK57Lx4bK3t7D9WS26xs13l+g+LWP9hESEBPq5SmwmJFoID1HteRNzHbQH8li1bMJlMLF682DVmNpu57rrreOSRR6ioqCAyMrLHe999912mTJniCt4BUlJSmDVrFu+8844rgK+vrwfAarV2uT88PBwAX9/RVe8oIiJn5mPyIjPJSmaS83uj5lSLq7NNTlEVO3LLAEiICiIz2XmQ1Lix6j0vIkPLbQF8QUEBSUlJBAQEdBnPysrC4XBQUFDQYwBvt9spLCzk+uuv7/bapEmT2L59O01NTfj5+TFx4kT8/f1ZvXo1ISEhJCcnU1xczOrVq5kxYwaTJ08etM8nIiLDX1iQmR9lxfCjrBjsdgeHy0+RW1JNXkk1W3Z29J43eZEeH+o8dCrJQmSYes+LyOByWwBfWVnZ4ybSiIiOFmAVFT3eV1tbi81mc1333XsdDgeVlZXEx8cTGhrKI488wr/8y7+4ynQALr74Yh599FH9BSsiIn1mNBpIigkmKSaYK2Yn0tTSxr4jNc6AvriaPUVVQEfv+SRnd5uMBIt6z4vIgHPb3yrNzc2YTKZu42azGYCWlpYe7+sc72nzaee9zc3NrjGLxUJmZiZTp04lJSWFffv28eyzz/L73/+ehx9+uN/zPtOGgsEWERHktmeLDCdaKzJU4seGcensZACOn2jgq/0VfFVYwc6CCv72dSlGo4G0+DCmpkUyNS2C8XFheHlQ73mtFZG+8bS14rYA3tfXl9bW1m7jnQF6ZzD+XZ3jNput13s7a9uPHj3KsmXLWLVqFfPnzwdg/vz5jBkzht/97ndce+21nH/++f2at7rQiHg2rRVxF2/g3PHhnDs+nLZ2O8WldR3lNlW8/O4+Xnp3HwG+3mQkOjfDurv3vNaKSN+oC81pIiIieiyTqaysBOh1A2toaCg+Pj6u6757r8FgcJXXZGdnY7PZuPDCC7tcN3fuXAB2797d7wBeRETkbJxtKENJjQtl0QXJ1De1kn+o2lU//0VH7/kYq7+ru01aXBhmH/WeF5Gzc1sAn56ezrp162hoaOiykXXPnj2u13tiNBpJTU0lNze322s5OTkkJCTg5+cHQFVVFQ6Hg++2um9ra+vyq4iIyGAK9DNxXkYU52VE4XA4KK1qJK+4itySaj76upT3vziGt5eB8WNDXfXzcZGB2qslIj1yW9+rBQsW0Nrayvr1611jNpuN7Oxspk2b5trgWlpaSlFRUZd7L7vsMr7++mvy8/NdY8XFxXz++ecsWLDANZaYmIjdbuedd97pcv/mzZsBurShFBERGQoGg4Ex4QFcel48K66fwv/cPYffXD+F+dPjONVoY/3fivj3//s7y/9nO8+8mc9neWXUNXQvGxWR0cutJ7HeddddbNu2jZtvvpn4+HjXSawvvPAC06dPB2Dp0qXs2rWLwsJC13319fVcc801NDU1ceutt+Ll5cWaNWtwOBy8/vrrhIWFAVBTU8MVV1xBbW0tS5YsYdy4ceTl5bFhwwbGjRvHa6+91uNG2jNRDbyIZ9NakeGu5lRLl3Kb+ibnfrH4qEDXybDjB6D3vNaKSN94Yg28WwP4lpYWHn30Ud58801OnjxJWloaK1asYPbs2a5regrgAcrKyrjvvvvYvn07drudGTNmcO+99xIXF9fluvLyclavXs3OnTspLy8nNDSUuXPnsnz5cleg3x8K4EU8m9aKjCR2h4Mj5aech0kVV3Pwm5O02x2YTV6kxX9bbhNt8e93uY3WikjfKIAfARTAi3g2rRUZyZpa2ig8UktuSRV5JdWU1zQBYA32dW2GzUgMI8D37D9d1loR6RtPDOB1uoSIiMgw4Wf2Zsr4cKaMDwegsrbJmZ0vqebv+8r5eE8pBgMkxwaTmWRlYpKFpJggvIzfltt8lldG9kdFVNe1YAk2s+jCFGZNjHbXRxKR70EZ+H5SBl7Es2mtyGjV1m6n5HgducXV5B2qpqS0Dgfgb/YmIzGMzCQLLa3tZH9UjK3N7rrPx9vIzf+QriBepBfKwIuIiMig8PYyMn5sKOPHhnJNR+/5gsM15Ha0q/yysPv5KQC2NjvZHxUpgBcZRhTAi4iIjECBfibOTY/k3PRIHA4Hx6sa+Zdnd/Z4bVVdCxU1jUSG+Q/xLEXk+1AALyIiMsIZDAZiwwOwBpupqmvp8ZrfPfU5UWF+TEqxkpVsJS0+FJO3ToYV8UQK4EVEREaJRRem8MI7+7rVwF9zQRLeXl7kFFW5Tob18TaSnhDGpGQrWSlWIkL93DhzETmdAngREZFRorPOvbcuNPOmj8XW2k7h0VpyiqrYW1RFTlEVL74H0RZ/slKsTEq2khoXisnbbYe5i4x66kLTT+pCI+LZtFZE+qava6W8upGcYmcwv+9ILW3tdnxMRiYkWJiUbGFSspVwZedlBFMXGhERERlWoiz+XGLx55Jz4mhpbafwSA05HZn5rw+eACDG2jU77+2l7LzIYFIALyIiIn1iNnmRlRJOVko4DoeDsupG9hZXs7foBNu+PMa7u45i9vFiQkft/KRkK9YQX3dPW2TEUQAvIiIi/WYwGIixBhBjDeDSc+NosbVTcLiGvcXO7PxXB5zZ+THhAUzqyM6PHxui7LzIAFAALyIiIj+Y2ceLKePDmTI+3NV3vjOYf+/vR9my8wi+Pl5MSPy2dt4SrOy8yPehAF5EREQGVGff+djwAC47L56mljb2dWTn9xZXsXu/81TYsREBrr7zKWOUnRfpKwXwIiIiMqj8zN5MTY1gamoEDoeD0hMN7C2uJqfoBFt3HeWdz4/gZ+7MzjvLbcKCzO6etojHUgAvIiIiQ8ZgMDAmIpAxEYEsmOHMzucf+jY7/2WhMzsfFxno6myTMiYYL6Oy8yKdFMCLiIiI2/iZvZmeFsH0NGd2/pvKBlft/JadR3jrs8P4m72ZkPRt7XxooLLzMropgBcRERGPYDAYGBsZyNjIQP5hZgKNzW3kH6p2BvTFVXyxrwKA+Khvs/PJscrOy+ijAF5EREQ8kr+vN+ekR3JOeiQOh4OjFfXOUpuiKt7+7AibdxwmwNebiUnOzHxmspWQAB93T1tk0CmAFxEREY9nMBiIjwoiPiqIH89KpLG5lbxDNewtctbO7ypwZucTo4OcG2FTrCTHBGM0Gtw8c5GBpwBeREREhh1/XxPnpkdybnokdoeDo+X15HRshN382SHe3HGIAF9vMpOdbSonJlsI9ld2XkYGBfAiIiIyrBkNBhKig0iIDuKK2YnUN7U6a+c7svM788sxAIkxwc6NsClWkqKVnZfhSwG8iIiIjCiBfibOy4jivIwo7A4HR8pPkdMRzL+5/RBvbD9EoJ+JzGSLMzufZCFI2XkZRhTAi4iIyIhlNBhIjA4mMTqYK89Por6pldySKvYWVZNbUsXnec7sfHJssKt2PiE6CKNB2XnxXG4N4G02G6tXr2bTpk3U1dWRnp7O8uXLmTVr1lnvLS8v57777mP79u3Y7XZmzpzJypUriYuL63ZtRUUFq1ev5qOPPuLkyZNERUUxb948Vq5cORgfS0RERDxUoJ+JmROimTkhGrvDweGyb7Pzmz4t4fVPSwjyN5GZZCUrxZmdD/QzuXvaIl0YHA6Hw10PX7FiBVu3bmXZsmUkJCSwceNGcnNzWbduHVOnTu31voaGBhYtWkRDQwO33HIL3t7erFmzBoPBwOuvv05ISIjr2m+++YYlS5YQGBjI1VdfTVhYGGVlZZSUlPDwww/3e85VVfXY7UP/RxYREURl5akhf67IcKO1ItI3Wivd1TXayCtx1s7nllRT39SKwQApsSFMSraQlRJOXFSgsvOjjDvWitFowGoN7PV1twXwOTk5LF68mJUrV3LLLbcA0NLSwsKFC4mMjOTFF1/s9d5nnnmGhx56iOzsbCZMmABAUVERV1xxBbfffjt33XWX69qf//znnDp1irVr1+Lr6/uD560AXsSzaa2I9I3WypnZ7Q5KyupcG2FLjjv/rIIDfJiU5NwIOzHJQoCvsvMjnScG8G4rodmyZQsmk4nFixe7xsxmM9dddx2PPPIIFRUVREZG9njvu+++y5QpU1zBO0BKSgqzZs3inXfecQXwRUVFfPrppzz99NP4+vrS1NSEyWTC21ul/yIiItI7o9FASmwIKbEhXD0nmboGG7klVeQUVfH1wRNszy3DaDCQMsZZO5+VYiUuMhCDsvMyBNwWyRYUFJCUlERAQECX8aysLBwOBwUFBT0G8Ha7ncLCQq6//vpur02aNInt27fT1NSEn58fO3bsAMDHx4dFixaRl5eHyWRi7ty5/Pu//zsWi2VwPpyIiIiMKMEBPszOjGF2Zgx2u4Pi43Wu2vnsj4vJ/riYkEAfJnXUzk9ItODvq4ShDA63/ZdVWVlJVFRUt/GIiAjAufG0J7W1tdhsNtd1373X4XBQWVlJfHw8hw8fBuDuu+/mRz/6EbfffjsHDx7kySef5NixY6xfvx4vL69+zftMP84YbBERQW57tshworUi0jdaK99fVFQws6aMBaCmrpndhRV8UVDOV/sr+XTvcYxGAxmJFqanR3JORhSJMcHKzg9jnrZW3BbANzc3YzJ1rxszm82Asx6+J53jPj7d+7V23tvc3AxAY2Mj4MzMP/TQQwBcdtllhIaG8oc//IEPP/yQ+fPn92veqoEX8WxaKyJ9o7UysLISw8hKDKP9slSKS7/Nzq99u4C1bxcQFmQmM8niys77mZWdHy5UA38aX19fWltbu413Buidwfh3dY7bbLZe7+3crNr568KFC7tcd+WVV/KHP/yB3bt39zuAFxEREemNl9HI+LGhjB8byrUXplBb38Le4ir2FlXxRWEln+Qcx8toYPzYEFff+THhAcrOS7+4LYCPiIjosUymsrISoNcNrKGhofj4+Liu++69BoPBVV7T+avVau1yXVBQED4+PtTV1f2gzyAiIiJyJqGBZuZkxTInK5a2dnuX7Pz6vxWx/m9FhAWZXRthMxLClJ2Xs3LbfyHp6emsW7eOhoaGLhtZ9+zZ43q9J0ajkdTUVHJzc7u9lpOTQ0JCAn5+fgBMnDgRcB76dLrq6mpsNps2sYqIiMiQ8fYykhoXSmpcKNddlELNqW+z87sKyvl4TyleRgOpcaGu7Hys1V/ZeenG6K4HL1iwgNbWVtavX+8as9lsZGdnM23aNNcG19LSUoqKirrce9lll/H111+Tn5/vGisuLubzzz9nwYIFrrEZM2YQFhZGdnY2drvdNd75zL6c+CoiIiIyGMKCzFwwOZY7F03isbvmcM8NU7n03DhONdp49cOD/OuzO/n//ryDte8W8tWBSpptbe6esngIt57Eetddd7Ft2zZuvvlm4uPjXSexvvDCC0yfPh2ApUuXsmvXLgoLC1331dfXc80119DU1MStt96Kl5cXa9asweFw8PrrrxMWFua6dsOGDdx7773Mnj2b+fPnU1RUxMsvv8wFF1zAU0891e85axOriGfTWhHpG60Vz1Zd18zeYmff+fzDNbTY2vH2+jY7n5ViJdqi7PxQ8MRNrG4N4FtaWnj00Ud58803OXnyJGlpaaxYsYLZs2e7rukpgAcoKyvjvvvuY/v27djtdmbMmMG9995LXFxct+ds2rSJZ599lpKSEkJDQ1m4cCF333339zqZVQG8iGfTWhHpG62V4aOt3c6Bo7XsLa4mp7iK0hMNAISH+DIpxcqkZCsZ8WGYffrXGlv6RgH8CKAAXsSzaa2I9I3WyvB14mQTucXV5BRVUXC4hpbWdry9jKTFf5udjwrzU3Z+gCiAHwEUwIt4Nq0Vkb7RWhkZWtvs7D9Wy96OzjbHq5xn4ESE+pKVHM6kFAtp8WGYTcrOf18K4EcABfAink1rRaRvtFZGphO1Ta7a+YIjNdha7Zi8v5ud93f3NIcVBfAjgAJ4Ec+mtSLSN1orI19rWzuFR2vZW+SsnS+vdmbnI8P8yOpoU5kWF4qPsvNn5IkBvE4KEBERERmBTN5eZCZZyUyysoTxVNQ0sre4mr3FVXy8p5T3vzyGj7eR9IQwV9/5yFA/d09b+kABvIiIiMgoEBnmz7zp/sybPhZba2d2voqcjpIb3oMoi39Hdt5CWlwoJm9l5z2RAngRERGRUcbH5OXMuidbuQEor24kp9i5EfZvX3/De18cxcdkJCM+jEkpVrKSrYQrO+8xFMCLiIiIjHJRFn8usfhzyTlxtLS2U3ikpqN2/gR7iqoAiLH6u0ptUseGYvI2unnWo5cCeBERERFxMZu8yEoJJyslnBsc4ymvaSKno03lB7uPsfXvRzGbvMhICOs4SMpCeIiy80NJAbyIiIiI9MhgMBBt8Sfa4s+l58bRYmun4EgNe4ur2FtUxdcHTwAQGx7grJ1PtjA+LhRvL2XnB5MCeBERERHpE7OPF1PGhTNlXDgOh4Oy6kZXdv69L46yZdcRzD5eTEgIIyvFWWNvCfZ197RHHAXwIiIiItJvBoOBGGsAMdYALjsvnmZbGwWHa5ytKotO8NUBZ3Z+TERndt7KuLEhys4PAAXwIiIiIvKD+fp4M3V8BFPHR+BwpFJa1cjejuz81r8f5Z2dR/AzezEhwdJRO28lLMjs7mkPSwrgRURERGRAGQwGxoQHMCY8gAUz4mlqcWbnO8ttvtxfCcDYiMCOUhsLKWOUne8rBfAiIiIiMqj8zN5MS41gWmoEDoeDbyobnBthi6t4d9cR3v78MH5mbyYmhrmy86GBys73RgG8iIiIiAwZg8HA2MhAxkYG8g8zE2hqaSP/ULUrO/9FoTM7Hx8Z6ArmU8YE42VUdr6TAngRERERcRs/szfT0yKZnhaJw+HgaEV9R3a+mnc+P8Jbnx3G3+zNxCQLWSlWMpOthAT4uHvabqUAXkREREQ8gsFgID4qiPioIH48K5HG5lbyD31bO//3fRUAJEQFMSnFSlayleTYYIxGg5tnPrQUwIuIiIiIR/L3NXFOeiTnpDuz80fK61218299dojNOw4R4Htadj7JSvAoyM4rgBcRERERj2cwGEiIDiIhOoiFsxNpaG4lr6Ta2aqypJpdBRUYgIToINchUkkxIzM7rwBeRERERIadAF8T52VEcV5GFHaHgyPlp9hbVEVOcRVv7jjEG9sPEehnIjPJ2Xc+M8lCkP/IyM4rgBcRERGRYc1oMJAYHUxidDBXnJ9EfZMzO59TVEVuSRWf55djAJJig5nUcSpsYkwQRsPwzM4bHA6Hw92TGE6qquqx24f+jywiIojKylND/lyR4UZrRaRvtFZktLA7HBwu+zY7X1JahwMI8j89O28l0M/U5b7P8srI/qiI6roWLMFmFl2YwqyJ0UMyZ6PRgNUa2Ovrbg3gbTYbq1evZtOmTdTV1ZGens7y5cuZNWvWWe8tLy/nvvvuY/v27djtdmbOnMnKlSuJi4vr9Z49e/Zw/fXX43A4+Pvf/05wcHC/56wAXsSzaa2I9I3WioxWpxptzux8cRW5xdXUN7ViMEDyadn541UNrN1SiK3N7rrPx9vIzf+QPiRBvEcH8CtWrGDr1q0sW7aMhIQENm7cSG5uLuvWrWPq1Km93tfQ0MCiRYtoaGjglltuwdvbmzVr1mAwGHj99dcJCQnpdo/D4eAnP/kJBw8epLGxUQG8yAiltSLSN1orImC3Oygpq3NuhC2u4tDxUzgAgwF6ipCtwWYevOP8QZ/X2QJ4t9XA5+Tk8NZbb7Fy5UpuueUWAK6++moWLlzIqlWrePHFF3u996WXXuLw4cNkZ2czYcIEAObMmcMVV1zBmjVruOuuu7rds3HjRo4cOcK1117LunXrBuUziYiIiMjwYTQaSIkNISU2hKvnJFPXaCOvuJpnNuf3eH1VXcsQz7BnbjuTdsuWLZhMJhYvXuwaM5vNXHfddXz55ZdUVFT0eu+7777LlClTXME7QEpKCrNmzeKdd97pdn19fT0PP/wwv/71r3vMzouIiIiIBPv7MCszGmuwucfXexsfam4L4AsKCkhKSiIgIKDLeFZWFg6Hg4KCgh7vs9vtFBYWkpmZ2e21SZMmcejQIZqamrqMP/HEEwQGBrJkyZKB+wAiIiIiMiItujAFH++uYbKPt5FFF6a4aUZduS2Ar6ysJDIystt4REQEQK8Z+NraWmw2m+u6797rcDiorKx0jR06dIi1a9dyzz334O2trpkiIiIicmazJkZz8z+kYw02Y8CZeR+qDax94baItrm5GZPJ1G3cbHb+aKKlpecao85xH5/ujfg7721ubnaN3X///Zx77rlcfPHFP3jOwBk3FAy2iIggtz1bZDjRWhHpG60Vkd5deVEQV1403t3T6JHbAnhfX19aW1u7jXcG6J3B+Hd1jttstl7v9fX1BeDjjz/mk08+YePGjQMyZ1AXGhFPp7Ui0jdaKyJ944614rFdaCIiInosk+ksf+mpvAYgNDQUHx+fLmUyp99rMBhc5TUPPvggc+fOJSAggGPHjgFQV1cHQGlpKc3Nzb0+R0RERETEE7ktgE9PT2fdunU0NDR02ci6Z88e1+s9MRqNpKamkpub2+21nJwcEhIS8PPzA+D48ePs37+f9957r9u1V111FZMnT+bVV18diI8jIiIiIjIk3BbAL1iwgOeff57169e7+sDbbDays7OZNm0aUVFRgDNT3tTURErKt7t+L7vsMh5++GHy8/NdrSSLi4v5/PPPue2221zXrVq1ira2ti7Pfeutt3j77bd58MEHiYmJGeRPKSIiIiIysNwWwE+ePJkFCxawatUqKisriY+PZ+PGjZSWlnL//fe7rrvnnnvYtWsXhYWFrrEbbriB9evX88tf/pJbb70VLy8v1qxZQ0REhOsfAwAXXXRRt+d2tqe86KKLvtdJrCIiIiIi7uTWvor//d//zaOPPsqmTZs4efIkaWlpPP3000yfPv2M9wUGBrJu3Truu+8+nnjiCex2OzNmzODee+8lLCxsiGYvIiIiIjL0DA6HY+hbqgxj6kIj4tm0VkT6RmtFpG88sQuN2w5yEhERERGR/lMALyIiIiIyjLi1Bn44MhoNo/LZIsOJ1opI32itiPTNUK+Vsz1PNfAiIiIiIsOISmhERERERIYRBfAiIiIiIsOIAngRERERkWFEAbyIiIiIyDCiAF5EREREZBhRAC8iIiIiMowogBcRERERGUYUwIuIiIiIDCMK4EVEREREhhEF8CIiIiIiw4i3uycgPauoqGDt2rXs2bOH3NxcGhsbWbt2LTNmzHD31EQ8Sk5ODhs3bmTnzp2UlpYSGhrK1KlTufvuu0lISHD39EQ8xt69e3nyySfJz8+nqqqKoKAg0tPTufPOO5k2bZq7pyfisZ555hlWrVpFeno6mzZtcvd0AAXwHqukpIRnnnmGhIQE0tLS+Oqrr9w9JRGP9Oyzz7J7924WLFhAWloalZWVvPjii1x99dVs2LCBlJQUd09RxCMcPXqU9vZ2Fi9eTEREBKdOneLNN9/kpptu4plnnuH888939xRFPE5lZSV//vOf8ff3d/dUujA4HA6Huych3dXX19Pa2kpYWBjvv/8+d955pzLwIj3YvXs3mZmZ+Pj4uMYOHTrEFVdcwY9//GMeeOABN85OxLM1NTUxf/58MjMzeeqpp9w9HRGP87vf/Y7S0lIcDgd1dXUek4FXDbyHCgwMJCwszN3TEPF406ZN6xK8AyQmJjJ+/HiKiorcNCuR4cHPzw+LxUJdXZ27pyLicXJycnjjjTdYuXKlu6fSjQJ4ERlxHA4HJ06c0D+CRXpQX19PdXU1xcXFPPzww+zfv59Zs2a5e1oiHsXhcPDHP/6Rq6++moyMDHdPpxvVwIvIiPPGG29QXl7O8uXL3T0VEY/z+9//nnfffRcAk8nET3/6U/7xH//RzbMS8Syvv/46Bw8e5H//93/dPZUeKYAXkRGlqKiIP/zhD0yfPp2rrrrK3dMR8Th33nkn119/PWVlZWzatAmbzUZra2u3UjSR0aq+vp6HHnqIX/7yl0RGRrp7Oj1SCY2IjBiVlZXcfvvthISEsHr1aoxG/RUn8l1paWmcf/75XGIllJIAAAbXSURBVHvttTz33HPk5eV5ZI2viLv8+c9/xmQyceutt7p7Kr3St5uIjAinTp3itttu49SpUzz77LNERES4e0oiHs9kMjFv3jy2bt1Kc3Ozu6cj4nYVFRW88MIL3HDDDZw4cYJjx45x7NgxWlpaaG1t5dixY5w8edLd01QJjYgMfy0tLfzjP/4jhw4dYs2aNSQnJ7t7SiLDRnNzMw6Hg4aGBnx9fd09HRG3qqqqorW1lVWrVrFq1apur8+bN4/bbruN3/72t26Y3bcUwIvIsNbe3s7dd9/N119/zRNPPMGUKVPcPSURj1RdXY3FYukyVl9fz7vvvktMTAxWq9VNMxPxHGPHju1x4+qjjz5KY2Mjv//970lMTBz6iX2HAngP9sQTTwC4ellv2rSJL7/8kuDgYG666SZ3Tk3EYzzwwAN88MEHXHzxxdTW1nY5ZCMgIID58+e7cXYinuPuu+/GbDYzdepUIiIiOH78ONnZ2ZSVlfHwww+7e3oiHiEoKKjH740XXngBLy8vj/lO0UmsHiwtLa3H8TFjxvDBBx8M8WxEPNPSpUvZtWtXj69prYh8a8OGDWzatImDBw9SV1dHUFAQU6ZM4Wc/+xnnnXeeu6cn4tGWLl3qUSexKoAXERERERlG1IVGRERERGQYUQAvIiIiIjKMKIAXERERERlGFMCLiIiIiAwjCuBFRERERIYRBfAiIiIiIsOIAngRERERkWFEAbyIiHi8pUuXMnfuXHdPQ0TEI3i7ewIiIuIeO3fuZNmyZb2+7uXlRX5+/hDOSERE+kIBvIjIKLdw4UIuuOCCbuNGo35IKyLiiRTAi4iMchMmTOCqq65y9zRERKSPlF4REZEzOnbsGGlpaTz++ONs3ryZK664gkmTJnHRRRfx+OOP09bW1u2effv2ceeddzJjxgwmTZrE5ZdfzjPPPEN7e3u3aysrK/nP//xP5s2bR2ZmJrNmzeLWW29l+/bt3a4tLy9nxYoVnHvuuUyePJmf//znlJSUDMrnFhHxVMrAi4iMck1NTVRXV3cb9/HxITAw0PX7Dz74gKNHj3LjjTcSHh7OBx98wP/8z/9QWlrK/fff77pu7969LF26FG9vb9e1H374IatWrWLfvn089NBDrmuPHTvGkiVLqKqq4qqrriIzM5Ompib27NnDjh07OP/8813XNjY2ctNNNzF58mSWL1/OsWPHWLt2LXfccQebN2/Gy8trkP6EREQ8iwJ4EZFR7vHHH+fxxx/vNn7RRRfx1FNPuX6/b98+NmzYwMSJEwG46aab+PWvf012djbXX389U6ZMAeBPf/oTNpuNV155hfT0dNe1d999N5s3b+a6665j1qxZAPzHf/wHFRUVPPvss8yZM6fL8+12e5ff19TU8POf/5zbbrvNNWaxWHjwwQfZsWNHt/tFREYqBfAiIqPc9ddfz4IFC7qNWyyWLr+fPXu2K3gHMBgM/OIXv+D999/nvffeY8qUKVRVVfHVV19xySWXuIL3zmt/9atfsWXLFt577z1mzZpFbW0tn3zyCXPmzOkx+P7uJlqj0dita87MmTMBOHz4sAJ4ERk1FMCLiIxyCQkJzJ49+6zXpaSkdBsbN24cAEePHgWcJTGnj58uOTkZo9HouvbIkSM4HA4mTJjQp3lGRkZiNpu7jIWGhgJQW1vbp/cQERkJtIlVRESGhTPVuDscjiGciYiIeymAFxGRPikqKuo2dvDgQQDi4uIAGDt2bJfx0xUXF2O3213XxsfHYzAYKCgoGKwpi4iMSArgRUSkT3bs2EFeXp7r9w6Hg2effRaA+fPnA2C1Wpk6dSoffvgh+/fv73Lt008/DcAll1wCOMtfLrjgAj7++GN27NjR7XnKqouI9Ew18CIio1x+fj6bNm3q8bXOwBwgPT2dm2++mRtvvJGIiAi2bdvGjh07uOqqq5g6darrunvvvZelS5dy4403csMNNxAREcGHH37Ip59+ysKFC10daAD+9V//lfz8fG677TauvvpqJk6cSEtLC3v27GHMmDH88z//8+B9cBGRYUoBvIjIKLd582Y2b97c42tbt2511Z7PnTuXpKQknnrqKUpKSrBardxxxx3ccccdXe6ZNGkSr7zyCo899hgvv/wyjY2NxMXF8dvf/paf/exnXa6Ni4vjtdde4/9v1w6KGAphAAqmBtCBD0RgAuQgBAtowUfroLc/nUx3FZDbG5K1VpxzYu8dpZSotUbv/ZmBAZJ7ve0oAfji3huttRhjxJzz188B+Htu4AEAIBEBDwAAiQh4AABIxA08AAAk4gceAAASEfAAAJCIgAcAgEQEPAAAJCLgAQAgEQEPAACJfACWceMYXj9DJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats  = stats(training_stats)\n",
    "plot_stats(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Qrc3c9ZK8Iid",
    "outputId": "9d099102-81e4-484f-98a0-0e8f3ddaae5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:04:24</td>\n",
       "      <td>0:00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0:04:23</td>\n",
       "      <td>0:00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0:04:23</td>\n",
       "      <td>0:00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0:04:23</td>\n",
       "      <td>0:00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.20         0.14           0.94       0:04:24         0:00:14\n",
       "2               0.10         0.11           0.97       0:04:23         0:00:14\n",
       "3               0.07         0.09           0.97       0:04:23         0:00:14\n",
       "4               0.04         0.12           0.97       0:04:23         0:00:14"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZlAf38u8J2h",
    "outputId": "ddcc155c-f3e9-4a99-92be-5581b225a024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Grained Accuracy = 0.969173859432799\n",
      "\n",
      "\n",
      "Fine Grained Metrics\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       376\n",
      "           1       0.97      0.97      0.97       435\n",
      "\n",
      "    accuracy                           0.97       811\n",
      "   macro avg       0.97      0.97      0.97       811\n",
      "weighted avg       0.97      0.97      0.97       811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_val_non_hostile, y_pred_val_non_hostile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rl1HHAKb8NxS"
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(y_pred_val_non_hostile, index = val_data.index, columns=['non-hostile'])\n",
    "result_df.index.name = 'Unique ID'\n",
    "result_df.to_csv('y_pred_val_non_hostile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsO3V06CJgI6"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()}, 'non_hostile_val.tar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8pWsVLw9ymN"
   },
   "source": [
    "**Training for Non Hostile Class (Using Train +Val Data and Test Data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQkmggpPPVDZ"
   },
   "outputs": [],
   "source": [
    "train_val_labels_non_hostile = y_train_val_non_hostile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrOZjkhYBJUj",
    "outputId": "588897a9-6050-4315-e84f-379129ea68ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = X_process(train_val_sentences)\n",
    "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_non_hostile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2SLITzKBB0A"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_val_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l975nE0w-lq0",
    "outputId": "b07412b0-6e72-4d76-f6b5-3cdbfdfa760f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    205.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    205.    Elapsed: 0:01:57.\n",
      "  Batch   120  of    205.    Elapsed: 0:02:56.\n",
      "  Batch   160  of    205.    Elapsed: 0:03:55.\n",
      "  Batch   200  of    205.    Elapsed: 0:04:54.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:05:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:28\n",
      "[{'epoch': 1, 'Training Loss': 0.006218319331443437, 'Training Time': '0:05:00', 'Validation Time': '0:00:28'}]\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    205.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    205.    Elapsed: 0:01:58.\n",
      "  Batch   120  of    205.    Elapsed: 0:02:57.\n",
      "  Batch   160  of    205.    Elapsed: 0:03:56.\n",
      "  Batch   200  of    205.    Elapsed: 0:04:55.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:05:01\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:28\n",
      "[{'epoch': 1, 'Training Loss': 0.006218319331443437, 'Training Time': '0:05:00', 'Validation Time': '0:00:28'}, {'epoch': 2, 'Training Loss': 0.014178090554338357, 'Training Time': '0:05:01', 'Validation Time': '0:00:28'}]\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    205.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    205.    Elapsed: 0:01:58.\n",
      "  Batch   120  of    205.    Elapsed: 0:02:56.\n",
      "  Batch   160  of    205.    Elapsed: 0:03:55.\n",
      "  Batch   200  of    205.    Elapsed: 0:04:54.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:05:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:28\n",
      "[{'epoch': 1, 'Training Loss': 0.006218319331443437, 'Training Time': '0:05:00', 'Validation Time': '0:00:28'}, {'epoch': 2, 'Training Loss': 0.014178090554338357, 'Training Time': '0:05:01', 'Validation Time': '0:00:28'}, {'epoch': 3, 'Training Loss': 0.014036525302515479, 'Training Time': '0:05:00', 'Validation Time': '0:00:28'}]\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    205.    Elapsed: 0:00:59.\n",
      "  Batch    80  of    205.    Elapsed: 0:01:58.\n",
      "  Batch   120  of    205.    Elapsed: 0:02:57.\n",
      "  Batch   160  of    205.    Elapsed: 0:03:55.\n",
      "  Batch   200  of    205.    Elapsed: 0:04:54.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:05:01\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:28\n",
      "[{'epoch': 1, 'Training Loss': 0.006218319331443437, 'Training Time': '0:05:00', 'Validation Time': '0:00:28'}, {'epoch': 2, 'Training Loss': 0.014178090554338357, 'Training Time': '0:05:01', 'Validation Time': '0:00:28'}, {'epoch': 3, 'Training Loss': 0.014036525302515479, 'Training Time': '0:05:00', 'Validation Time': '0:00:28'}, {'epoch': 4, 'Training Loss': 0.014854550303780564, 'Training Time': '0:05:01', 'Validation Time': '0:00:28'}]\n"
     ]
    }
   ],
   "source": [
    "training_stats, y_pred_test_non_hostile = train_fn_test(train_val_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqVGibIcQxI2"
   },
   "source": [
    "**Evaluation on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "id": "J3XfmpU6A8TP",
    "outputId": "4a6cd709-8929-4b78-c0ad-2308faf0e8ac"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-91155c2a8903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_stats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-6f844b95e724>\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(df_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Plot the learning curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valid. Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Label the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats  = stats(training_stats)\n",
    "plot_stats(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHuEtaXQBumV"
   },
   "outputs": [],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Edzrl2k7Pf2m"
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(y_pred_test_non_hostile, index = test_data.index, columns=['non-hostile'])\n",
    "result_df.index.name = 'Unique ID'\n",
    "result_df.to_csv('y_pred_test_non_hostile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlOMpeiyP0e5"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()}, 'non_hostile_test.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJj5LP_OCFQl"
   },
   "source": [
    "TODO: 2 level model ( NH followed by others), 3 level model ( NH followed by fake followed by others)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Model_1a.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
