{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxyjuPoOPjJq"
   },
   "source": [
    "**Model Specifications**\n",
    "Detect Hate Using HinglishBert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCWMvHep3B7C"
   },
   "source": [
    "**Installing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlOS1Mp42yMw",
    "outputId": "33d0f706-d3a8-44c9-bcba-c4389743b194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMBBc1EW3F4v"
   },
   "source": [
    "**Required Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aPNhzGe3A_-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import ast\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ958U2_3YnT"
   },
   "source": [
    "**Reading Data and Rearranging into DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWJalNxA3Xqj"
   },
   "outputs": [],
   "source": [
    "train_file = 'train.csv'\n",
    "val_file = 'val.csv'\n",
    "test_file = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woDH9cHl3fjU"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
    "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
    "non_hostile_val_data = pd.read_csv('y_pred_val_non_hostile.csv', header=0, index_col=0)\n",
    "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
    "train_val_data = train_data.append(val_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6tPwxYgijPd"
   },
   "outputs": [],
   "source": [
    "non_hostile_test_data = pd.read_csv('y_pred_test_non_hostile.csv', header=0, index_col=0)\n",
    "val_data_orig = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4Y-IcvgC1DK"
   },
   "outputs": [],
   "source": [
    "train_data.drop(train_data[train_data['Labels Set']=='non-hostile'].index, inplace = True)\n",
    "val_data.drop(non_hostile_val_data[non_hostile_val_data['non-hostile']==1].index, inplace=True)\n",
    "train_val_data.drop(train_val_data[train_val_data['Labels Set']=='non-hostile'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mtwrtNEig5N"
   },
   "outputs": [],
   "source": [
    "test_data.drop(non_hostile_test_data[non_hostile_test_data['non-hostile']==1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "mL-Yczph4Chg",
    "outputId": "7f16bb17-8b58-4a21-db07-3756ad92925e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2678, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>hate,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üôè', 'üôè']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
       "      <td>defamation,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@prabhav218']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
       "      <td>fake</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
       "      <td>‡§ö‡•Ä‡§® UN ‡§§‡§∞‡•ç‡§ï ‡§≠‡§æ‡§∞‡§§ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§Ö‡§ú‡§∞‚Äå ‡§Æ‡§∏‡•Å‡§¶ ‡§Ü‡§§‡§Ç‡§ï‡•Ä ‡§Æ‡§æ‡§®‡§§‡§æ ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@_Pb_swain_:']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ü§î']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['RT']</td>\n",
       "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ñ‡§°‡•Ä ‡§π‡•à,\\n\\...</td>\n",
       "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ñ‡§°‡•Ä ‡§π‡•à, ‡§∏‡§Ø‡§æ‡§®‡•á ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§™‡§°‡•á ‡§π‡•à? ‡§¨‡•ã...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@ShilpiSinghINC:']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['RT']</td>\n",
       "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•ã...</td>\n",
       "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§´‡§∞‡•ç‡§ï‡§º ‡§™‡§°‡§º‡§§‡§æ! ‡§Ö‡§Æ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Post  ... Unnamed: 13\n",
       "Unique ID                                                     ...            \n",
       "1          ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
       "4          @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
       "6          ‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...  ...         NaN\n",
       "11         RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...  ...         NaN\n",
       "12         RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...  ...         NaN\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "nSxggvRQ4EGE",
    "outputId": "adb1f70b-8c8b-47ec-9a76-b5ff97de7e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
       "      <td>defamation</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
       "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§ú‡•ã ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à ‡§ï‡§ø ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§Ø‡•Å‡§¶‡•ç...</td>\n",
       "      <td>fake</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§ú‡•ã ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à ‡§ï‡§ø ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§Ø‡•Å‡§¶‡•ç...</td>\n",
       "      <td>‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§π‡•à, ‡§∏‡§®...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö...</td>\n",
       "      <td>‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§Æ‡§¶‡§¶ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö‡§≤‡•Ä ‡§Ü‡§§‡•ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>‡§Ø‡§π ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§Æ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ø‡§π ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§Æ...</td>\n",
       "      <td>‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§π‡•Å‡§à,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>‡§∏‡§§‡•ç‡§Ø ‡§ï‡§≠‡•Ä ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§π‡•ã‡§®‡•á ‡§¶‡•á‡§§‡§æ‡•§ ‡§î‡§∞ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§ï‡§≠‡•Ä ‡§¶...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡§§‡•ç‡§Ø ‡§ï‡§≠‡•Ä ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§π‡•ã‡§®‡•á ‡§¶‡•á‡§§‡§æ‡•§ ‡§î‡§∞ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§ï‡§≠‡•Ä ‡§¶...</td>\n",
       "      <td>‡§∏‡§§‡•ç‡§Ø ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§¶‡•á‡§§‡§æ‡•§ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§¶‡•Å‡§É‡§ñ‡•Ä ‡§≠‡§Ø‡§≠‡•Ä‡§§ ‡§®‡§π‡•Ä ‡§¶...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
       "Unique ID                                                     ...                                                   \n",
       "2          ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...  ...  ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...\n",
       "8          ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§ú‡•ã ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à ‡§ï‡§ø ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§Ø‡•Å‡§¶‡•ç...  ...  ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ - ‡§µ‡§æ‡§Æ‡§™‡§Ç‡§•‡•Ä ‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§ ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§π‡•à, ‡§∏‡§®...\n",
       "13         ‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö...  ...  ‡§≠‡§æ‡§à ‡§ú‡§æ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§Æ‡§¶‡§¶ ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§®‡•å‡§ï‡§∞‡•Ä ‡§ö‡§≤‡•Ä ‡§Ü‡§§‡•ç...\n",
       "14         ‡§Ø‡§π ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§Æ...  ...  ‡§¶‡•Å‡§∞‡•ç‡§ò‡§ü‡§®‡§æ ‡§ï‡§®‡•ç‡§®‡•Ç‡§∞ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§π‡§µ‡§æ‡§à ‡§Ö‡§°‡•ç‡§°‡•á ‡§π‡•Å‡§à,...\n",
       "15         ‡§∏‡§§‡•ç‡§Ø ‡§ï‡§≠‡•Ä ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§π‡•ã‡§®‡•á ‡§¶‡•á‡§§‡§æ‡•§ ‡§î‡§∞ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§ï‡§≠‡•Ä ‡§¶...  ...  ‡§∏‡§§‡•ç‡§Ø ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§®‡§π‡•Ä ‡§¶‡•á‡§§‡§æ‡•§ ‚Äú‡§ú‡•ç‡§û‡§æ‡§®‚Äù ‡§¶‡•Å‡§É‡§ñ‡•Ä ‡§≠‡§Ø‡§≠‡•Ä‡§§ ‡§®‡§π‡•Ä ‡§¶...\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_data.shape)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "JHNlD7M44Esg",
    "outputId": "2ee86ff0-aa4e-46d7-d431-4859f95d81f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(783, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
       "      <td>‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üôè', 'üòÇ', 'üëç']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
       "      <td>‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
       "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@_Pb_swain_:']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üëá', 'üòÇ', 'üòÇ', 'üòÇ', 'üòÇ']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['RT']</td>\n",
       "      <td>‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡•á...</td>\n",
       "      <td>‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@BasudebaTripat4: @Rajanspsingh1 ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§∏‡§æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@BasudebaTripat4:', '@Rajanspsingh1']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§∏‡§æ‡§≤‡•á ‡§ï‡§æ ‡§∏‡§∞ ‡§´‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ,, ‡§ó‡§∞‡•ç‡§¶‡§® ‡§§‡•ã‡§°‡§º...</td>\n",
       "      <td>‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§æ‡§≤‡•á ‡§∏‡§∞ ‡§´‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ,, ‡§ó‡§∞‡•ç‡§¶‡§® ‡§§‡•ã‡§°‡§º ‡§¶‡•á‡§§‡•á ‡§Ö‡§ö‡•ç‡§õ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
       "Unique ID                                                     ...                                                   \n",
       "1          ‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...  ...  ‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...\n",
       "3          ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...  ...  ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...\n",
       "4          ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...  ...  ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§\n",
       "5          RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...  ...  ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...\n",
       "8          @BasudebaTripat4: @Rajanspsingh1 ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§ø‡§Ø‡§æ ‡§∏‡§æ...  ...  ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§æ‡§≤‡•á ‡§∏‡§∞ ‡§´‡•ã‡§°‡§º ‡§¶‡§ø‡§Ø‡§æ,, ‡§ó‡§∞‡•ç‡§¶‡§® ‡§§‡•ã‡§°‡§º ‡§¶‡•á‡§§‡•á ‡§Ö‡§ö‡•ç‡§õ...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "hMC_GwsU8-Sm",
    "outputId": "b5c2f1fa-365c-4bf4-fc2b-97e1d7557765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3054, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "      <th>emails</th>\n",
       "      <th>urls</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>reserved_words</th>\n",
       "      <th>Filtered_Post</th>\n",
       "      <th>Filtered_Post_Stopword_Removed</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>hate,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['üôè', 'üôè']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
       "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
       "      <td>defamation,offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@prabhav218']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
       "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
       "      <td>fake</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...</td>\n",
       "      <td>‡§ö‡•Ä‡§® UN ‡§§‡§∞‡•ç‡§ï ‡§≠‡§æ‡§∞‡§§ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§Ö‡§ú‡§∞‚Äå ‡§Æ‡§∏‡•Å‡§¶ ‡§Ü‡§§‡§Ç‡§ï‡•Ä ‡§Æ‡§æ‡§®‡§§‡§æ ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@_Pb_swain_:']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ü§î']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['RT']</td>\n",
       "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ñ‡§°‡•Ä ‡§π‡•à,\\n\\...</td>\n",
       "      <td>‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ñ‡§°‡•Ä ‡§π‡•à, ‡§∏‡§Ø‡§æ‡§®‡•á ‡§µ‡§ø‡§¶‡•á‡§∂ ‡§™‡§°‡•á ‡§π‡•à? ‡§¨‡•ã...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@ShilpiSinghINC:']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['RT']</td>\n",
       "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•ã...</td>\n",
       "      <td>48000 ‡§ò‡§∞‡•ã‡§Ç ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§Ü‡§¶‡•á‡§∂ ‡§Ü‡§Ø‡§æ ‡§π‡•à, ‡§´‡§∞‡•ç‡§ï‡§º ‡§™‡§°‡§º‡§§‡§æ! ‡§Ö‡§Æ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Post  ... Unnamed: 13\n",
       "0   ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
       "3   @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
       "5   ‡§ö‡•Ä‡§® ‡§®‡•á UN ‡§Æ‡•á‡§Ç ‡§§‡§∞‡•ç‡§ï ‡§¶‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡§æ ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§π‡•Ä ‡§Ö...  ...         NaN\n",
       "10  RT @_Pb_swain_: ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§î‡§∞ ‡§ú‡§¨ ‡§∏‡§æ‡§∞‡§æ ‡§¶‡•á‡§∂ ‡§∏‡•á‡§®‡§æ ‡§ï‡•á ...  ...         NaN\n",
       "11  RT @ShilpiSinghINC: 48000 ‡§ò‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§§‡•ã‡§°‡§º‡§®‡•á ‡§ï‡§æ ‡§Ü‡§¶...  ...         NaN\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_val_data.shape)\n",
    "train_val_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTg69u-b4wDw"
   },
   "source": [
    "**Transforming the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPoz0-5P4IsD"
   },
   "outputs": [],
   "source": [
    "labels_set = {'defamation',\n",
    " 'fake',\n",
    " 'hate',\n",
    " 'non-hostile',\n",
    " 'offensive'}\n",
    "\n",
    "labels_mapping = {'defamation':0,\n",
    " 'fake':1,\n",
    " 'hate':2,\n",
    " 'non-hostile':3,\n",
    " 'offensive':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1e1OzBY4MKF"
   },
   "outputs": [],
   "source": [
    "train_y = np.empty((0, 5))\n",
    "for index, row in train_data.iterrows():\n",
    "  y = np.zeros((1, 5))\n",
    "  for label in row['Labels Set'].split(','):\n",
    "    y[0, labels_mapping[label]] = 1\n",
    "\n",
    "  train_y = np.vstack((train_y, y))\n",
    "\n",
    "\n",
    "val_y = np.empty((0, 5))\n",
    "for index, row in val_data.iterrows():\n",
    "  y = np.zeros((1, 5))\n",
    "  for label in row['Labels Set'].split(','):\n",
    "    y[0, labels_mapping[label]] = 1\n",
    "\n",
    "  val_y = np.vstack((val_y, y))\n",
    "\n",
    "train_val_y = np.empty((0, 5))\n",
    "for index, row in train_val_data.iterrows():\n",
    "  y = np.zeros((1, 5))\n",
    "  for label in row['Labels Set'].split(','):\n",
    "    y[0, labels_mapping[label]] = 1\n",
    "\n",
    "  train_val_y = np.vstack((train_val_y, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBa01jcE4NWo",
    "outputId": "6d1ac50c-7962-42fc-dc7c-dac22bb53824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2678, 5)\n",
      "(379, 5)\n",
      "(3054, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(val_y.shape)\n",
    "print(train_val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvCtXMKS64VT"
   },
   "source": [
    "**Modelling Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34AzCgmM40un"
   },
   "outputs": [],
   "source": [
    "def X_process(sentences):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_length,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    return input_ids, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4FZSOIJ5Ua2"
   },
   "outputs": [],
   "source": [
    "def train_load(input_ids, attention_masks, labels):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,  # The training samples.\n",
    "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
    "                batch_size = batch_size # Trains with this batch size.\n",
    "            )\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1AFD9Fs5aOw"
   },
   "outputs": [],
   "source": [
    "def val_load(input_ids, attention_masks, labels):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_dataset, # The validation samples.\n",
    "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    \n",
    "    return validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_fjVV8d5a5f"
   },
   "outputs": [],
   "source": [
    "def test_load(input_ids, attention_masks):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
    "    test_dataloader = DataLoader(\n",
    "                test_dataset, # The validation samples.\n",
    "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    \n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvMF_Pg-9XYn"
   },
   "outputs": [],
   "source": [
    "def train_val_load(input_ids, attention_masks, labels):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_validation_dataloader = DataLoader(\n",
    "                train_val_dataset, # The validation samples.\n",
    "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    \n",
    "    return train_validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRBErql77BAv"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_dataloader, validation_dataloader):\n",
    "    \n",
    "    seed_val = 42\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every 40 batches.\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "            # `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Always clear any previously calculated gradients before performing a\n",
    "            # backward pass. PyTorch doesn't do this automatically because \n",
    "            # accumulating the gradients is \"convenient while training RNNs\". \n",
    "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "            model.zero_grad()        \n",
    "\n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            state = model(b_input_ids, \n",
    "                                 token_type_ids=None, \n",
    "                                 attention_mask=b_input_mask, \n",
    "                                 labels=b_labels)\n",
    "            loss = state.loss\n",
    "            logits = state.logits\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can\n",
    "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "            # single value; the `.item()` function just returns the Python value \n",
    "            # from the tensor.\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "            # modified based on their gradients, the learning rate, etc.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        y_pred_val = []\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                state = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       attention_mask=b_input_mask,\n",
    "                                       labels=b_labels)\n",
    "                loss = state.loss\n",
    "                logits = state.logits\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            \n",
    "#             labels = label_ids\n",
    "            preds = logits\n",
    "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#             labels_flat = labels.flatten()\n",
    "#             y_true.extend(labels_flat)\n",
    "            y_pred_val.extend(pred_flat)\n",
    "\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        print(training_stats)\n",
    "        \n",
    "    return training_stats, y_pred_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17SD78fGdXtx"
   },
   "outputs": [],
   "source": [
    "def train_fn_test(train_dataloader, validation_dataloader):\n",
    "    \n",
    "    seed_val = 42\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every 40 batches.\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "            # `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Always clear any previously calculated gradients before performing a\n",
    "            # backward pass. PyTorch doesn't do this automatically because \n",
    "            # accumulating the gradients is \"convenient while training RNNs\". \n",
    "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "            model.zero_grad()        \n",
    "\n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            state = model(b_input_ids, \n",
    "                                 token_type_ids=None, \n",
    "                                 attention_mask=b_input_mask, \n",
    "                                 labels=b_labels)\n",
    "            loss = state.loss\n",
    "            logits = state.logits\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can\n",
    "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "            # single value; the `.item()` function just returns the Python value \n",
    "            # from the tensor.\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "            # modified based on their gradients, the learning rate, etc.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        \n",
    "        y_pred_val = []\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                state = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       attention_mask=b_input_mask)\n",
    "                logits = state.logits\n",
    "\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            \n",
    "#             labels = label_ids\n",
    "            preds = logits\n",
    "            \n",
    "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#             labels_flat = labels.flatten()\n",
    "#             y_true.extend(labels_flat)\n",
    "            y_pred_val.extend(pred_flat)\n",
    "\n",
    "\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "        print(training_stats)\n",
    "        \n",
    "    return training_stats, y_pred_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBONPGg77Clo"
   },
   "outputs": [],
   "source": [
    "def stats(training_stats):\n",
    "    pd.set_option('precision', 2)\n",
    "\n",
    "    # Create a DataFrame from our training statistics.\n",
    "    df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "    # Use the 'epoch' as the row index.\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "    # A hack to force the column headers to wrap.\n",
    "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "    # Display the table.\n",
    "    return df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwhcuXIG7Dpk"
   },
   "outputs": [],
   "source": [
    "def plot_stats(df_stats):\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "    # Plot the learning curve.\n",
    "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "    # Label the plot.\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evcCcgjA7FTu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57MSQH9l7GSm"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaHqtP0nElkb"
   },
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred):\n",
    "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
    "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
    "  print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrEu7-vTNxst"
   },
   "source": [
    "\n",
    "**Training for Hate Class (Using Train Data and Val Data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxBtbX61Nxsu",
    "outputId": "8f9e37c5-5643-42ce-f72c-165095e1fec4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
    "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.to(device) # Send the model to the GPU if we have one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UumXdB9Nxsx"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7Nr_05qNxsy"
   },
   "source": [
    "**TODO: Tryout different batchsize and length (80, 100)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a2RNGhpNxsy"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPL2bLLvOWzr"
   },
   "outputs": [],
   "source": [
    "# train_sentences = train_data['Filtered_Post'].values\n",
    "# val_sentences = val_data['Filtered_Post'].values\n",
    "# test_sentences = test_data['Filtered_Post'].values\n",
    "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
    "\n",
    "train_sentences = train_data['Post'].values\n",
    "val_sentences = val_data['Post'].values\n",
    "test_sentences = test_data['Post'].values\n",
    "train_val_sentences = train_val_data['Post'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQbgOIjuQffx"
   },
   "outputs": [],
   "source": [
    "y_train_hate = train_y[:,2].astype(int)\n",
    "y_val_hate = val_y[:,2].astype(int)\n",
    "y_train_val_hate = train_val_y[:,2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzuEr8LedH7Y"
   },
   "outputs": [],
   "source": [
    "train_labels_hate = y_train_hate\n",
    "val_labels_hate = y_val_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zN8t3Bc3Nxsy",
    "outputId": "561f03b2-8576-40e0-83a4-2fc687154574"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = X_process(train_sentences)\n",
    "train_dataloader = train_load(input_ids, attention_masks, train_labels_hate)\n",
    "\n",
    "input_ids, attention_masks = X_process(val_sentences)\n",
    "validation_dataloader = val_load(input_ids, attention_masks, val_labels_hate)\n",
    "\n",
    "input_ids, attention_masks = X_process(test_sentences)\n",
    "test_dataloader = test_load(input_ids, attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jW2p6AI3Nxsy"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1JzyqSFNxsy",
    "outputId": "d6fe9792-8f60-4832-9921-c77b2e36bcfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    670.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    670.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    670.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    670.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    670.    Elapsed: 0:00:49.\n",
      "  Batch   240  of    670.    Elapsed: 0:00:59.\n",
      "  Batch   280  of    670.    Elapsed: 0:01:09.\n",
      "  Batch   320  of    670.    Elapsed: 0:01:20.\n",
      "  Batch   360  of    670.    Elapsed: 0:01:31.\n",
      "  Batch   400  of    670.    Elapsed: 0:01:41.\n",
      "  Batch   440  of    670.    Elapsed: 0:01:51.\n",
      "  Batch   480  of    670.    Elapsed: 0:02:02.\n",
      "  Batch   520  of    670.    Elapsed: 0:02:12.\n",
      "  Batch   560  of    670.    Elapsed: 0:02:22.\n",
      "  Batch   600  of    670.    Elapsed: 0:02:33.\n",
      "  Batch   640  of    670.    Elapsed: 0:02:43.\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epcoh took: 0:02:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.71\n",
      "  Validation Loss: 0.59\n",
      "  Validation took: 0:00:07\n",
      "[{'epoch': 1, 'Training Loss': 0.6181535743955356, 'Valid. Loss': 0.5937711160433919, 'Valid. Accur.': 0.7122807017543861, 'Training Time': '0:02:51', 'Validation Time': '0:00:07'}]\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    670.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    670.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    670.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    670.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    670.    Elapsed: 0:00:52.\n",
      "  Batch   240  of    670.    Elapsed: 0:01:02.\n",
      "  Batch   280  of    670.    Elapsed: 0:01:13.\n",
      "  Batch   320  of    670.    Elapsed: 0:01:23.\n",
      "  Batch   360  of    670.    Elapsed: 0:01:33.\n",
      "  Batch   400  of    670.    Elapsed: 0:01:44.\n",
      "  Batch   440  of    670.    Elapsed: 0:01:54.\n",
      "  Batch   480  of    670.    Elapsed: 0:02:05.\n",
      "  Batch   520  of    670.    Elapsed: 0:02:15.\n",
      "  Batch   560  of    670.    Elapsed: 0:02:25.\n",
      "  Batch   600  of    670.    Elapsed: 0:02:36.\n",
      "  Batch   640  of    670.    Elapsed: 0:02:46.\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:02:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation Loss: 0.67\n",
      "  Validation took: 0:00:07\n",
      "[{'epoch': 1, 'Training Loss': 0.6181535743955356, 'Valid. Loss': 0.5937711160433919, 'Valid. Accur.': 0.7122807017543861, 'Training Time': '0:02:51', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.5700650526683277, 'Valid. Loss': 0.6686303657136465, 'Valid. Accur.': 0.7175438596491228, 'Training Time': '0:02:54', 'Validation Time': '0:00:07'}]\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    670.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    670.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    670.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    670.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    670.    Elapsed: 0:00:52.\n",
      "  Batch   240  of    670.    Elapsed: 0:01:02.\n",
      "  Batch   280  of    670.    Elapsed: 0:01:12.\n",
      "  Batch   320  of    670.    Elapsed: 0:01:23.\n",
      "  Batch   360  of    670.    Elapsed: 0:01:33.\n",
      "  Batch   400  of    670.    Elapsed: 0:01:43.\n",
      "  Batch   440  of    670.    Elapsed: 0:01:54.\n",
      "  Batch   480  of    670.    Elapsed: 0:02:04.\n",
      "  Batch   520  of    670.    Elapsed: 0:02:14.\n",
      "  Batch   560  of    670.    Elapsed: 0:02:25.\n",
      "  Batch   600  of    670.    Elapsed: 0:02:35.\n",
      "  Batch   640  of    670.    Elapsed: 0:02:45.\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:02:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.69\n",
      "  Validation Loss: 1.01\n",
      "  Validation took: 0:00:07\n",
      "[{'epoch': 1, 'Training Loss': 0.6181535743955356, 'Valid. Loss': 0.5937711160433919, 'Valid. Accur.': 0.7122807017543861, 'Training Time': '0:02:51', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.5700650526683277, 'Valid. Loss': 0.6686303657136465, 'Valid. Accur.': 0.7175438596491228, 'Training Time': '0:02:54', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.5490411883734388, 'Valid. Loss': 1.0107880750769063, 'Valid. Accur.': 0.6938596491228071, 'Training Time': '0:02:53', 'Validation Time': '0:00:07'}]\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    670.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    670.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    670.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    670.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    670.    Elapsed: 0:00:51.\n",
      "  Batch   240  of    670.    Elapsed: 0:01:02.\n",
      "  Batch   280  of    670.    Elapsed: 0:01:12.\n",
      "  Batch   320  of    670.    Elapsed: 0:01:22.\n",
      "  Batch   360  of    670.    Elapsed: 0:01:32.\n",
      "  Batch   400  of    670.    Elapsed: 0:01:42.\n",
      "  Batch   440  of    670.    Elapsed: 0:01:53.\n",
      "  Batch   480  of    670.    Elapsed: 0:02:03.\n",
      "  Batch   520  of    670.    Elapsed: 0:02:13.\n",
      "  Batch   560  of    670.    Elapsed: 0:02:23.\n",
      "  Batch   600  of    670.    Elapsed: 0:02:34.\n",
      "  Batch   640  of    670.    Elapsed: 0:02:44.\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:02:52\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation Loss: 1.12\n",
      "  Validation took: 0:00:07\n",
      "[{'epoch': 1, 'Training Loss': 0.6181535743955356, 'Valid. Loss': 0.5937711160433919, 'Valid. Accur.': 0.7122807017543861, 'Training Time': '0:02:51', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.5700650526683277, 'Valid. Loss': 0.6686303657136465, 'Valid. Accur.': 0.7175438596491228, 'Training Time': '0:02:54', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.5490411883734388, 'Valid. Loss': 1.0107880750769063, 'Valid. Accur.': 0.6938596491228071, 'Training Time': '0:02:53', 'Validation Time': '0:00:07'}, {'epoch': 4, 'Training Loss': 0.47257057432947097, 'Valid. Loss': 1.124653418891524, 'Valid. Accur.': 0.7043859649122808, 'Training Time': '0:02:52', 'Validation Time': '0:00:07'}]\n"
     ]
    }
   ],
   "source": [
    "training_stats, y_pred_val_hate = train_fn(train_dataloader, validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyoV30azNxsz"
   },
   "source": [
    "**Evaluation on Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "tvWJNE7YNxsz",
    "outputId": "6db3d9ec-ed82-4239-d7d2-7adb6ff6a87a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats  = stats(training_stats)\n",
    "plot_stats(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oxZ4Tx8PNxsz",
    "outputId": "498870aa-5b87-4f8e-8bc9-ff0bcddacc66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0:02:51</td>\n",
       "      <td>0:00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0:02:54</td>\n",
       "      <td>0:00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.55</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0:02:53</td>\n",
       "      <td>0:00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0:02:52</td>\n",
       "      <td>0:00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.62         0.59           0.71       0:02:51         0:00:07\n",
       "2               0.57         0.67           0.72       0:02:54         0:00:07\n",
       "3               0.55         1.01           0.69       0:02:53         0:00:07\n",
       "4               0.47         1.12           0.70       0:02:52         0:00:07"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrRQFllONxsz",
    "outputId": "adc99f7c-3bcd-48f2-c2c2-ad305be7bf43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Grained Accuracy = 0.7044854881266491\n",
      "\n",
      "\n",
      "Fine Grained Metrics\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       270\n",
      "           1       0.48      0.43      0.46       109\n",
      "\n",
      "    accuracy                           0.70       379\n",
      "   macro avg       0.63      0.62      0.63       379\n",
      "weighted avg       0.70      0.70      0.70       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_val_hate, y_pred_val_hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FHgr-fodo8e"
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(y_pred_val_hate, index = val_data.index, columns=['hate'])\n",
    "result_df.index.name = 'Unique ID'\n",
    "result_df.to_csv('y_pred_val_hate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67HWdCRDNxs0"
   },
   "source": [
    "**Training for Hate Class (Using Train +Val Data and Test Data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwvcdNspi294"
   },
   "outputs": [],
   "source": [
    "train_val_labels_hate = y_train_val_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iU-RaRs7Nxs0",
    "outputId": "f8d8c98d-625e-47c8-c859-d630fd576645"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = X_process(train_val_sentences)\n",
    "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1wfwVeBNxs0"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_val_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndmjATAqNxs0",
    "outputId": "3be148b2-c913-4d6c-ae1b-ab3ccc381eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    764.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    764.    Elapsed: 0:00:51.\n",
      "  Batch   240  of    764.    Elapsed: 0:01:01.\n",
      "  Batch   280  of    764.    Elapsed: 0:01:12.\n",
      "  Batch   320  of    764.    Elapsed: 0:01:22.\n",
      "  Batch   360  of    764.    Elapsed: 0:01:32.\n",
      "  Batch   400  of    764.    Elapsed: 0:01:42.\n",
      "  Batch   440  of    764.    Elapsed: 0:01:52.\n",
      "  Batch   480  of    764.    Elapsed: 0:02:03.\n",
      "  Batch   520  of    764.    Elapsed: 0:02:13.\n",
      "  Batch   560  of    764.    Elapsed: 0:02:23.\n",
      "  Batch   600  of    764.    Elapsed: 0:02:34.\n",
      "  Batch   640  of    764.    Elapsed: 0:02:44.\n",
      "  Batch   680  of    764.    Elapsed: 0:02:54.\n",
      "  Batch   720  of    764.    Elapsed: 0:03:05.\n",
      "  Batch   760  of    764.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:03:16\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:15\n",
      "[{'epoch': 1, 'Training Loss': 0.5171852915456971, 'Training Time': '0:03:16', 'Validation Time': '0:00:15'}]\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    764.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    764.    Elapsed: 0:00:51.\n",
      "  Batch   240  of    764.    Elapsed: 0:01:01.\n",
      "  Batch   280  of    764.    Elapsed: 0:01:12.\n",
      "  Batch   320  of    764.    Elapsed: 0:01:22.\n",
      "  Batch   360  of    764.    Elapsed: 0:01:32.\n",
      "  Batch   400  of    764.    Elapsed: 0:01:42.\n",
      "  Batch   440  of    764.    Elapsed: 0:01:52.\n",
      "  Batch   480  of    764.    Elapsed: 0:02:03.\n",
      "  Batch   520  of    764.    Elapsed: 0:02:13.\n",
      "  Batch   560  of    764.    Elapsed: 0:02:23.\n",
      "  Batch   600  of    764.    Elapsed: 0:02:33.\n",
      "  Batch   640  of    764.    Elapsed: 0:02:44.\n",
      "  Batch   680  of    764.    Elapsed: 0:02:54.\n",
      "  Batch   720  of    764.    Elapsed: 0:03:04.\n",
      "  Batch   760  of    764.    Elapsed: 0:03:15.\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:03:15\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:15\n",
      "[{'epoch': 1, 'Training Loss': 0.5171852915456971, 'Training Time': '0:03:16', 'Validation Time': '0:00:15'}, {'epoch': 2, 'Training Loss': 0.4715675422812066, 'Training Time': '0:03:15', 'Validation Time': '0:00:15'}]\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    764.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    764.    Elapsed: 0:00:51.\n",
      "  Batch   240  of    764.    Elapsed: 0:01:01.\n",
      "  Batch   280  of    764.    Elapsed: 0:01:11.\n",
      "  Batch   320  of    764.    Elapsed: 0:01:22.\n",
      "  Batch   360  of    764.    Elapsed: 0:01:32.\n",
      "  Batch   400  of    764.    Elapsed: 0:01:42.\n",
      "  Batch   440  of    764.    Elapsed: 0:01:52.\n",
      "  Batch   480  of    764.    Elapsed: 0:02:02.\n",
      "  Batch   520  of    764.    Elapsed: 0:02:13.\n",
      "  Batch   560  of    764.    Elapsed: 0:02:23.\n",
      "  Batch   600  of    764.    Elapsed: 0:02:33.\n",
      "  Batch   640  of    764.    Elapsed: 0:02:43.\n",
      "  Batch   680  of    764.    Elapsed: 0:02:53.\n",
      "  Batch   720  of    764.    Elapsed: 0:03:04.\n",
      "  Batch   760  of    764.    Elapsed: 0:03:14.\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:03:15\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:15\n",
      "[{'epoch': 1, 'Training Loss': 0.5171852915456971, 'Training Time': '0:03:16', 'Validation Time': '0:00:15'}, {'epoch': 2, 'Training Loss': 0.4715675422812066, 'Training Time': '0:03:15', 'Validation Time': '0:00:15'}, {'epoch': 3, 'Training Loss': 0.42526198883543365, 'Training Time': '0:03:15', 'Validation Time': '0:00:15'}]\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    764.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    764.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    764.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    764.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    764.    Elapsed: 0:00:51.\n",
      "  Batch   240  of    764.    Elapsed: 0:01:01.\n",
      "  Batch   280  of    764.    Elapsed: 0:01:11.\n",
      "  Batch   320  of    764.    Elapsed: 0:01:21.\n",
      "  Batch   360  of    764.    Elapsed: 0:01:31.\n",
      "  Batch   400  of    764.    Elapsed: 0:01:42.\n",
      "  Batch   440  of    764.    Elapsed: 0:01:52.\n",
      "  Batch   480  of    764.    Elapsed: 0:02:02.\n",
      "  Batch   520  of    764.    Elapsed: 0:02:12.\n",
      "  Batch   560  of    764.    Elapsed: 0:02:22.\n",
      "  Batch   600  of    764.    Elapsed: 0:02:32.\n",
      "  Batch   640  of    764.    Elapsed: 0:02:43.\n",
      "  Batch   680  of    764.    Elapsed: 0:02:53.\n",
      "  Batch   720  of    764.    Elapsed: 0:03:03.\n",
      "  Batch   760  of    764.    Elapsed: 0:03:13.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:03:14\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:15\n",
      "[{'epoch': 1, 'Training Loss': 0.5171852915456971, 'Training Time': '0:03:16', 'Validation Time': '0:00:15'}, {'epoch': 2, 'Training Loss': 0.4715675422812066, 'Training Time': '0:03:15', 'Validation Time': '0:00:15'}, {'epoch': 3, 'Training Loss': 0.42526198883543365, 'Training Time': '0:03:15', 'Validation Time': '0:00:15'}, {'epoch': 4, 'Training Loss': 0.3629476972477735, 'Training Time': '0:03:14', 'Validation Time': '0:00:15'}]\n"
     ]
    }
   ],
   "source": [
    "training_stats, y_pred_hate = train_fn_test(train_val_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPlAyssNRJ2S"
   },
   "source": [
    "**Evaluation on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "id": "LnhWwhMUNxs0",
    "outputId": "14eaea0c-82ac-48e2-9cbe-d36dad198a51"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-91155c2a8903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_stats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-6f844b95e724>\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(df_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Plot the learning curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valid. Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Label the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats  = stats(training_stats)\n",
    "plot_stats(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "54illM8xNxs0",
    "outputId": "9720bc63-71bc-416d-f01b-58ee16f430b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0:03:16</td>\n",
       "      <td>0:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0:03:15</td>\n",
       "      <td>0:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0:03:15</td>\n",
       "      <td>0:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0:03:14</td>\n",
       "      <td>0:00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss Training Time Validation Time\n",
       "epoch                                             \n",
       "1               0.52       0:03:16         0:00:15\n",
       "2               0.47       0:03:15         0:00:15\n",
       "3               0.43       0:03:15         0:00:15\n",
       "4               0.36       0:03:14         0:00:15"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amqNhvhitcLw"
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(y_pred_hate, index = test_data.index, columns=['hate'])\n",
    "result_df.index.name = 'Unique ID'\n",
    "result_df.to_csv('y_pred_test_hate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXWnp_AW_HDo"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()}, 'hate_test.tar')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Model_1c.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
