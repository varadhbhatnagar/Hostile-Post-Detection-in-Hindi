{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model_2b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyjuPoOPjJq"
      },
      "source": [
        "**Model Specifications**\n",
        "Detect Fake Using verloop Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWMvHep3B7C"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOS1Mp42yMw",
        "outputId": "0beadfd2-2b48-49f4-8a9f-df44667741b6"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBBc1EW3F4v"
      },
      "source": [
        "**Required Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPNhzGe3A_-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import ast\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ958U2_3YnT"
      },
      "source": [
        "**Reading Data and Rearranging into DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJalNxA3Xqj"
      },
      "source": [
        "train_file = 'train.csv'\n",
        "val_file = 'val.csv'\n",
        "test_file = 'test.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDH9cHl3fjU"
      },
      "source": [
        "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
        "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
        "non_hostile_val_data = pd.read_csv('y_pred_val_non_hostile.csv', header=0, index_col=0)\n",
        "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
        "train_val_data = train_data.append(val_data, ignore_index=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6tPwxYgijPd"
      },
      "source": [
        "non_hostile_test_data = pd.read_csv('y_pred_test_non_hostile.csv', header=0, index_col=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Y-IcvgC1DK"
      },
      "source": [
        "train_data.drop(train_data[train_data['Labels Set']=='non-hostile'].index, inplace = True)\n",
        "val_data.drop(non_hostile_val_data[non_hostile_val_data['non-hostile']==1].index, inplace=True)\n",
        "train_val_data.drop(train_val_data[train_val_data['Labels Set']=='non-hostile'].index, inplace = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mtwrtNEig5N"
      },
      "source": [
        "test_data.drop(non_hostile_test_data[non_hostile_test_data['non-hostile']==1].index, inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "mL-Yczph4Chg",
        "outputId": "d3340bc1-675e-4aff-ad1b-840ef9e254ca"
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ... Unnamed: 13\n",
              "Unique ID                                                     ...            \n",
              "1          मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "4          @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "6          चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "11         RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "12         RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "nSxggvRQ4EGE",
        "outputId": "df1cef79-d4d0-4283-978f-e9238f4455fc"
      },
      "source": [
        "print(val_data.shape)\n",
        "val_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(379, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>defamation</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "2          भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...  ...  भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...\n",
              "8          अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...  ...  अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...\n",
              "13         भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...  ...  भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...\n",
              "14         यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...  ...  दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...\n",
              "15         सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...  ...  सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JHNlD7M44Esg",
        "outputId": "66ac3545-0148-459d-dbc4-3419119fa822"
      },
      "source": [
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(783, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '😂', '👍']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['👇', '😂', '😂', '😂', '😂']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>इन पंचर छापों को कोन समझाए कि उनके रोजगार मे...</td>\n",
              "      <td>पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@BasudebaTripat4:', '@Rajanspsingh1']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अच्छा किया साले का सर फोड़ दिया,, गर्दन तोड़...</td>\n",
              "      <td>अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...  ...  कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...\n",
              "3          कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...  ...  कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...\n",
              "4          अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...  ...  अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।\n",
              "5          RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...  ...  पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...\n",
              "8          @BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...  ...  अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hMC_GwsU8-Sm",
        "outputId": "e586b495-f4c4-4b80-f93c-f551aeeda8ff"
      },
      "source": [
        "print(train_val_data.shape)\n",
        "train_val_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3054, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Post  ... Unnamed: 13\n",
              "0   मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "3   @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "5   चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "10  RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "11  RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTg69u-b4wDw"
      },
      "source": [
        "**Transforming the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPoz0-5P4IsD"
      },
      "source": [
        "labels_set = {'defamation',\n",
        " 'fake',\n",
        " 'hate',\n",
        " 'non-hostile',\n",
        " 'offensive'}\n",
        "\n",
        "labels_mapping = {'defamation':0,\n",
        " 'fake':1,\n",
        " 'hate':2,\n",
        " 'non-hostile':3,\n",
        " 'offensive':4}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1OzBY4MKF"
      },
      "source": [
        "train_y = np.empty((0, 5))\n",
        "for index, row in train_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_y = np.vstack((train_y, y))\n",
        "\n",
        "\n",
        "val_y = np.empty((0, 5))\n",
        "for index, row in val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  val_y = np.vstack((val_y, y))\n",
        "\n",
        "train_val_y = np.empty((0, 5))\n",
        "for index, row in train_val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_val_y = np.vstack((train_val_y, y))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBa01jcE4NWo",
        "outputId": "a92d5371-f862-49de-8ff7-3e67a7652400"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(train_val_y.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 5)\n",
            "(379, 5)\n",
            "(3054, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCtXMKS64VT"
      },
      "source": [
        "**Modelling Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AzCgmM40un"
      },
      "source": [
        "def X_process(sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FZSOIJ5Ua2"
      },
      "source": [
        "def train_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    return train_dataloader"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AFD9Fs5aOw"
      },
      "source": [
        "def val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return validation_dataloader"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fjVV8d5a5f"
      },
      "source": [
        "def test_load(input_ids, attention_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMF_Pg-9XYn"
      },
      "source": [
        "def train_val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_validation_dataloader = DataLoader(\n",
        "                train_val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return train_validation_dataloader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBErql77BAv"
      },
      "source": [
        "def train_fn(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask,\n",
        "                                       labels=b_labels)\n",
        "                loss = state.loss\n",
        "                logits = state.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17SD78fGdXtx"
      },
      "source": [
        "def train_fn_test(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask)\n",
        "                logits = state.logits\n",
        "\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBONPGg77Clo"
      },
      "source": [
        "def stats(training_stats):\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    return df_stats\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhcuXIG7Dpk"
      },
      "source": [
        "def plot_stats(df_stats):\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evcCcgjA7FTu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MSQH9l7GSm"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHqtP0nElkb"
      },
      "source": [
        "def evaluation(y_true, y_pred):\n",
        "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEu7-vTNxst"
      },
      "source": [
        "**Training for Fake Class (Using Train Data and Val Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxBtbX61Nxsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1f8c42-d7b1-44f7-a03d-aad1c1ddda5b"
      },
      "source": [
        "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
        "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(26)\n",
        "np.random.seed(26)\n",
        "torch.manual_seed(26)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device) # Send the model to the GPU if we have one"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UumXdB9Nxsx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Nr_05qNxsy"
      },
      "source": [
        "**TODO: Tryout different batchsize and length (80, 100)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2RNGhpNxsy"
      },
      "source": [
        "batch_size = 8\n",
        "max_length = 256"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPL2bLLvOWzr"
      },
      "source": [
        "# train_sentences = train_data['Filtered_Post'].values\n",
        "# val_sentences = val_data['Filtered_Post'].values\n",
        "# test_sentences = test_data['Filtered_Post'].values\n",
        "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
        "\n",
        "train_sentences = train_data['Post'].values\n",
        "val_sentences = val_data['Post'].values\n",
        "test_sentences = test_data['Post'].values\n",
        "train_val_sentences = train_val_data['Post'].values"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbgOIjuQffx"
      },
      "source": [
        "y_train_fake = train_y[:,1].astype(int)\n",
        "y_val_fake = val_y[:,1].astype(int)\n",
        "y_train_val_fake = train_val_y[:,1].astype(int)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzuEr8LedH7Y"
      },
      "source": [
        "train_labels_fake = y_train_fake\n",
        "val_labels_fake = y_val_fake"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8t3Bc3Nxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2629fecb-a572-46ec-f51f-6d1e2ba61cd4"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_sentences)\n",
        "train_dataloader = train_load(input_ids, attention_masks, train_labels_fake)\n",
        "\n",
        "input_ids, attention_masks = X_process(val_sentences)\n",
        "validation_dataloader = val_load(input_ids, attention_masks, val_labels_fake)\n",
        "\n",
        "input_ids, attention_masks = X_process(test_sentences)\n",
        "test_dataloader = test_load(input_ids, attention_masks)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2p6AI3Nxsy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JzyqSFNxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6e0595-c0e3-4119-8d97-e670dc99bdbe"
      },
      "source": [
        "training_stats, y_pred_val_fake = train_fn(train_dataloader, validation_dataloader)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    335.    Elapsed: 0:01:02.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:33.\n",
            "  Batch   160  of    335.    Elapsed: 0:02:04.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:35.\n",
            "  Batch   240  of    335.    Elapsed: 0:03:06.\n",
            "  Batch   280  of    335.    Elapsed: 0:03:37.\n",
            "  Batch   320  of    335.    Elapsed: 0:04:08.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:04:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:00:12\n",
            "[{'epoch': 1, 'Training Loss': 0.5154898588781927, 'Valid. Loss': 0.38211005840760964, 'Valid. Accur.': 0.84375, 'Training Time': '0:04:19', 'Validation Time': '0:00:12'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    335.    Elapsed: 0:01:02.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:33.\n",
            "  Batch   160  of    335.    Elapsed: 0:02:04.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:34.\n",
            "  Batch   240  of    335.    Elapsed: 0:03:05.\n",
            "  Batch   280  of    335.    Elapsed: 0:03:36.\n",
            "  Batch   320  of    335.    Elapsed: 0:04:07.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epcoh took: 0:04:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.41\n",
            "  Validation took: 0:00:12\n",
            "[{'epoch': 1, 'Training Loss': 0.5154898588781927, 'Valid. Loss': 0.38211005840760964, 'Valid. Accur.': 0.84375, 'Training Time': '0:04:19', 'Validation Time': '0:00:12'}, {'epoch': 2, 'Training Loss': 0.39688101776444645, 'Valid. Loss': 0.40850112470798194, 'Valid. Accur.': 0.8515625, 'Training Time': '0:04:19', 'Validation Time': '0:00:12'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    335.    Elapsed: 0:01:02.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:32.\n",
            "  Batch   160  of    335.    Elapsed: 0:02:03.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:34.\n",
            "  Batch   240  of    335.    Elapsed: 0:03:05.\n",
            "  Batch   280  of    335.    Elapsed: 0:03:35.\n",
            "  Batch   320  of    335.    Elapsed: 0:04:06.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:04:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:12\n",
            "[{'epoch': 1, 'Training Loss': 0.5154898588781927, 'Valid. Loss': 0.38211005840760964, 'Valid. Accur.': 0.84375, 'Training Time': '0:04:19', 'Validation Time': '0:00:12'}, {'epoch': 2, 'Training Loss': 0.39688101776444645, 'Valid. Loss': 0.40850112470798194, 'Valid. Accur.': 0.8515625, 'Training Time': '0:04:19', 'Validation Time': '0:00:12'}, {'epoch': 3, 'Training Loss': 0.3369064816635158, 'Valid. Loss': 0.5122729951690417, 'Valid. Accur.': 0.8671875, 'Training Time': '0:04:18', 'Validation Time': '0:00:12'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    335.    Elapsed: 0:01:01.\n",
            "  Batch   120  of    335.    Elapsed: 0:01:32.\n",
            "  Batch   160  of    335.    Elapsed: 0:02:03.\n",
            "  Batch   200  of    335.    Elapsed: 0:02:33.\n",
            "  Batch   240  of    335.    Elapsed: 0:03:04.\n",
            "  Batch   280  of    335.    Elapsed: 0:03:35.\n",
            "  Batch   320  of    335.    Elapsed: 0:04:05.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:04:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:00:12\n",
            "[{'epoch': 1, 'Training Loss': 0.5154898588781927, 'Valid. Loss': 0.38211005840760964, 'Valid. Accur.': 0.84375, 'Training Time': '0:04:19', 'Validation Time': '0:00:12'}, {'epoch': 2, 'Training Loss': 0.39688101776444645, 'Valid. Loss': 0.40850112470798194, 'Valid. Accur.': 0.8515625, 'Training Time': '0:04:19', 'Validation Time': '0:00:12'}, {'epoch': 3, 'Training Loss': 0.3369064816635158, 'Valid. Loss': 0.5122729951690417, 'Valid. Accur.': 0.8671875, 'Training Time': '0:04:18', 'Validation Time': '0:00:12'}, {'epoch': 4, 'Training Loss': 0.27023513284998374, 'Valid. Loss': 0.6482176482192396, 'Valid. Accur.': 0.8567708333333334, 'Training Time': '0:04:17', 'Validation Time': '0:00:12'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoV30azNxsz"
      },
      "source": [
        "**Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvWJNE7YNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "896e53db-3d85-4ac5-f297-42d5263ce186"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeUBVZfrA8e+9wAVkEUU2wQVRFhEQdxNzC0ElLVNxya3Gskmdn42lTjWVM00zalFpNWm2aO67hOKCWmkqbmkmaoobssq+CFy45/eHw83bRQUFL+jz+Sve8y7POXDyue99z3tUiqIoCCGEEEIIIeoFtakDEEIIIYQQQlSdJPBCCCGEEELUI5LACyGEEEIIUY9IAi+EEEIIIUQ9Igm8EEIIIYQQ9Ygk8EIIIYQQQtQjksALIR55SUlJ+Pj4sGDBgnvuY9asWfj4+NRgVA+v211vHx8fZs2aVaU+FixYgI+PD0lJSTUe34YNG/Dx8eHQoUM13rcQQtQEc1MHIIQQf1SdRDguLg4PD49ajKb+KSoq4r///S9bt24lPT2dxo0b07FjR/785z/j5eVVpT6mTZvG9u3b2bRpE35+fpXWURSFfv36kZeXx759+7CysqrJ06hVhw4dIj4+nvHjx2Nvb2/qcIwkJSXRr18/xowZw9///ndThyOEqGMkgRdC1Dlz5841+Pno0aOsXr2ayMhIOnbsaHCscePG9z2eu7s7J0+exMzM7J77+Mc//sE777xz37HUhDfeeIOYmBgiIiLo0qULGRkZ7N69mxMnTlQ5gR82bBjbt29n/fr1vPHGG5XWOXjwINeuXSMyMrJGkveTJ0+iVj+YL4bj4+NZuHAhTz/9tFECP2TIEAYNGoSFhcUDiUUIIapLEnghRJ0zZMgQg5/Ly8tZvXo17du3Nzr2RwUFBdja2lZrPJVKhaWlZbXjvFVdSfZu3LhBbGwsISEhvP/++/ryKVOmUFpaWuV+QkJCcHNzIzo6mtdeew2NRmNUZ8OGDcDNZL8m3O/voKaYmZnd14c5IYSobbIGXghRb/Xt25exY8dy+vRpnn/+eTp27MjgwYOBm4l8VFQUw4cPp2vXrrRr147Q0FDmz5/PjRs3DPqpbE32rWV79uzhmWeeISAggJCQEP7zn/9QVlZm0Edla+AryvLz83nrrbfo3r07AQEBjBw5khMnThidT3Z2NrNnz6Zr164EBwczbtw4Tp8+zdixY+nbt2+VrolKpUKlUlX6gaKyJPx21Go1Tz/9NDk5OezevdvoeEFBATt27MDb25vAwMBqXe/bqWwNvE6n4/PPP6dv374EBAQQERHBli1bKm1/4cIF3n77bQYNGkRwcDBBQUEMHTqUtWvXGtSbNWsWCxcuBKBfv374+PgY/P5vtwY+KyuLd955h169etGuXTt69erFO++8Q3Z2tkG9ivYHDhxgyZIlPPHEE7Rr146wsDA2btxYpWtRHWfOnOHll1+ma9euBAQEMHDgQBYvXkx5eblBvZSUFGbPnk2fPn1o164d3bt3Z+TIkQYx6XQ6vv76a5588kmCg4Pp0KEDYWFh/O1vf0Or1dZ47EKIeyMz8EKIei05OZnx48cTHh5O//79KSoqAiAtLY1169bRv39/IiIiMDc3Jz4+ni+++IKEhASWLFlSpf6///57VqxYwciRI3nmmWeIi4vjyy+/pGHDhkyePLlKfTz//PM0btyYl19+mZycHL766iteeOEF4uLi9N8WlJaWMnHiRBISEhg6dCgBAQGcPXuWiRMn0rBhwypfDysrK5566inWr1/Pd999R0RERJXb/tHQoUP57LPP2LBhA+Hh4QbHYmJiKC4u5plnngFq7nr/0XvvvcfSpUvp3LkzEyZMIDMzkzlz5tCsWTOjuvHx8Rw5coTevXvj4eGh/zbijTfeICsrixdffBGAyMhICgoK2LlzJ7Nnz6ZRo0bAnZ+9yM/PZ9SoUVy+fJlnnnmGtm3bkpCQwMqVKzl48CBr1641+uYnKiqK4uJiIiMj0Wg0rFy5klmzZtG8eXOjpWD36pdffmHs2LGYm5szZswYmjRpwp49e5g/fz5nzpzRfwtTVlbGxIkTSUtLY/To0bRs2ZKCggLOnj3LkSNHePrppwH47LPP+Pjjj+nTpw8jR47EzMyMpKQkdu/eTWlpaZ35pkmIR54ihBB13Pr16xVvb29l/fr1BuV9+vRRvL29lTVr1hi1KSkpUUpLS43Ko6KiFG9vb+XEiRP6sqtXryre3t7Kxx9/bFQWFBSkXL16VV+u0+mUQYMGKT169DDod+bMmYq3t3elZW+99ZZB+datWxVvb29l5cqV+rJvv/1W8fb2Vj799FODuhXlffr0MTqXyuTn5yuTJk1S2rVrp7Rt21aJiYmpUrvbGTdunOLn56ekpaUZlI8YMULx9/dXMjMzFUW5/+utKIri7e2tzJw5U//zhQsXFB8fH2XcuHFKWVmZvvzUqVOKj4+P4u3tbfC7KSwsNBq/vLxcefbZZ5UOHToYxPfxxx8bta9Q8fd28OBBfdkHH3ygeHt7K99++61B3YrfT1RUlFH7IUOGKCUlJfry1NRUxd/fX5k+fbrRmH9UcY3eeeedO9aLjIxU/Pz8lISEBH2ZTqdTpk2bpnh7eys//fSToiiKkpCQoHh7eyuLFi26Y39PPfWUMmDAgLvGJ4QwLVlCI4So1xwcHBg6dKhRuUaj0c8WlpWVkZubS1ZWFo899hhApUtYKtOvXz+DXW5UKhVdu3YlIyODwsLCKvUxYcIEg5+7desGwOXLl/Vle/bswczMjHHjxhnUHT58OHZ2dlUaR6fT8Ze//IUzZ86wbds2Hn/8cWbMmEF0dLRBvTfffBN/f/8qrYkfNmwY5eXlbNq0SV924cIFfv75Z/r27at/iLimrvet4uLiUBSFiRMnGqxJ9/f3p0ePHkb1GzRooP/vkpISsrOzycnJoUePHhQUFJCYmFjtGCrs3LmTxo0bExkZaVAeGRlJ48aN2bVrl1Gb0aNHGyxbcnFxwdPTk0uXLt1zHLfKzMzk+PHj9O3bF19fX325SqXipZde0scN6P+GDh06RGZm5m37tLW1JS0tjSNHjtRIjEKI2iFLaIQQ9VqzZs1u+8Dh8uXLWbVqFefPn0en0xkcy83NrXL/f+Tg4ABATk4ONjY21e6jYslGTk6OviwpKQlnZ2ej/jQaDR4eHuTl5d11nLi4OPbt28e8efPw8PDgo48+YsqUKbz22muUlZXpl0mcPXuWgICAKq2J79+/P/b29mzYsIEXXngBgPXr1wPol89UqInrfaurV68C0KpVK6NjXl5e7Nu3z6CssLCQhQsXsm3bNlJSUozaVOUa3k5SUhLt2rXD3Nzwn01zc3NatmzJ6dOnjdrc7m/n2rVr9xzHH2MCaN26tdGxVq1aoVar9dfQ3d2dyZMns2jRIkJCQvDz86Nbt26Eh4cTGBiob/fKK6/w8ssvM2bMGJydnenSpQu9e/cmLCysWs9QCCFqlyTwQoh6zdrautLyr776in//+9+EhIQwbtw4nJ2dsbCwIC0tjVmzZqEoSpX6v9NuJPfbR1XbV1XFQ5edO3cGbib/Cxcu5KWXXmL27NmUlZXh6+vLiRMnePfdd6vUp6WlJREREaxYsYJjx44RFBTEli1bcHV1pWfPnvp6NXW978df//pX9u7dy4gRI+jcuTMODg6YmZnx/fff8/XXXxt9qKhtD2pLzKqaPn06w4YNY+/evRw5coR169axZMkS/vSnP/Hqq68CEBwczM6dO9m3bx+HDh3i0KFDfPfdd3z22WesWLFC/+FVCGFaksALIR5Kmzdvxt3dncWLFxskUj/88IMJo7o9d3d3Dhw4QGFhocEsvFarJSkpqUovG6o4z2vXruHm5gbcTOI//fRTJk+ezJtvvom7uzve3t489dRTVY5t2LBhrFixgg0bNpCbm0tGRgaTJ082uK61cb0rZrATExNp3ry5wbELFy4Y/JyXl8fevXsZMmQIc+bMMTj2008/GfWtUqmqHcvFixcpKyszmIUvKyvj0qVLlc6217aKpV3nz583OpaYmIhOpzOKq1mzZowdO5axY8dSUlLC888/zxdffMFzzz2Ho6MjADY2NoSFhREWFgbc/GZlzpw5rFu3jj/96U+1fFZCiKqoW9MDQghRQ9RqNSqVymDmt6ysjMWLF5swqtvr27cv5eXlLF261KB8zZo15OfnV6mPXr16ATd3P7l1fbulpSUffPAB9vb2JCUlERYWZrQU5E78/f3x8/Nj69atLF++HJVKZbT3e21c7759+6JSqfjqq68MtkT89ddfjZLyig8Nf5zpT09PN9pGEn5fL1/VpT1PPPEEWVlZRn2tWbOGrKwsnnjiiSr1U5McHR0JDg5mz549nDt3Tl+uKAqLFi0CIDQ0FLi5i84ft4G0tLTUL0+quA5ZWVlG4/j7+xvUEUKYnszACyEeSuHh4bz//vtMmjSJ0NBQCgoK+O6776qVuD5Iw4cPZ9WqVXz44YdcuXJFv41kbGwsLVq0MNp3vjI9evRg2LBhrFu3jkGDBjFkyBBcXV25evUqmzdvBm4mY5988gleXl4MGDCgyvENGzaMf/zjH/z444906dLFaGa3Nq63l5cXY8aM4dtvv2X8+PH079+fzMxMli9fjq+vr8G6c1tbW3r06MGWLVuwsrIiICCAa9eusXr1ajw8PAyeNwAICgoCYP78+Tz55JNYWlrSpk0bvL29K43lT3/6E7GxscyZM4fTp0/j5+dHQkIC69atw9PTs9Zmpk+dOsWnn35qVG5ubs4LL7zA66+/ztixYxkzZgyjR4/GycmJPXv2sG/fPiIiIujevTtwc3nVm2++Sf/+/fH09MTGxoZTp06xbt06goKC9In8wIEDad++PYGBgTg7O5ORkcGaNWuwsLBg0KBBtXKOQojqq5v/kgkhxH16/vnnURSFdevW8e677+Lk5MSAAQN45plnGDhwoKnDM6LRaPjmm2+YO3cucXFxbNu2jcDAQL7++mtef/11iouLq9TPu+++S5cuXVi1ahVLlixBq9Xi7u5OeHg4zz33HBqNhsjISF599VXs7OwICQmpUr9PPvkkc+fOpaSkxOjhVai96/3666/TpEkT1qxZw9y5c2nZsiV///vfuXz5stGDo/PmzeP9999n9+7dbNy4kZYtWzJ9+nTMzc2ZPXu2Qd2OHTsyY8YMVq1axZtvvklZWRlTpky5bQJvZ2fHypUr+fjjj9m9ezcbNmzA0dGRkSNHMnXq1Gq//beqTpw4UekOPhqNhhdeeIGAgABWrVrFxx9/zMqVKykqKqJZs2bMmDGD5557Tl/fx8eH0NBQ4uPjiY6ORqfT4ebmxosvvmhQ77nnnuP7779n2bJl5Ofn4+joSFBQEC+++KLBTjdCCNNSKQ/iySIhhBD3pLy8nG7duhEYGHjPL0MSQgjxcJE18EIIUUdUNsu+atUq8vLyKt33XAghxKNJltAIIUQd8cYbb1BaWkpwcDAajYbjx4/z3Xff0aJFC0aMGGHq8IQQQtQRsoRGCCHqiE2bNrF8+XIuXbpEUVERjo6O9OrVi7/85S80adLE1OEJIYSoIySBF0IIIYQQoh6RNfBCCCGEEELUI5LACyGEEEIIUY/IQ6zVlJ1diE734FcdOTrakplZ8MDHFaK+kXtFiKqRe0WIqjHFvaJWq2jUyOa2xyWBryadTjFJAl8xthDi7uReEaJq5F4Romrq2r0iS2iEEEIIIYSoRySBF0IIIYQQoh6RBF4IIYQQQoh6RBJ4IYQQQggh6hFJ4IUQQgghhKhHTLoLTWlpKR999BGbN28mLy8PX19fpk+fTvfu3avUPjo6mm+++Ybz58+j0Wjw9vbmtddeIzAwEICkpCT69etXadvFixfz+OOP19i53OrGjUIKCnIpL9fWWJ/p6Wp0Ol2N9SdMy8zMAlvbhlhb336LKCGEEEKIypg0gZ81axY7duxg3LhxtGjRgo0bNzJp0iSWLVtGcHDwHdtGRUXxxRdfMHjwYCIjIykqKuLMmTNkZGQY1R08eDAhISEGZb6+vjV6LhW02lLy87NxcGiChYUlKpWqRvo1N1dTViYJ/MNAURS02hJycq5jbm6BhYXG1CEJIYQQoh4xWQJ/8uRJYmJimD17NhMmTADgqaeeIiIigvnz57N8+fLbtj127Biff/45CxYsIDQ09K5j+fv7M2TIkJoK/Y7y83OwtW2IRmP1QMYT9Y9KpUKjscLGpiEFBTk0auRs6pCEEEIIUY+YbA18bGwsFhYWDB8+XF9maWnJsGHDOHr0KOnp6bdtu3TpUgICAggNDUWn01FYWHjX8YqKiigtLa2R2O+krKwUS0vrWh9H1H9WVtZotbX/NymEEEKIh4vJEviEhAQ8PT2xsTFcAxwYGIiiKCQkJNy27YEDBwgICOCDDz6gY8eOdOjQgb59+7Jly5ZK63/00UcEBwcTGBhIZGQkhw8frtFzuZVOV45abVZr/YuHh1pthk5XbuowhBBCCFGJ+NRjvLH/X0Sufok39v+L+NRjpg5Jz2RLaDIyMnBxcTEqd3JyArjtDHxubi45OTnExMRgZmbGjBkzcHBwYPny5bz66qtYW1vrl9Wo1WpCQkIIDQ3F2dmZy5cvs2TJEiZOnMjXX39Np06dauXcamrdu3i4yd+JEEIIUTfFpx5jxZn1aHU3NyTJLslhxZn1AHRx7WDK0AATJvDFxcVYWFgYlVtaWgJQUlJSabuioiIAcnJyWLNmDUFBQQCEhoYSGhrKJ598ok/gmzZtypIlSwzaDxw4kEGDBjF//nxWrVpV7bgdHW3veDw9XY25ee18sVFb/QrTUavVODnZmTqMh45cUyGqRu4VISoXc3CHPnmvoNVpibm0g0EBvUwU1e9MlsBbWVmh1Rpvs1iRuFck8n9UUe7h4aFP3gE0Gg1hYWEsXbqUwsJCo6U5FVxcXBg0aBBr1qzhxo0bWFtXb716ZmYBOp1y2+M6na5Wdot52HehmTLlBQAWLlz0QNuamk6nIyMj39RhPFScnOzkmgpRBXKvCFG5c9kXuF6UVemx60VZD+S+UatVd5w0NlkC7+TkVOkymYptIJ2dK9+Zw8HBAY1GQ5MmTYyONWnSBEVRKCgouG0CD+Dm5oZOpyMvL6/aCfyjJiSkasuM1q7dgptb01qORgghhBCidlzOu0p04nYSss6hQoWC8YRtI0sHE0RmzGQJvK+vL8uWLTOaLT9x4oT+eGXUajV+fn6kpaUZHUtNTcXMzIyGDRveceyrV69WqZ6AN9+cY/DzmjUrSUtLYerUVwzKHRwa3dc4UVGfmKStEEIIIR5tqYVpRCfu4OeMX7CxaMDQ1hFYm1uz5twmg2U0FmoLBnuFmzDS35ksgQ8PD+fLL79k7dq1+n3gS0tL2bBhAx06dNA/4JqcnMyNGzfw8vIyaPuf//yH/fv306NHDwAKCgrYtm0bwcHBWFnd3IM9KyuLxo0bG4x7+fJlYmJi6NSpk76euL2wsIEGP+/dG0dubo5R+R8VFxdX6/pW9jzEg2grhBBCiEdT5o1stl7cyaHUo1iaaRjoGUrfZj2xNr+Zv5irzdhyIZackhwcLB0Y7BVeJx5gBRMm8EFBQYSHhzN//nwyMjJo3rw5GzduJDk5mffee09fb+bMmcTHx3P27Fl92ahRo1i7di1Tp05lwoQJ2Nvbs379evLz83nlld9nhufNm8fVq1fp1q0bzs7OXLlyRf/g6syZMx/cyT7kpkx5gYKCAl577W8sWBDF2bNnGDNmHM8//yI//riXLVs2cu7cWfLycnFycmbgwCcZO3YiZmZmBn3A7+vYjx07wrRpk3n33blcvJjIpk3rycvLJSAgiFdf/RseHs1qpC3A+vVrWLVqOZmZ1/Hy8mLKlOksXvyZQZ9CCCGEeDjkleYTe2k3+64dRKVS0bdZT/q36IOtxnD5dRfXDnRx7VAnnxcxWQIPMHfuXD788EM2b95Mbm4uPj4+LFq0iI4dO96xnbW1NUuXLmXu3Ll8++23FBcX4+/vz1dffWXQtkePHqxatYpvv/2W/Px87O3t6dGjB1OmTKFNmza1fXo15sCvqWz4IZHM3GIc7S0Z2suL7v6upg7LQE5ONq+9Np3+/cMJDx+Ei8vN+LZu/Q5r6wZERo6hQQNrjh49whdf/JfCwkJefvkvd+33m2+WoFabMXr0OPLz81i5chnvvPMGixd/UyNtN25cR1TUXNq370Bk5ChSUlKYPXsGdnZ2ODnJG1KFEEKIh0WR9ga7rnzPnqs/UqaU092tMwNa9qORVd1Y114dJk3gLS0tmTlz5h1nw5ctW1ZpuZOTE/Pmzbtj/xEREURERNxXjKZ24NdUvtl2htL/7UCTmVfCN9vOANSpJP769QxmzXqTiIghBuVvv/1PLC1/X0rz1FPDmDfvX2zcuJZJk15Co9Hcsd+ysjK+/PIbzM1v/qna2zfko4/mk5h4nlatWt9XW61WyxdffIa/fwAffvipvl7r1m149923JYEXQgghHgIl5aV8f3U/O67s5UbZDTq5tGeQZyjODZxMHdo9M2kC/6jY/0sK+06m3FPbC8m5lJUbPgVdWqbjq60J/PBzcrX6Cgl0o0eA2z3FcTdWVlaEhw8yKr81eS8qKqS0VEtQUDCbN2/g8uVLtGnjfcd+Bw0arE+sAYKC2gOQnHztrgn83dqeOXOa3Nxc/vznpw3qhYaG8/HHH9yxbyGEEELUbWW6MvYnxxN7KY680nzaOfryZKtwPOzq/655ksDXcX9M3u9WbipOTs4GSXCFxMQLLF78GceOHaawsNDgWGFhwV37rViKU8HOzh6A/Py7r0W7W9vU1Jsfqv64Jt7c3Bw3t9r5oCOEEEKI2qVTdBxOPU7MxR1kFmfT2sGTP7Ubi5dDS1OHVmMkgX8AegTc+8z3q5/uJzPP+K20jvaWzBxTN56EBsOZ9gr5+flMnfoCDRrY8vzzk3F390Cj0XDu3Bk++2wBOt3dX0ylVptVWq4od/8Acz9thRBCCFG/KIrCieu/Ep24ndTCNJrZuTPSZyh+jb1RqVSmDq9GSQJfxw3t5WWwBh5AY65maC+vO7SqG44fP0pubi7vvjuP9u1//7CRklK9pT+1xdX15oeqpKSrBAUF68vLyspISUnBy+vOS3SEEEIIUTecyfqNLRdiuZx/FZcGTjzf7lnaO7VDrVKbOrRaIQl8HVfxoGpd34WmMmr1zZvm1hlvrVbLxo1rTRWSAV/ftjRs2JAtWzYSFjZQvwRo585Y8vPzTBydEEIIIe7mYu4VtiTGci77PI0sHRjjO5yurh0wu8238A8LSeDrge7+rvQMakpZ2d2XnNQlAQGB2NnZ8+67bzNsWCQqlYrt27dSV1awWFhY8NxzLxAVNY//+78/06dPP1JSUti2LRp3d4+H7us2IYQQ4mGRXJBKdOJ2Tl7/FVsLG4a1GUyIezcs1I9GavtonKUwiYYNHZg7N4qFCz9k8eLPsLOzp3//AXTq1IVXXpli6vAAeOaZSBRFYdWq5XzyyUd4ebXh3//+gA8/nI9GY2nq8IQQQghxi+s3MvkucSdH0o5jaWZJhGcYfZqFYGX+aP2brVLkib5qycwsQKe7/SVLTb2Mq2uLGh/X3Fxd72bg6yudTkdERCi9evVh5sw3anWs2vp7eZTVxTfmCVEXyb0i6pPckjy2XYpjf/IhzFRm9PboQWiL3thYNKj1sU1xr6jVKhwdbW97XGbgxSOtpKQES0vDT+2xsTHk5eUSHHznNwILIYQQonYVaovYeXkve5P2U66U06NpV8Jb9sXBsqGpQzMpSeDFI+3kyZ/57LMF9O7dF3v7hpw7d4aYmC20auVFnz5PmDo8IYQQ4pFUXFbCnqv72HXle0rKS+jkEkxEq1CaWDuaOrQ6QRJ48Uhr2tSdJk2cWLduNXl5udjbNyQ8fBCTJ0/BwsLC1OEJIYQQjxStrox91w4SeymOAm0hgU38ebJVGE1t6/7uew+SJPDikebu7sHcuVGmDkMIIYR4pJXryjmUeoytF3eSXZKDd6PWDG4VjmfD5qYOrU6SBF4IIYQQQpiETtHxc8YpvkvcQVpROi3smvGs33B8G7cxdWh1miTwQgghhBDigVIUhYSsc2xJjOVq/jVcbVyYFDCOoCb+8h6WKpAEXgghhBBCPDCJuZfYfGEb53Mu4mjViHF+kXR2DUatUps6tHpDEnghhBBCCFHrkvKTiU6M5VTmGew0tozwfooeTbtg/oi8PbUmyRUTQgghhBC1Jr0og5iLOzmS9jPW5tYMaTWAXs16YGmmMXVo9ZYk8EIIIYQQosZlF+ew7VIcB1IOY64yI6xFX55o/jgNHsDbUx92ksALIYQQQogaU1BayI7Le/j+2k8oikJP9+6Et+yLvcbO1KE9NORpAfHAbd0aTUhIJ1JSkvVlw4Y9ybvvvn1Pbe/XsWNHCAnpxLFjR2qsTyGEEOJRc6OsmJiLO3nrwL/ZffVHOjm3561urzLCe4gk7zVMZuDFXb322nSOHTtMdPROrK2tK63zyitT+PXXX9iyZQeWlpYPOMKq2bVrO1lZmYwYMdrUoQghhBAPjdJyLT9eO8D2y7sp1BbR3imAiFb9cbNxMXVoDy1J4MVdhYaG8dNPP7Jv3/eEhoYbHc/OzuLo0cP07z/gnpP3FSvWo1bX7hdCcXE7+O23c0YJfPv2HYiL24+FhUWtji+EEEI8TMp15RxMOcLWS7vIKcnFr7E3T7YKo4V9M1OH9tCTBF7cVc+evbG2bsCuXdsrTeB3795FeXk5/fsbH6sqjcZ0T6Kr1eo6+62BEEIIUdfoFB3H0k8Sk7iD9BvX8bRvzvi2I/Fu5GXq0B4ZksCLu7KysqJnz17s2bOLvLw87O3tDY7v2rUdR0dHmjVrwfz5/+bo0XjS0tKwsrKiQ4dOvPzyX3Bza3rHMYYNe5Lg4I68/vrb+rLExAt8+OE8Tp36hYYNGzJkyFCaNHEyavvjj3vZsmUj586dJS8vFycnZwYOfJKxYydiZmYGwJQpL/Dzz8cACAnpBICrqxvr1kVz7NgRpk2bzMcf/5cOHTrp+42L2/Fg0XwAACAASURBVMG3337N5cuXaNDAhh49evLSS9NwcHDQ15ky5QUKCgr4+9/n8MEHc0lI+BU7O3uGDx/JmDHjq3ehhRBCiDpMURR+zTzDlsRYrhWk0NTGlcmBE2jn6CdvT33AJIGvB+JTjxGdGEtWcQ6NLB0Y7BVOF9cODzSG0NBwduzYxt69cQwe/LS+PDU1hVOnTjJs2EgSEn7l1KmTPPFEGE5OzqSkJLNp03qmTn2Rb79di5WVVZXHy8y8zrRpk9HpdDz77HisrKzZsmVjpTPlW7d+h7V1AyIjx9CggTVHjx7hiy/+S2FhIS+//BcAxo9/jhs3bpCWlsLUqa8AYG19+22stm6N5l//egd//wBeemka6elprF+/moSEX1m8eKlBHHl5ufz1r9Po06cf/fr1Z8+eXXz22QJatWpN9+49qnzOQgghRF31W3YiWxJjScy9RBNrRya0HUVHlyB5e6qJmDSBLy0t5aOPPmLz5s3k5eXh6+vL9OnT6d69e5XaR0dH880333D+/Hk0Gg3e3t689tprBAYG6uvodDqWLFnCypUrycjIoGXLlrz00ksMHDiwtk6rRsWnHmPFmfVodVoAsktyWHFmPcADTeI7d+6Kg0Mjdu3abpDA79q1HUVRCA0Nw8urNX36PGHQrkePx5k8eSJ798YRHj6oyuMtX/4Nubk5fPHFMnx8fAEYMCCCUaOeNqr79tv/xNLy9w8HTz01jHnz/sXGjWuZNOklNBoNnTt3Y8OGteTm5hAWdufffVlZGZ99toDWrb1ZsOBz/fIeHx9f3n77daKjNzJs2Eh9/fT0NN5665/65UUREUMYNiyCmJjNksALIYSo167kJxF9YTuns87SUGPPSJ+hPObWGTO1malDe6SZNIGfNWsWO3bsYNy4cbRo0YKNGzcyadIkli1bRnBw8B3bRkVF8cUXXzB48GAiIyMpKirizJkzZGRkGNVbtGgRkZGRtGvXjri4OKZPn45arSY8/N7XbFfHoZSjHEg5fE9tL+ZeoUwpMyjT6rQsT1jHT8nx1eqru1tnurp1vKc4zM3N6dv3CTZtWs/169dp0qQJALt27cDDoxlt27YzqF9WVkZhYQEeHs2wtbXj3Lkz1UrgDxzYT0BAkD55B2jUqBGhoQPYuHGtQd1bk/eiokJKS7UEBQWzefMGLl++RJs23tU61zNnTpOdnaVP/iv07RvKJ598xE8/7TdI4G1tbXniiTD9zxYWFvj5+ZOcfK1a4wohhBB1RVphOtEXd3A8/SQ25g14uvUgHnd/DI2ZbPhQF5gsgT958iQxMTHMnj2bCRMmAPDUU08RERHB/PnzWb58+W3bHjt2jM8//5wFCxYQGhp623ppaWl89dVXjBs3jtdffx2A4cOH8+yzzzJ37lz69+9f6zuf3K8/Ju93K69NoaHhbNiwlt27dzBixGguXbrI+fPnmDhxEgAlJcUsW/Y1W7dGk5GRjqIo+rYFBQXVGistLZWAgCCj8ubNWxiVJSZeYPHizzh27DCFhYUGxwoLqzcu3FwWVNlYarUaD49mpKWlGJQ7O7sYrf2zs7PnwoXz1R5bCCGEMKWs4my2XtzFwZQjWJhZMKBlP/o1fxxr88q3kRamYbIEPjY2FgsLC4YPH64vs7S0ZNiwYURFRZGeno6zs3OlbZcuXUpAQAChoaHodDpu3LiBjY2NUb1du3ah1WoZPfr3bQNVKhWjRo3ir3/9KydPnqR9+/Y1f3J/0NWt4z3PfL+x/19kl+QYlTeydOD/Oky+39CqJSAgCDc3d3bujGXEiNHs3BkLoF86EhU1j61boxk+fBTt2gVga2sLqHj77b8ZJPM1KT8/n6lTX6BBA1uef34y7u4eaDQazp07w2efLUCn09XKuLdS3+ZrxNo6ZyGEEKKm5ZcWsP3Sbn68dgBUKvo0C6F/iz7YaWxNHZqohMkS+ISEBDw9PY0S78DAQBRFISEh4bYJ/IEDBxg0aBAffPABy5Yto6ioCHd3d/7v//6PwYMHG4xha2uLp6en0RgAp0+ffiAJ/P0Y7BVusAYewEJtwWCvB7P854+eeKI/y5Z9RVLSVeLiduDj46efqa5Y5z516nR9/ZKSkmrPvgO4uLiSlHTVqPzKlcsGPx8/fpTc3FzefXce7dv//kxA5W9qrdoT8q6ubvqxbu1TURSSkq7i6SnbZAkhhHg43Ci7wa4rP7D76o+U6cro5tqJgZ5P0MjK4e6NhcmYbP1IRkZGpQm6k9PNbQLT09MrbZebm0tOTg4xMTGsW7eOGTNm8MEHH+Dq6sqrr77Kzp07DcaoWKtdnTHqki6uHRjt+wyN/3cjNbJ0YLTvMw98F5oK/fsPAGDhwiiSkq4a7P1e2Uz0+vWrKS8vr/Y43bv34JdfTnD27Bl9WXZ2Njt3bjOoV7EE6tbZbq1Wa7ROHsDa2rpKHyZ8fdvSqFFjNm1ah1b7+wenPXviyMhI57HH5MFUIYQQ9VtpeSk7L+/l7z/9m9hLcbRz9OWNLq8wxm+YJO/1gMlm4IuLiyt982XF9nwlJSWVtisqKgIgJyeHNWvWEBR0c510aGgooaGhfPLJJ/p18cXFxZW+IOhuY9yJo+Odv0pKT1djbl6zn4se8+jEYx6d7l7xAWjTpjVt2nizb98PqNVqwsLC9ecbEtKT7du3Ymdni6dnK3755SSHD8fTsKEDKpVKX0+tvjkTbmZmeK1urTNu3AS2b9/GK69MYcSIkVhZWbFp0wZcXd04f/43fdvg4PbY29vz7rtvM2LEKFQq2LZtq77PW8fw8/Njx45tLFwYRdu2/lhbW9OzZy/MzNQGdc3NNbz88jT++c+3mTbtRUJDw0lLS2Xt2lV4ebXm6aef0fepUqlQqTD6nVesib/b34JarcbJye5efhXiDuSaClE1cq88esrKy9h9cT/rf91GdnEuwW7+jAwYgmcjeXvqndS1e8VkCbyVlZXB7GaFiqT6dm/GrCj38PDQJ+9w802eYWFhLF26lMLCQmxsbLCysqK0tLTaY9xJZmYBOt3t1zbrdDrKymp+3bW5ubpW+r0XoaHh/PbbOYKDO+Lg4KiPa+rUvwIqtm/fRklJKQEBQXz44Se88spUFEXR16u4fuXlhtfq1joODo58/PF/iYqayzfffGXwIqd///sf+rY2Nvb85z9RLFz4IZ9//gl2dvb07z+ATp268MorUwzGePLJoZw5k0BMTDSrVi3H1dWN7t17Ul6uM4onPDwCc3MLli//hgULorCxsSE0NJzJk6diZmahr6coCoqC0e+m4huBu/3OdDodGRn59/y7EMacnOzkmgpRBXKvPFp0io4jaT8Tk7iD68VZeDVsyYS2o2nt4AllyN/CHZjiXlGrVXecNFYpJnrSbuLEiVy/fp3o6GiD8gMHDjBhwgQWLVpEr169jNrpdDqCgoJo27Ytq1evNji2aNEi3n//fX744QdcXFx444032LZtG0ePHjWod+XKFUJDQ3nrrbcMHnCtirsl8Kmpl3F1Nd4p5X7VpQRe1Jza+nt5lElSIkTVyL3yaFAUhZPXT/Nd4naSC1PxsG3KYK9w2jb2kbenVlFdTOBNtgbe19eXixcvGm37d+LECf3xyqjVavz8/EhLSzM6lpqaipmZGQ0bNgRuLpkoKCjg4sWLlY7h5+d33+chhBBCCFEXncs+z/tHP2HRL99QpivjOf/RzOw8DX9HX0ne6zmTJfDh4eFotVrWrv39YcPS0lI2bNhAhw4dcHFxASA5OZkLFy4YtU1JSWH//v36soKCArZt20ZwcDBWVjdf7NOvXz8sLCxYsWKFvp6iKKxatYqmTZsaLMERQgghhHgYXM67yoLji/no+CKyS3IZ7fsMb3T9Kx1d2qNW1e3334iqMdka+KCgIMLDw5k/fz4ZGRk0b96cjRs3kpyczHvvvaevN3PmTOLj4zl79qy+bNSoUaxdu5apU6cyYcIE7O3tWb9+Pfn5+bzyyiv6eq6urowbN44vv/ySkpISAgIC2LVrF0eOHCEqKqrOv8RJCCGEEKKqUgrTiE7czomMU9ha2PBM6wh6unfHQt6e+tAxWQIPMHfuXD788EM2b95Mbm4uPj4+LFq0iI4d7/zSI2tra5YuXcrcuXP59ttvKS4uxt/fn6+++sqo7YwZM2jYsCGrV69mw4YNeHp68v777zNw4MDaPDUhhBBCiAci80YWMRd3Ep96DEszDYM8Q+nbrCdW5lamDk3UEpM9xFpfyUOsoibJQ6w1Tx7ME6Jq5F6p/3JL8tl+OY591w6hVql43OMx+jfvg63G+O304t7VxYdYTToDL4QQQgghqqdIW8TOK9+z9+o+ypRyHnPrzADPJ3CwbGjq0MQDIgm8EEIIIUQ9UFJeyt6r+9h55XuKy4rp6BLEIM/+ODcwfuu8eLhJAl8LFEWR7ZnEXcnqNSGEEFWh1ZWxP/kQsZfiyC8tIKCJH0+2Csfd1s3UoQkTkQS+hpmZmaPVlqLRVP8tr+LRotWWYmYmt6AQQojK6RQd8anHiLm4k6zibNo4tOKFgHG0atjS1KEJE5PsoYbZ2jqQk5OBg4MTFhYamYkXRhRFQastJScnAzu7RqYORwghRB2jKAonMk4Rnbid1KJ0mtu5M9rnGXwbt5G8QgCSwNc4a+ubT37n5l6nvLysxvpVq9XodLILzcPCzMwcO7tG+r8XIYQQQlEUzmT/xpYLsVzJT8KlgTN/ajeW9k7tJHEXBiSBrwXW1jY1npjJdl9CCCHEw+ti7mU2X9jGbzmJNLJ04Fm/EXRxCcZMbWbq0EQdJAm8EEIIIYSJXCtIITpxO79cP42dhS3D2wyhh3tXLNSSoonbk78OIYQQQogHLKMok5iLOziS9jNW5pY82Sqc3h49sDKXTTDE3UkCL4QQQgjxgOSU5LLtUhw/JcdjpjIjtEVvnmjeCxuLBqYOTdQjksALIYQQQtSyAm0hOy/v5fuk/egUhZCm3Qhv2ZeGlvamDk3UQ5LACyGEEELUkuKyYvZc3ceuKz9QUl5CF9cODPQMpYl1Y1OHJuoxSeCFEEIIIWqYtlzLj8kH2X5pNwXaQoKc2hHh2Z+mtq6mDk08BCSBF0IIIYSoIeW6cg6lHmXrxV1kl+Tg26gNT3qF0dK+ualDEw8RSeCFEEIIIe6TTtFxPP0Xvru4nfSi67Swb8ZYvxH4NG5t6tDEQ0gSeCGEEEKIe6QoCqezzhJ9IZarBcm42bjwQsB4Apu0lbenilojCbwQQgghxD04n3ORLRdiuZB7EUerxoxvO5JOLu1Rq9SmDk085CSBF0IIIYSohqv5yUQnxvJr5hnsNXZEej/NY007Yy5vTxUPiPylCSGEEEJUQVpRBjGJOziafoIG5tYM8RpAb48eaMw0pg5NPGIkgRdCCCGEuIPs4hy2XtzFwdQjmKvNCW/Rl37Ne9HAwtrUoYlHlCTwQgghhBCVyC8tYMflPfxw7QAoCo+7dyesZV/sNXamDk084iSBF0IIIYS4xY2yYuKu/MDuqz9QWq6lq1tHBrYMxdG6kalDEwKQBF4IIYQQAoDSci0/XPuJHZf3UKgtItgpgIhWYbjaOJs6NCEMSAIvhBBCiEdaua6cAymH2XYpjpySXPwaezO4VTjN7T1MHZoQlZIEXgghhBCPJJ2i41jaCb67uIOMG5m0atiCCW1H0qaRl6lDE+KOTJrAl5aW8tFHH7F582by8vLw9fVl+vTpdO/e/Y7tFixYwMKFC43KmzRpwv79+w3KfHx8Ku3j7bffZtSoUfcevBBCCCHqJUVROJWZQHTidq4VpOBu68ZLgRPxd/SVt6eKesGkCfysWbPYsWMH48aNo0WLFmzcuJFJkyaxbNkygoOD79p+zpw5WFlZ6X++9b9vFRISwuDBgw3KgoKC7i94IYQQQtQ7v2VfYEtiLIm5l3GydmRi21F0cAmSt6eKesVkCfzJkyeJiYlh9uzZTJgwAYCnnnqKiIgI5s+fz/Lly+/ax4ABA7C3t79rvVatWjFkyJD7DVkIIYQQ9dSVvCS2JMaSkHUOB8uGjPIZSne3zpipzUwdmhDVZrIEPjY2FgsLC4YPH64vs7S0ZNiwYURFRZGeno6z852f+lYUhYKCAmxsbO76lVdxcTEqlQpLS8saiV8IIYQQdV9qYRrRiTv4OeMXbCwa8HTrQTzu/hgaMwtThybEPTNZAp+QkICnpyc2NjYG5YGBgSiKQkJCwl0T+N69e1NUVISNjQ1hYWHMnDkTBwcHo3rr1q1j2bJlKIqCt7c306ZNIzQ0tEbPRwghhBB1R+aNbLZe2smhlKNozCwY2PIJ+jZ/HGvzypfbClGfmCyBz8jIwMXFxajcyckJgPT09Nu2tbe3Z+zYsQQFBWFhYcHBgwdZvXo1p0+fZu3atWg0Gn3d4OBgBg4ciIeHBykpKSxdupQpU6bw/vvvExERUfMnJoQQQgiTySvNZ/ul3ey7dhBUKvo0C6F/iz7YaWxNHZoQNcZkCXxxcTEWFsZfX1UscSkpKblt2/Hjxxv8HB4eTps2bZgzZw6bNm1ixIgR+mOrVq0yqPv0008TERHBvHnzGDRoULWfNnd0NN3/AJyc5NXNQlSF3CtCVM3DdK8UlhYRfXYnMef2oC3X0sfzMZ7xH0CTBo1NHZp4CNS1e8VkCbyVlRVardaovCJxr+5a9VGjRjFv3jwOHDhgkMD/UYMGDRg5ciTvv/8+iYmJeHlVb6/XzMwCdDqlWm1qgpOTHRkZ+Q98XCHqG7lXhKiah+VeKS0vZW/SfnZe3ktR2Q06OgcxqFV/XBo4oRRCRmH9P0dhWqa4V9Rq1R0njU2WwDs5OVW6TCYjIwPgruvf/0itVuPi4kJubu5d67q5uQFUqa4QQggh6p4yXRk/Jcez7VIceaX5tHP0JaJVOM3smpo6NCFqnckSeF9fX5YtW0ZhYaHBg6wnTpzQH68OrVZLSkoK7dq1u2vdq1evAtC4sXytJoQQQtQnOkXH4dTjxFzcSWZxFl4NPXm+3bO0dvA0dWhCPDAme2tBeHg4Wq2WtWvX6stKS0vZsGEDHTp00D/gmpyczIULFwzaZmVlGfW3ZMkSSkpK6Nmz5x3rZWdns2LFCjw8PGjZsmUNnY0QQgghapOiKJzIOMW/4qNYmrCaBuZW/DnoeaZ3mCzJu3jkmGwGPigoiPDwcObPn09GRgbNmzdn48aNJCcn89577+nrzZw5k/j4eM6ePasv69OnDwMHDsTb2xuNRsOhQ4fYvn07HTt2NNhZZvny5cTFxdG7d2+aNm1KWloaq1evJisri08++eSBnq8QQggh7s2ZrN/YkhjL5byruDRw4vl2z9LeqZ28PVU8skyWwAPMnTuXDz/8kM2bN5Obm4uPjw+LFi2iY8eOd2z35JNPcuzYMWJjY9Fqtbi7u/PnP/+ZF198EXPz308pODiYY8eOsXbtWnJzc2nQoAHt27fnxRdfvOsYQgghhDCti7lXiE6M5Wz2eRpZOjDGdzhdXTvI21PFI0+lKMqD31KlHpNdaISo2+ReEaJq6vK9klyQyneJ2zlx/VdsLWwIb9mPkKZdsZC3pwoTkF1ohBBCCCFu4/qNTGIu7uRw6nEszSyJ8AyjT7MeWMnbU4UwIAm8EEIIIUwqtySP2Etx7E+OR61S0a/544S26I2thc3dGwvxCJIEXgghhBAmUagtYuflvexN2k+5Us5jTbswoGU/HCwbmjo0Ieo0SeCFEEII8UAVl5WwN2kfu658T3FZCZ1cghnkGYpTA0dThyZEvSAJvBBCCCEeCK2ujH3XDrL90m7ytQUENvEnolV/3G3dTB2aEPWKJPBCCCGEqFXlunLi046z9eJOsoqz8Xbw4kWv8Xg2bGHq0ISolySBF0IIIUStUBSFnzNOEZ24nbSidFrYNWOM7zB8GrVGpVKZOjwh6i1J4IUQQghRoxRF+d/bU7dxJf8arjYuTAoYR1ATf0nchagBksALIYQQosYk5l5iy4VYfstJxNGqEeP8IunsGoxapTZ1aEI8NCSBF0IIIcR9u1aQwpYLsZzKTMBOY8tw7yH0aNoVC7WkGkLUNLmrhBBCCHHP0ouuE3NxB0fTTmBlbsXgVuH0bhaCpZnG1KEJ8dCSBF4IIYQQ1ZZTksvWi7s4kHIYc5UZoS16E9q8Fw0sGpg6NCEeepLACyGEEKLKCkoL2XF5Dz9c+wmdotDTvRthLfrR0NLO1KEJ8ciQBF4IIYQQd1VcVszuqz8Sd+UHSspL6eLagYGeoTSxbmzq0IR45EgCL4QQQojb0pZr+fHaAbZf3kOBtpD2Tu2IaBWGm42LqUMT4pElCbwQQgghjJTryjmYeoStF3eRU5KLb6M2DPYKp4V9M1OHJsQjTxL4Ou7Ar6ls+P4CWXklNLa3ZGgvL7r7u5o6LCGEEA8pnaLjePpJvkvcQfqN63jaN2d820i8G7U2dWhCiP+RBL4OO/BrKt9sO0NpmQ6AzLwSvtl2BkCSeCGEEDVKURR+zTxDdOJ2kgqSaWrjyosB4wlo0lbenipEHSMJfB224fsL+uS9QmmZjg3fX5AEXgghRI05n3ORLRe2cSH3Ek2sGjO+7Ug6ubSXt6cKUUdJAl+HZeaVVKtcCCGEuJv41GNsuRBLTkkOdho7bC1sSC5MpaHGjpE+T/OYWxfM1GamDlMIcQeSwNdhjvaWt03Wv/juNOFdmuPhbPuAoxJCCFFfxaceY8WZ9Wh1WgDySvPJK82no3MQz/oNRyNvTxWiXpDvxuqwob280Jgb/ooszNX4t2zEkbPp/P3LeKLWnCDhcjaKopgoSiGEEPVBua6c9b9F65P3WyXmXpbkXYh6RGbg67CKde6V7UJTcEPLnmNJxB1NYt7K47R0tSO8a3M6+jhhppbPZUIIIW7KvJHFT8nx/JRymAJtYaV1sktyHnBUQoj7oVJk6rZaMjML0Oke/CVzcrIjIyPfqLxUW85Pv6ay/dAV0rJv4ORgRf/OzQkJdMPSQtYwikfP7e4VIR4l5bpyTmUmsO/aIRKyzgHg7+jDpbyrlSbxjSwd+GePvz3oMIWoF0zx74parcLR8fbLpGUGvp7TWJjRu707jwc25fhv14k9dJnlO8+xed9F+nZwp29HD+wbyNeiQgjxKMi8kc1PKfEcSI4ntzSfhhp7wlv247GmnWls1choDTyAhdqCwV7hJoxaCFFdJp2BLy0t5aOPPmLz5s3k5eXh6+vL9OnT6d69+x3bLViwgIULFxqVN2nShP379xuVr127li+//JKkpCSaNm3KuHHjGDNmzD3FXNdm4P9IURR+S8ol9tAVfj5/HQtzNSGBboR1boZzowYPIFIhTEtm4MWj5uZs+xn2Jx/idOZZANo6+hDStCv+jr5GO8rcuguNg6UDg73C6eLawRShC1EvyAz8H8yaNYsdO3Ywbtw4WrRowcaNG5k0aRLLli0jODj4ru3nzJmDlZWV/udb/7vCqlWreOuttwgPD2fixIkcOXKEOXPmUFJSwnPPPVej51MXqFQqvJs54N3MgeTrhWyPv8KPJ5LZe/waHb2dGNCtBZ5u9qYOUwghxH3KKs7mp+TDHEg5TE5J7v9m2/vS3a0LjtaNbtuui2sHurh2kA+7QtRjJpuBP3nyJMOHD2f27NlMmDABgJKSEiIiInB2dmb58uW3bVsxA3/48GHs7W+fjBYXF9OrVy86duzIp59+qi+fMWMGu3fv5vvvv8fOzq5acdf1GfjK5BSUsOtIEnuOX+NGSRk+zRwI79qcAC9H1PJ2PfGQkaREPMzKdeWczjrLvmsH+fV/s+1+jt6ENO1KO0e/au3fLveKEFUjM/C3iI2NxcLCguHDh+vLLC0tGTZsGFFRUaSnp+Ps7HzHPhRFoaCgABsbm0pf83zo0CFycnIYPXq0QfmYMWOIjo7mhx9+YNCgQTVzQnWYg60lw3p7Mah7C344kcyOw1f5aN1J3JvYENalOd38XTA3k51rhBCirsouztHvJJNTkou9xo6wFn14rGkXHK0bmzo8IcQDZrIEPiEhAU9PT2xsbAzKAwMDURSFhISEuybwvXv3pqioCBsbG8LCwpg5cyYODg7646dPnwagXbt2Bu38/f1Rq9WcPn36kUjgK1hbmhPWpTn9OnpwOCGdbYcu8+XWBDb+mMgTnTzoFeROAyt5rlkIIeoCnaLj18wz7Lt2iF8zzwDg27gNw72HEFDN2XYhxMPFZNlaRkYGLi4uRuVOTk4ApKen37atvb09Y8eOJSgoCAsLCw4ePMjq1as5ffo0a9euRaPR6MfQaDQGST2gL7vTGA8zczM13du50s3fhV8vZrHt0BXW7rnAdz9dold7d0I7NaORnaWpwxRCiEdSdnEOB1IO81PyYbJLcrDT2NL/f7PtTWS2XQiBCRP44uJiLCwsjMotLW8mjiUlJbdtO378eIOfw8PDadOmDXPmzGHTpk2MGDHijmNUjHOnMW7nTuuRapuTU/XW61eFs7M9fbq25HxSDhv3nGdH/BV2HbnK48EeDO3dmhbywKuoh2rjXhGiNul0On5OPc2uCz9yNOUXFEUh0MWPiV7D6eQehHktzbbLvSJE1dS1e8VkCbyVlRVarfHrnCuS6opEvqpGjRrFvHnzOHDggD6Bt7KyorS0tNL6JSUl1R4D6udDrFXR0NKMCeE+DOrWnB2Hr/LjiWvsPnKVQC9HBnRtjnczh0qfMxCirpEH80R9klOSy4Hkw+xPjr85225hS2jz3vRo2oUm1o4AZGcW1crYcq8IUTXyEOstnJycKl3CkpGRAXDX9e9/pFarcXFxITc312AMrVZLTk6OwTKa0tJScnJyqj3Go8DJwZoxod4MCfFk97Ek4o4m8Z8Vx/F0s2NA1xZ08HZCrZZEXggh7pVO0ZGQdY791w7xS2YCOkWHb6M2DG0TQWCTtpir5VkkIcSdmez/Er6+vixbtozCwkKDB1lPnDihP14dzMqaZAAAIABJREFUWq2WlJQUgwdW/fz8ADh16hQhISH68lOnTqHT6fTHhTFbawsG9/AkvEtz9p9KZXv8FT7ddApnB2v6d2lGjwA3LC3kASohhKiq3JI8DqTcnG3PKs7G1sKGfs0e57GmXXBu0MTU4Qkh6hGTJfDh4eF8+eWXrF27Vr8PfGlpKRs2bKBDhw76B1yTk5O5ceMGXl5e+rZZWVk0bmz4IM+SJUsoKSmhZ8+e+rJu3brh4ODAihUrDBL4lStX0qBBAx5//PFaPMOHg8bCjD7B7vQKasrx3zLYdugK3+44x6YfL9Kvowd9O7hj10Bj6jCFEKJO0ik6zmT9xr7kQ/xy/TQ6RYdPo9Y85TWQICd/mW0XQtwTk/2fIygoiPDwcObPn09GRgbNmzdn48aNJCcn89577+nrzZw5k/j4eM6ePasv69OnDwMHDsTb2xuNRsOhQ4fYvn07HTt2JCIiQl/PysqKadOmMWfOHP7yl78QEhLCkSNH2LJlCzNmzLjjS6CEIbVa9f/s3Xl00/ed7/+nZMuSZVuSF3mRbBljg01YjcGGQCA0m0lI2mRCb1t6aTqZnJxfmklv5uZM25Pf6czJ3JnMpEmTTqe5c9Jfc++ESZpmgUCmCSGBAIEEm90shrAFL7KxMbYM3m3p94eMwGGzibG8vB7n9BwsffXVRykf9OLD+/P+UJCbzMyJTo5U+fhw20lWbznBh9tOMn9aGncWekh2RId7mCIiw4Kv42xvJ5kSGnpX27+VcQvzXIUkW53hHp6IjHBh/av/c889x0svvcTq1avx+Xzk5ubyyiuvUFBQcNXX3XvvvezatYu1a9fS1dWF2+3mscce49FHHyUysu9HWrZsGSaTiVdffZX169eTlpbG008/zfLly2/kRxu1DAYDEzMcTMxwUH26hY9KK9i0x8unu6uZlZtMcZGHLHWuEZExyB/wc/jMUbZ4t1HWu9o+0ZHNt7MXM805BZNW20VkkBgCgcDQt1QZwUZrF5pvovFsB5/srGTjbi9tHd3keRwUF2UydXyCOtfIkBvOc0VGp+bOs2zz7mCrt4TT7WeIMVmZkzaLea4iUobxarvmikj/DMcuNArwA6QAf2VtHd1s2uPl4x2VNJ7twO2MobjQQ9FNKURGGMM9PBkjRsJckZHPH/DzZeMxtlRvY+/pA/gDfiY4xjPfVcT05KkjYrVdc0WkfxTgRwEF+Gvr7vFTcvAUa0srqK5vIT7OzB2zMlg4w0W0efh/qcnINpLmiow8ZzvPhTrJnG5rICbSSlFaAfNdRaTEjKzWxJorIv0zHAO80pQMusgII/OmpnHzlFT2HT/D2pKTvPXpUd7//AS3znBz+6wM4uMGfoiWiEg4nF9t3+otYW/9AXoCPeQ4sliSdScznFMwRVz+xG8RkRtFAV5uGIPBwLTsRKZlJ3Kippm1JRWsLa1g3fZK5k5O5a4iD+6kmGvfSEQkDM52nmNbTbC2vb53tX1h+s3McxWSGpMS7uGJyBimAC9DIivNxv/znSnUNbWxrrSCLWU1bNlXw/TsRIqLPEzMcGjDq4iEXSAQ4EjTMbZUl7Cnfj89gR6y7VncnXUH+c6pWm0XkWFBNfADpBr4wXG2tZNPd1Xzyc4qzrV1kZVmY3GRh5kTnRiNCvJy/UbbXJGhca6zhW21O9haXUJd22miI6OZk1rAPHcRaaN0tV1zRaR/hmMNvAL8ACnAD66Orh4+31fDR6WV1DW1kRwfzV2FHuZNSSXKFBHu4ckINFrnigy+4Gr7cbZ6S9hTt4/uQA/j7eOY7yoiP3kaUaN8tV1zRaR/FOBHAQX4G8PvD7Dry3o+LDnJiZqzxFlN3DYznW8VpBMbPbq/RGVwjfa5It/cuc4WSmp3stVbwqnWeqIjLRSmBjvJuGJTwz28IaO5ItI/wzHAD0oNfHd3N+vXr8fn87Fo0SKczuF7cIUMT0ajgVl5yRTkOvmysokPSyp4b8sJPig5yS1TXdxZmIHTER3uYYrICBUIBDjadIIt3m2h1fYsWyb/fdJ3mZk8jaiIqHAPUUSk3wYc4J977jlKSkp49913geAfij/+8Y/ZsWMHgUAAh8PBW2+9hcfjGfTByuhnMBjI9cST64mnuv4ca0sr2Linmg27q5idl0xxkYdxqbZwD1NERoiWrlZKanawxVvKqdY6oiMtzHMXMc9VhDs2LdzDExG5LgMO8J999hk333xz6OcNGzawfft2/uqv/opJkybxD//wD7zyyiv8r//1vwZ1oDL2uJ2xPHzPTTywIJtPdlSycU81peV1TMqMp7jIw5SsBHWuEZFLBAIBjvm+Ykt1Cbvry+j2d5Nl8/DDSd+lQKvtIjIKDDjA19bWkpmZGfr5008/JT09naeeegqAI0eO8P777w/eCGXMi48zs3RRDvfMHcfmvV7Wba/gxbf2ku6MobjIQ+GkFCIjjOEepoiEWWtXKyW1u9jiLaG25RSWCAs3pxUy363VdhEZXQYc4Lu6uoiMvPCykpKSPivyGRkZ1NfXD87oRC5itURSXOTh9lnplBw8xdqSCv6//yrn3U3HuXN2Bgumu4g262gDkbEkEAhw3HeSLd5t7K4ro8vfzTibh2V5SylImY5Zq+0iMgoNOO2kpqaye/duvvvd73LkyBEqKyt54oknQs83NDRgtVoHdZAiF4uMMDJvaho3T0ll3/EG1pZU8KcNR1mz9StuzXdxx6wMHLHmcA9TRG6g86vtW70l1LScwhJhZk7abOa5isiIc4V7eCIiN9SAA/w999zDyy+/zJkzZzhy5AixsbEsXLgw9Hx5ebk2sMqQMBgMTMtOYlp2EidqmvmwpIK1JRV8vL2SOZNTKS704EqKCfcwRWSQBAIBTjRXsKV6G7vq9tLl7yYzLoNleQ8yM3k6lkj9xV1ExoYBB/hHH32Umpoa1q9fT2xsLP/yL/+CzRbsCnL27Fk2bNjAQw89NNjjFLmqrDQbj31nCnWNrXy0vZKtZTVsKathRk4SxUUeJqTbteFVZIRq7Wqj9NQutlaX4G2pxRwRRVFqAfPdc8iIc4d7eCIiQ25QD3Ly+/20tLRgsVgwmUbn4Ts6yGlkONvayYZd1azfWcW5ti6yXTaKizzkT3BiNCrIj2aaK6NDIBDgq+YKtlSXsLNuL13+Ljxxbua75lCQMkOr7YNAc0Wkf0btQU7ndXd3ExcXN5i3FLkucdYovj0/i+IiD1v31fBRaQW/W7WflPho7ir0cPOUVKJMEeEepoh8TVt3G6W1u9nqLaH6XA3miCgKU2cy31WEx5Ye7uGJiAwLA16B37RpE2VlZfz1X/916LHXX3+dF154gfb2dhYvXsw///M/awV+kGml5Jvx+wPs/LKeD7ed5Kvas8RZTdxekM6imenERo/O36tjlebKyBNcba9kq7eEnaf20OnvIiPOzXxXEbNSZmCJtIR7iKOS5opI/4yKFfg//OEPJCYmhn4+duwY//RP/0RGRgbp6el88MEHTJ06VXXwMqwYjQZm5yUzK9fJ4Yom1pZWsOqzE/x520lumebirtkZJDmiwz1MkTGlrbud7bW72eLdRvW5GqIiopidms88VxGZtoxwD09EZNgacIA/fvx4n64zH3zwAWazmXfeeYfY2Fj+5//8n7z33nsK8DIsGQwG8jLjycuMp6r+HB+VVLBxdzWf7qpmVp6TxUWZZKaqDEzkRgkEAlScrWJL9TZ29K62p8e6+F7u/cxKySdaq+0iItc04ADv8/mIj48P/fz5558zZ84cYmODy/yFhYVs2rRp8EYocoOkO2N5eMlN3L9gPJ/sqGLjnmpKy+uYlBnP4iIPk7MS1LlGZJC0d7ez/dRutlaXUHnOS5TRxKyUGcx3z8ETl665JiIyAAMO8PHx8Xi9XgDOnTvHvn37+Ju/+ZvQ893d3fT09AzeCEVusASbhe9+K4clN49j055qPt5Rya/f2ktGcizFhR5mT0omMsIY7mGKjEgVzVVs8W5j+6k9dPZ04o5N479NvJ/ZqTOIjlTZmojI9RhwgJ8xYwZvvvkmOTk5bN68mZ6eHhYsWBB6/uTJkyQnJw/qIEWGgtUSyeI5mdwxO4NtB06xtrSC3//XQd7dfIw7Z2Vwy3QX0eZBbdwkMiq1d7ez49QetnhLqDxbjclooiBlOvNdcxhny9Bqu4jINzTgNPLEE0+wfPly/sf/+B8A3H///eTk5ADB2sZPPvmEoqKiwR2lyBCKjDAyf1oaN09NZd+xBtaWVPDmhqOs2foVi2a6ub0gHXuselCLfF2wtr2EHad209HTiSsmle9O/A6FqflabRcRGUTXdZBTU1MTu3btIi4ujtmzZ4ce9/l8vPfeexQVFZGXlzeoAx0u1EZybDrubWZtyUl2Hq4nIsLAzVNSuavQQ1piTLiHJl+juTK02rs72Nm72l5xtiq42p48nfnuIsbZPFptH8Y0V0T6Zzi2kRzUk1gHqrOzk9/85jesXr2a5uZm8vLyePLJJ5k7d+6A7vPII4+wefNmli9fztNPP93nudzc3Mu+5u///u/5/ve/P+AxK8CPbacaW1lXWsmWfTV0dfuZkZPE4jkeJqQ7wj006aW5MjQqz1azxVvCjtrdtPd04IpJZZ67iMKUmVhNWm0fCTRXRPpnOAb46y7oraioYP369VRWVgKQkZHBbbfdhsfj6fc9fv7zn7Nu3TqWL19OZmYmq1at4pFHHmHFihXk5+f36x4bN25kx44dV71m/vz53HfffX0emz59er/HKXJeSryV/35XLt++JYsNO6vYsKuaZ/9zF9luG8WFmeRPTMKoFUcZpTp6OoOr7dUlnDxbickYycze1fYsW6ZW20VEhsh1BfiXXnqJ3//+95d0m/nVr37Fo48+yk9/+tNr3qOsrIw///nP/OIXvwj1jP/Od77DkiVLeP7553n99deveY/Ozk6effZZHn74YX77299e8brx48fz7W9/+5r3E+kvmzWK79wynsVFmWzZV8NHpRX8btU+UhKs3FWYwbwpqZgiI8I9TJFBUXXWyxZvCdtrd9He00FqTAoPTriPotSZWE3WcA9PRGTMGXCAf+edd/j3f/938vPz+au/+ismTJgAwJEjR/jDH/7Av//7v5ORkcEDDzxw1fusXbsWk8nE0qVLQ4+ZzWYefPBBXnzxRerq6q7Zzea1116jvb39mgEeoL29HYPBgNmszYcyeMxREdxWkM6t+S52Hq7nw5IKXlt7mPc+O8FtBeksyncTG20K9zBFBiy42r6Xrd4SvmquINIYyczkacx3zWG8XavtIiLhNOAA/8YbbzB9+nRWrFhBZOSFl3s8HhYuXMiyZcv4z//8z2sG+PLycrKysoiJ6bsJcNq0aQQCAcrLy68a4Ovr63n55Zf55S9/SXT01est33nnHVasWEEgEGDixIk88cQT3HHHHf34tCL9E2E0Ujgphdl5yRyqaGJtSQWrNh/ngy9Ocsv0NO6cnUGSXXXBMvxVn6thS3UJpbW7aO9pJ9WazIMT7qMwdSYxWm0XERkWBhzgjx07xt/8zd/0Ce+hm0VGcvfdd/PrX//6mvepr68nJSXlksedTicAdXV1V339r3/9a7Kysq5ZGpOfn8/dd99Neno6NTU1vPbaazz++OO88MILLFmy5Jrj/LqrbSi40ZzOuLC9t/RfcrKNBbM8fFXTzKqNR/l0V7BW/pbpbh5YlMN4tz3cQxz1NFcGpqO7ky8qd/Lxsc840nACkzGSooyZ3JE9n7ykHK22j2KaKyL9M9zmyoADvMlkorW19YrPt7S0YDJdu2Sgvb39stedL3Hp6Oi44mvLysp47733WLFixTW/WN58880+P99///0sWbKEX/3qV9xzzz0D/mJSFxrpr5hIAz+8fQJ3F2bw8Y5KNu7xsml3FTeNi2dxUSY3jYtXMLoBNFf6z3uuli3ebZTW7qKtu50Uq5O/yFlCYVoBsabgv46ePn0uzKOUG0VzRaR/RkUXmqlTp/KnP/2JpUuXkpSU1Oe5hoYG3nrrrX51eLFYLHR1dV3y+PngfqVa9UAgwD/+4z9y5513MmvWrIEOH6vVyve+9z1eeOEFjh8/TnZ29oDvITIQCTYL/+1bE7j35nFs3OPl4x2VvPCnPXiSY7mryMPsvGQiI4zhHqaMEZ09XeyuK2OLdxvHfSeJNEQwI3kq811zyHFk6S+VIiIjwIAD/GOPPcZDDz3E3XffzV/8xV+ETmE9evQoK1eupKWlheeff/6a93E6nZctk6mvrwe4Yv37xx9/TFlZGU8++SRVVVV9njt37hxVVVUkJSVhsViu+N5paWlA8OApkaFitZi4e04md8zKYNvBWtaWVPD79w+yctMx7pjtYcH0NCxR193ZVeSqvOdq2eotoaR2F23dbSRbk3ggZwlFqQXERulAMhGRkWTAaWH27Nn89re/5R/+4R/4P//n//R5zuVy8S//8i/9WhnPy8tjxYoVtLS09NnIunfv3tDzl+P1evH7/fzoRz+65LmVK1eycuVKfv/737NgwYIrvvf53vUJCQnXHKfIYDNFGrllmot5U9MoO9bA2m0neXP9Ed7feoJb893cXpCOPVbdkuSbu7DaXsJx31eh1fZ5riImOMZrtV1EZIS67pNY/X4/+/fvD62CZ2RkMHnyZN566y1ee+01Pvjgg6u+fu/evXz3u9/t0we+s7OTJUuWkJiYyB//+EcgGNjb2tpCpS4VFRV8+eWXl9zvJz/5CYsWLeLBBx8kPz+fxMREzpw5c0lIb2xs5N5778VsNrN+/foBf27VwMuNcKzax9qSCnZ9WU9EhJGbp6RyV2EGaYlaGR0ozRWobTnFluoSSmp30trdRnJ0EvPcRRSlFhAXFb6N+DK8aK6I9M+oqIG/cGMj06ZNY9q0aX0eb2xs5MSJE9d8/fTp0ykuLub555+nvr4ej8fDqlWr8Hq9PPvss6Hrfvazn1FaWsrhw4eBYLvKK532mpGRwe233x76+fXXX2f9+vXceuutuFwuTp06xZ/+9CfOnDnD7373u+v52CI3RLbbzk8emMqpM618tL2SLWU1fLbXy4wJSSwuyiQnXZ1r5Oq6errYXb+PLdUlHPOdIMIQwQznFOa7i5jgyNZqu4jIKBLWgtvnnnuOl156idWrV+Pz+cjNzeWVV16hoKBgUO6fn5/Prl27ePvtt/H5fFitVmbMmMGjjz46aO8hMphSEqwsvyuX78zPYv3OKjbsqmL3kdPkuO0sLvIwfUISRgUxuUhtS12wtr1mJy3drTijE/lO9t3MSZul1XYRkVHquktoruR//+//zb/+679SXl4+mLcdNlRCI0Opo7OHz8q8rNteyWlfO6kJVoqLPMydnIIpMiLcwxuWxsJc6fJ3s6duH1u82zjadAKjwch05xTmu4qYGJ+N0aCuRnJtY2GuiAyGUVVCIyI3njkqgttnZbBoppsdh+pZW1LB//3wECs3H+f2gnQWzXQTY7n2uQsyOpxqqWOrt5RttTto6WolyZLAt7MXMydtFrao4XXIiIiI3DgK8CIjQITRSNFNKRROSubQyUY+LKlg5ebj/PmLkyyY7uLO2Rkk2q/cOlVGri5/N3vr97OlehtHmo4HV9uTJjPfPUer7SIiY1S/AvzX20Veza5du657MCJydQaDgUnjEpg0LoGKU2f5qLSCDbuqWL+zisKbkiku9OBJ0UrsaFDXWs+W3tr2c10tJFoS+Pb4xRSlzcJu1v/HIiJjWb9q4K/Uk/2KNzUYVAM/yFSrKFdyprmdddsr2bTXS0dnD5OzEigu8nBTZvyY7DwykudK9/nVdm8pXzYexWgwMi1pMvNdReQm5Gi1XQbVSJ4rIkNpONbA9yvAl5aWDviNCwsLB/yakUABXoar1vYuPt1dzSc7qvC1dOJJiaW4yMPsvGQijGMn+I3EuVLXeprPvaV8UbO9d7U9nptdRcxNm4XdbAv38GSUGolzRSQcRmyAlwsU4GW46+r288WBWj4qraCmoZVEm4U7CzO4ZVoalqjRv+1lpMyV4Gr7AbZ6Szjcu9o+Nekm5ruKyEuYoNV2ueFGylwRCTcF+FFAAV5GCn8gwN6jp1lbUsGRKh8xlkgWzXRzW0EG9piocA/vhhnuc6W+tYGt3hK21ezgbNc5EizxzHMVMidtFg6zDuySoTPc54rIcDEcA/zoX44TGaOMBgP5E5zkT3BytNrH2pIK/vz5SdaWVDJvaip3FXpITbCGe5hjQo+/h72nD7C1uoRDjUcwGoxMSZzEfHcRkxImarVdREQGRAFeZAzIcdt5/IGp1J5p5aPSCrbuq2XzHi/5E50UF3nIcWvl90Y43dbA1t7a9rOd54g3O1iSdSdzXbO12i4iItdNAV5kDElNsPKj4jy+c8t41u+s4tNdVez6sp4J6XaKizxMz0nCOAY71wymHn8P+04fZIu3hPIzX2LAwJSkScx3FXFTYq5W20VE5BtTDfwAqQZeRpP2zm4+K6thXWklDc3tpCVauavQw9zJqZgiR2bQDNdcaWg7E1ptb+48S7zZwc2u2cxNm028xTHk4xG5Fn2viPTPcKyBV4AfIAV4GY16/H62H6pjbUkFFafOYY+J4vZZ6SzKd2O1mMI9vAEZyrnS4+9hX0M5W6uDq+0AU5LymOcqYnJinlbbZVjT94pI/wzHAK8SGhEhwmhkzk2pFE1K4eDJRtaWVPDupuP81xcnWTjdxR2zMki0W8I9zGGjoa2Rz2tK+cJbiq/zLA6zncXjbuNmV6FW20VE5IZTgBeREIPBwORxCUwel0DFqbOsLa3gkx1VrN9ZReGkZIqLMslIvvKKwGjW4+9hf8Mhtni3Ud4QXG2fnJjL991zuCkhlwhjRJhHKCIiY4VKaAZIJTQy1jT42vl4RyWb9njp6OphSlYCi4s85GXGYxiGG14He66caW/kc28pn3u34+tsxh5l42ZXITe7ZpNgiR+09xEZavpeEemf4VhCowA/QArwMla1tHexcXc1H++oormlk8yUOIqLPMzKcxJhHD613oMxV3r8PRxoOMQWbwkHGw4DMClxIvNdc5iSmKfVdhkV9L0i0j8K8KOAAryMdV3dPXxx4BQfllRw6kwrSXYLd87O4JZpLsxR4Q+232SuNLY3BVfba7bT1OHDHhXHXFchN6cVkhit1XYZXfS9ItI/CvCjgAK8SJA/EGDvkdN8WFrB0SofMZZIvjUzndsK0rHFRIVtXAOdK/6AP7jaXl3CgYZDAExKmMh8dxFTEidptV1GLX2viPTPcAzw2sQqItfFaDCQP9FJ/kQnR6t8fFhykv/6/CvWllYwb0oqdxV6SEmwhnuYV9TY3sTnNdv53FtKU4cPW1Qcd2Uu4mZXIYnRCeEenoiIyBUpwIvIN5aTbuev06dR09DCR6WVbNlXy6Y9XmZOdFI8x0O2yx7uIQLB1faDDYfZ4i1h/+lyAPISJrB0wn1MTbpJq+0iIjIiKMCLyKBJS4zhocV53H9LFp/srOLTXdXs/LKeiel2iudkMi07EWMYOtc0dfj4wrudrd5SGjuaiIuK5Y7MW5nnKiJJq+0iIjLCqAZ+gFQDL9J/7Z3dfLa3hnXbK2ho7iAt0UpxoYc5k1MxRQ5u55rS2l2sObaWpo4mHGYH946/i9ioGLZUl7C/oRx/wE9e/ATmu+cwTavtIvpeEemn4VgDrwA/QArwIgPX3eNnx6E6PiypoLLuHPbYKO6YlcGtM1xYLaZvfP/S2l28cehduvxdlzwXZ4plrms2N6cV4rQmfuP3Ehkt9L0i0j8K8KOAArzI9QsEAhz8qpEPS05y8KtGLFERLJzh4o5ZGSTYLP26R4+/h7Nd5/B1NAf/19nMe0c/pL2n/ZJrY0wx/NO8p4k0qlpQ5Ov0vSLSP8MxwOtbTUSGjMFgYHJWApOzEjhZe5aPSiv4eHsVn+yoovCmZBbOTMIa14OvszkU0JtCv/bh62imufMcAfr3l+iWrhaFdxERGXXC+s3W2dnJb37zG1avXk1zczN5eXk8+eSTzJ07d0D3eeSRR9i8eTPLly/n6aefvuT5t99+m1dffZWqqipcLhfLly9n2bJlg/UxROQqAoEAbd3tfUL5+WBuyGomJ6WJunON7A60sOfQpcE81hSD3WzDbraRHusK/doeZQv9+vkdv6Oxo+mS18abHUPxEUVERIZUWAP8z3/+c9atW8fy5cvJzMxk1apVPPLII6xYsYL8/Px+3WPjxo3s2LHjis+/+eab/N3f/R3FxcX8+Mc/ZseOHTzzzDN0dHTwl3/5l4P1UUTGpI6ezj6r400Xh/SLft15mdr06EhLKITPSMsl2hjDqTo/Xx5vo/VcJC57IosLJlCYl0aE8eobXu/LLr6kBt5kNHFfdvGgf2YREZFwC1sNfFlZGUuXLuUXv/gFDz30EAAdHR0sWbKE5ORkXn/99Wveo7Ozk3vvvZd7772X3/72t5eswLe3t7Nw4UIKCgp4+eWXQ48/9dRTbNiwgU2bNhEXFzegcasGXsaCLn83zR1n8XU209Qbzr8eyn2dzbR1X1p3bjKacFy0Su4w2y+7am6OuPxprV3dPWzdX8tHpZWcOtNKkt3CXYUe5k9Nwxx15c4xX+9Cc192MYWpMwftv4nIaKPvFZH+UQ38RdauXYvJZGLp0qWhx8xmMw8++CAvvvgidXV1JCcnX/Uer732Gu3t7Tz88MP89re/veT5kpISmpqa+MEPftDn8WXLlvH++++zefNm7rnnnsH5QCIjwOU2gDZ1XLpqfq6r5ZLXRhgiQiE8NSaF3IQJOC4K5OdDuyXCguEb9Ho3RUZw6ww3C6a72HPkNB+WnOT1j79k9ZYTfGumm28VpGOzXhr+C1NnUpg6U6FERERGvbAF+PLycrKysoiJienz+LRp0wgEApSXl181wNfX1/Pyyy/zy1/+kujo6Mtec/DgQQCmTJnS5/HJkydjNBqtvQJwAAAgAElEQVQ5ePCgAryMCv6An5au1ktWyZs6fH1+vtwGUAMGbFFx2M02EizxZNkzvxbM7dijbFhN0RgNg9u7/WqMBgMzJzqZOdHJkaom1pZUsGbrV3xYUsH8qWncWZhBSrx1yMYjIiIyXIQtwNfX15OSknLJ406nE4C6urqrvv7Xv/41WVlZfPvb377qe0RFReFw9N3Idv6xa72HSLhdbQPo+drzpo5mmjvP0hPoueT119oA6jDbiYuKHdJgfj0mpDuYkO6gpqGFj0or+KzMy8bd1RTkOikuymS8y8YXB2pZuekYZ5o7SLCZeWBhNnMnp4Z76CIiIoMubAG+vb0dk+nSA1zMZjMQrIe/krKyMt577z1WrFhx1X+qv9J7nH+fq73HlVytHulGczoHVq8vw1t7dweNbT4a25o40+a78Ov24K/PtDXR2NZEZ8+lG0Ctpmjio+0kRDvISEgjIdpBvMUeeiw+2o7DYsMU8c0PSRpOnM44puWlcqa5nf/acpwPPv+KHYfrcTtjqDvTRlePH4CG5g5eW3sYW5yFWwsywjxqkeFL3ysi/TPc5krYArzFYqGr69Jgcj5Unw/yXxcIBPjHf/xH7rzzTmbNmnXN9+js7Lzscx0dHVd8j6vRJla5lgsbQH2XrS/v7wbQjBg3U+InDWgDKAABoBWaWtuBS99jtFg8O4Nbp6Xx2V4vb316lK9Py46uHv7vfx1gsketJEUuR98rIv2jTawXcTqdly1hqa+vB7hi/fvHH39MWVkZTz75JFVVVX2eO3fuHFVVVSQlJWGxWHA6nXR1ddHU1NSnjKazs5OmpqZrbpIVudjFG0CbrhDKB7QBtE8py+BsAB1ros2R3Fno4c0NRy/7fENzB2+uP0KO286EdDv22IH/pV1ERGS4CVuAz8vLY8WKFbS0tPTZyLp3797Q85fj9Xrx+/386Ec/uuS5lStXsnLlSn7/+9+zYMECJk2aBMD+/fuZP39+6Lr9+/fj9/tDz8vYdrkNoKHWide9AdR+IZhH2YgxWRXMb6BEm5mG5ktL4iIjDGzYVc267ZUAJDuiyUkPhvmcdAdpiVaM+v9FRERGmLAF+OLiYl599VXefvvtUB/4zs5OVq5cycyZM0MbXL1eL21tbWRnZwPwrW99i/T09Evu95Of/IRFixbx4IMPMnnyZADmzJmDw+HgjTfe6BPg//jHP2K1WlmwYMEN/pQSTlfeAOq7qEvL9W0APd/bfCRsAB0LHliYzX98eIjObn/osahIIz9anMes3GROnjrL0SofR6qaKDvWwOf7awGIsUSS47b3hnoHWWlxmCKv3GteRERkOAhbgJ8+fTrFxcU8//zz1NfX4/F4WLVqFV6vl2effTZ03c9+9jNKS0s5fPgwAB6PB4/Hc9l7ZmRkcPvtt4d+tlgsPPHEEzzzzDP89Kc/Zf78+ezYsYM1a9bw1FNPYbPZbuyHlBsmeAKo7zJdWXrLW3p/7rrsCaDRwdXxKBsT47MvqS93mG3YouKINIb1oGIZgPPdZq7UhSbHbSfHbae4yEMgEOBUYxtHqpo4UuXjaJWPvccagOCKfWZqXLDrjdtOdrr9sj3nRUREwimsCeW5557jpZdeYvXq1fh8PnJzc3nllVcoKCgYtPdYtmwZJpOJV199lfXr15OWlsbTTz/N8uXLB+09ZPAEN4Be+YCh84+191y6OTPKaAq1Rhxny+gTyvu9AVRGrLmTU5k7OfWam40MBgOpCVZSE6zcMs0FQHNrJ8eqfBypDq7Sf7y9krUlFQCkJliDK/RuOxMyHKTER6scSkREwsoQCASGvqXKCKYuNNdnsDaAnt/sadcGULmCwZgrXd09nKg5y5GqJo5W+Tha7aOlvRuAOKupd1Osg5x0O+NS44iMUBmVjDwj/XtFZKioC42MOhdvAP36qZ/XtwHU3qeURRtAJRxMkRFMzHAwMSPYvcofCFDT0MrR3kB/pMrH7iOne681kpUaR066o3dzrJ0Yy+jqvy8iIsOLArxc1uU2gH49oF/PBlCH2R5aOdcGUBkpjAYD7qQY3EkxLJzhBsB3roOj1cEwf6TKx0elFXywLfiXVFdSTDDM95bdOO361yERERk8CvBj0I3aAHq+lEUbQGUssMeaKchNpiA3eJ5ER1cPJ7zNoTr60vI6Nu3xBq+NiQp1upmQbicjOVZlNyIict2Usoa50tpdrDm2lqaOJhxmB/dlF1OYOvOy115tA+jFP19pA+j51ohX2gDqMNuI0gZQkcsymyLIy4wnLzMeCJbdeOtbgt1uqoPdbnYeDh5UF2UyMj7NFiq7yXbZsVr0x7GIiPSPNrEO0FBuYi2t3cUbh97tsxIeaYhgVko+Dov9ktKWlq7WS+6hDaAy1gznjXmNZztCG2OPVPmoqDtLIAAGwO2MZULokCk7iTbNSbmxhvNcERlOhuMmVgX4ARrKAP//bv0nGjuaLvvcxRtAv15brg2gMpaNpFDS3tnNcW9zbz/6Jo56m+noDO4piY8zX6ijT3eQnhxDhFFlNzJ4RtJcEQmn4Rjg9W+2w9iVwjvAvy56VhtARUY4S1QkN41L4KZxCQD0+P1U1bX0bo4NHjRVWl4HgDkqgmyXLdS+cnyajWiz/ggXERmL9Kf/MBZvdlw2xMebHQrvIqNQhNFIZmocmalx3FaQDkCDr71PHf2aLScIAAYDeJLjejfHBlfp4+PM4f0AIiIyJBTgh7H7sosvqYE3GU3cl10cxlGJyFBKtFtItKcyZ3IqAK3t3Rz3nm9f2cRnZV7W76wKXmuzXFRH78CdFIPRqBI6EZHRRgF+GDvfbaa/XWhEZPSzWiKZMj6RKeMTAeju8VNZdy5UR19+spFtB08BEG2OJNttY0JvHX2Wy4bZFBHO4YuIyCDQJtYBGspNrBfTZiOR/hnrcyUQCFDva+dobw390Sof1adbAIgwGvCkxAbr6N3BlXp7rMpuxqqxPldE+kubWEVE5IYyGAwkO6JJdkRz85Q0AM61dXGs2hc6OfbT3dWs214JQLIjmpze1pUT0h2kJVoxqnOViMiwpgAvIjLKxUabmJ6TxPScJCBYdnOy9myojn7f8QY+318LQIwlkmz3hY2xWWlxmCJVdiMiMpwowIuIjDGREUay3Xay3XaKizwEAgHqGtv4sveQqaPVPsqONQDBsptxaXFMcPeeGptux2bVicwiIuGkAC8iMsYZDAZSEqykJFi5ZZoLgLOtnaGSm6NVPj7ZWcna0goAUhKswRV6d7D0JjVBB8aJiAwlBXgREblEnDWK/AlO8ic4Aejq7uFEzVmO9vaj3/1lPVvKanqvNZHjvlBHn5kShylSZ1WIiNwoCvAiInJNpsgIJmY4mJjhAMAfCFDb0Bpcpa8MHjS1+8hpIFiiMz4tjpzeU2Nz3HZio03hHL6IyKiiAC8iIgNmNBhwJcXgSophwfRg2Y2vpTPUvvJIlY+PSiv4YFuw7a4rKSbUunJCuh2nI1plNyIi10kBXkREBoU9JoqC3GQKcpMB6Ojq4auaZr7sraPffqiOzXu9ANhiokJ19BMyHGQkxxIZobIbEZH+UIAXEZEbwmyKINcTT64nHgiW3XjrWzhS7Qut1O88XA9AlMnI+DQbOem93W5cdqwWfUWJiFyO/nQUEZEhYTQYSE+OJT05lkX5bgAaz3b0qaP/4IuT+AMBDIDbGcuE0CFTdhJtFpXdiIigAC8iImEUH2dmdl4ys/OCZTftnd0c9zZztPeQqS8O1PLp7urQtTkXHTKVnhxDhFFlNyIy9ijAi4jIsGGJiuSmcQncNC4BAL8/QFX9udCpsUd6a+kBzFERZLtsvaHewXiXjWizvtZEZPTTn3QiIjJsGY0GPClxeFLiuK0gHYAGXztHqpt6V+l9vL/1KwKAwQAZybFM6K2jz3HbSbBZwvsBRERuAAV4EREZURLtFhLtqcy5KRWA1vZujnt7T42t9vFZmZf1O6uC19osF9XRO3AnxWA0qo5eREa2sAb4zs5OfvOb37B69Wqam5vJy8vjySefZO7cuVd93Zo1a3jnnXc4duwYPp+P5ORkioqKePzxx3G73X2uzc3Nvew9/v7v/57vf//7g/ZZREQkPKyWSKaMT2TK+EQAunv8VNadC67QV/sor2hk28FTAESbI8h22XtDvYPxaTbMURHhHL6IyICFNcD//Oc/Z926dSxfvpzMzExWrVrFI488wooVK8jPz7/i6w4dOkRKSgoLFy7Ebrfj9Xp566232LhxI2vWrMHpdPa5fv78+dx33319Hps+ffoN+UwiIhJekRFGstJsZKXZuGN2BoFAgNO+do5UNYVC/arPTgAQYTTgSYklx+0IHTJljzWH+ROIiFydIRAIBMLxxmVlZSxdupRf/OIXPPTQQwB0dHSwZMkSkpOTef311wd0vwMHDvDAAw/wt3/7tzz88MOhx3Nzc1m+fDlPP/30oIy7oeEcfv/Q/ydzOuOorz875O8rMtJorkh/tLR3cazaFzo19kRNM13dfgCcDgsT0h3Bshu3nbSkGIyjsH2l5opI/4RjrhiNBhITY6/4fNhW4NeuXYvJZGLp0qWhx8xmMw8++CAvvvgidXV1JCcn9/t+LlfwKO/m5ubLPt/e3o7BYMBs1sqKiMhYF2MxMS07iWnZSUCw7ObkqbMcqQzW0e873sDn+2t7r40k+6L2leNS44gyqexGRMInbAG+vLycrKwsYmJi+jw+bdo0AoEA5eXl1wzwTU1N9PT04PV6+d3vfgdw2fr5d955hxUrVhAIBJg4cSJPPPEEd9xxx+B9GBERGdEiI4xku4InwAIEAgHqGttC7SuPVvsoO9YABMtuxqXGhVbpc9Lt2KxR4Ry+iIwxYQvw9fX1pKSkXPL4+fr1urq6a97jrrvuoqmpCQCHw8Evf/lL5syZ0+ea/Px87r77btLT06mpqeG1117j8ccf54UXXmDJkiWD8ElERGS0MRgMpCRYSUmwMn9aGgBnWzs5Wu0L1dF/srOStaUVAKQkWJngtoc63qQmWHVqrIjcMGEL8O3t7ZhMpkseP1/i0tHRcc17/Nu//Rutra2cOHGCNWvW0NLScsk1b775Zp+f77//fpYsWcKvfvUr7rnnngH/AXu1eqQbzemMC9t7i4wkmityIziB8ZmJ3Nn7c2dXD0ermig/cYaDJ86w91gDW/bVAGCLiWLSuARuykpg0rhEcjLsmCKHX9mN5opI/wy3uRK2AG+xWOjq6rrk8fPBvT+16rNnzwZg4cKF3Hbbbdx7771YrVZ++MMfXvE1VquV733ve7zwwgscP36c7OzsAY1bm1hFhjfNFRlKztgonFNTWTA1lUAgQO2Z1gtlN1U+Sg4E6+iDnXHiQv3oc9x2YqMvXcQa0rFrroj0izaxXsTpdF62TKa+vh5gQBtYATIyMpg8eTLvv//+VQM8QFpa8J9DfT7fgN5DRETkSgwGA2mJMaQlxrBgerCxgq+ls/fE2GAd/brSSj7cFiy7cSXFkBPaHGvH6YhW2Y2I9EvYAnxeXh4rVqygpaWlz0bWvXv3hp4fqPb2dtra2q55XWVlJQAJCQkDfg8REZH+ssdEUZDrpCA3uL+ro6uHr2qaQ6fGbj9Ux+a9XiBYdnOhjt6BJyWWyAhjOIcvIsNU2AJ8cXExr776Km+//XaoD3xnZycrV65k5syZoQ2uXq+Xtra2PqUuZ86cuSR879+/n0OHDnH33Xdf9brGxkbeeOMN0tPTGTdu3I35cCIiIpdhNkWQ64kn1xMPgD8QwHu6JbRKf6TKx84vg/8SHRVpZLzLFiq7yXbZsVrCev6iiAwTYfuTYPr06RQXF/P8889TX1+Px+Nh1apVeL1enn322dB1P/vZzygtLeXw4cOhxxYtWsTixYuZOHEiVquVo0eP8u677xITE8Njjz0Wuu71119n/fr13HrrrbhcLk6dOsWf/vQnzpw5E2o7KSIiEi5Gg4F0ZyzpzlhuzXcD0Hi2g6PVF+roP/iiAn/gJAbA7Yzpc8hUot2ishuRMSisf5V/7rnneOmll1i9ejU+n4/c3FxeeeUVCgoKrvq6H/zgB3zxxRd88skntLe343Q6KS4u5rHHHiMjIyN0XX5+Prt27eLtt9/G5/NhtVqZMWMGjz766DXfQ0REJBzi48zMzktmdl5wL1h7ZzcnvMGymyPVPr44UMunu6tD1+a4g60rJ6Y7SE+OIcKoshuR0c4QCASGvqXKCKYuNCLDm+aKjHZ+f4Cq+nOhOvojVU2cae7t4GaKYLzLFjo1drzLRrS571rdFwdqWbnpGGeaO0iwmXlgYTZzJ6eG46OIjAjqQiMiIiLfiNFowJMShycljtsK0gE409zep33l+59/RSAABgNkJMcywR0su2lu7eTdjcfo7PYD0NDcwX98eAhAIV5kBNEK/ABpBV5keNNcEYG2jm6OeXtPja3ycdzbTEdXzxWvT7SZ+dVj84ZwhCIjh1bgRURE5IaLNkcyJSuRKVmJAPT4/VTWneOZ/7vjstc3NHewdV8NkzLjSbBZhnKoInIdFOBFRERGuQijkXGpNhJtZhp66+UvZjDAH/5cDkBKfDSTMuPJy4wnzxOPLSZqqIcrItegAC8iIjJGPLAwm//48FCoBh6C/eaXF+eS7ozl0MlGyk82su3gKTbuCR4wle6MIS8znkmZ8eRmOLBaTOEavoj0UoAXEREZI85vVL1SFxpPShx3Fnro8fv5qvZsKNBv2uPlkx1VGAwwLjUuFOgnuB2YoyLC+ZFExiRtYh0gbWIVGd40V0T6ZyBzpavbz3Gvj/LeQH/c20yPP0CE0UC2yxYK9ONddkyR6kMvo8tw3MSqAD9ACvAiw5vmikj/fJO50tHZw5GqJspPNnKoopGvas8SCATLcSak23sDfQKZqbE6WEpGvOEY4FVCIyIiIgNijopgyvhEpowPdrlpbe/icGVvoD/ZyLubjgPHiTZHkJsRH1qhdztjMBoM4R28yCigAC8iIiLfiNViIn+Ck/wJTgCaWzo5VNEYqqHfc/Q0ALHRplCYn5QZT0p8NAYFepEBU4AXERGRQWWLiaJwUgqFk1KA4Emx51fnD55sZMehOgDi48zkeS4E+kS7etCL9IcCvIiIiNxQCTYL86amMW9qGoFAgLqmtlCg33+igS8O1AKQ7IgOrdDnZcZjVw96kctSgBcREZEhYzAYSIm3khJv5dYZbgKBANWnW0KBfvuhOjbvDfagdydd1IPe4yBGPehFAAV4ERERCSODwUC6M5Z0Zyx3zMrA7w9w8tSFHvSflXlZv7MKA+BJjQuV20xIt2OJUoyRsUm/80VERGTYMBoNZKXZyEqzsXhOJt09fo57m0OB/pMdlawtqSDCaCDLZWNSbw19ttuGKVKHSsnYoD7wA6Q+8CLDm+aKSP+M1LnS0dXD0WpfKNCfqGkmEABTpJEctz20Qj8uLU496GVQqA+8iIiIyDdgNkUweVwCk8clANDa3s2XVU2hQL9y83EALFERTMxwhAJ9enKsetDLqKEALyIiIiOW1RLJjJwkZuQkAXC2tZPDFcFDpcpPNlJ2rAGAGEtknx70qQlW9aCXEUsBXkREREaNOGsUs/KSmZWXDEDj2Y7Q6nz5yTPsPFwPgD02Khjme2vokxzR4Ry2yIAowIuIiMioFR9nZu6UVOZOSSUQCFDvaw8F+oNfNbLtwCkAkuyW0Op8XmY8jlhzmEcucmUK8CIiIjImGAwGkh3RJDuiWTDdRSAQwNvQGgr0u76s57OyGgDSEq2hQJ/riSc2Wj3oZfhQgBcREZExyWAw4E6KwZ0Uw20F6fj9ASrrzoXq57fuq2XDrmoMQEZybKiGfmKGg2izIpSEj373iYiIiBBs3ZeZGkdmahzFRR66e/x8VXOW8pNnKD/ZyIZd1azbXonRYCArLS4U6HPcdqJM6kEvQ0d94AdIfeBFhjfNFZH+0VwZuK7uHo5WN1N+spFDJxs57m3GHwgQGWEgx20PBfqsNBuREepBP1qoD7yIiIjICGWKjAjVxQO0dXRzpOrCoVKrPzvBe5+dwGyKYELGhUOlPMlxGI1qWSmDJ6wBvrOzk9/85jesXr2a5uZm8vLyePLJJ5k7d+5VX7dmzRreeecdjh07hs/nIzk5maKiIh5//HHcbvcl17/99tu8+uqrVFVV4XK5WL58OcuWLbtRH0tERETGgGhzJNOyE5mWnQjAubYuDlf0HipV0cjbnx4DwGqOJNdz4VApV1KMetDLNxLWAP/zn/+cdevWsXz5cjIzM1m1ahWPPPIIK1asID8//4qvO3ToECkpKSxcuBC73Y7X6+Wtt95i48aNrFmzBqfTGbr2zTff5O/+7u8oLi7mxz/+MTt27OCZZ56ho6ODv/zLvxyKjykiIiJjQGy0iYJcJwW5wRzSdK6DQxWNoRX63UdOA2CLiSLvokDvdEQr0MuAhK0GvqysjKVLl/KLX/yChx56CICOjg6WLFlCcnIyr7/++oDud+DAAR544AH+9m//locffhiA9vZ2Fi5cSEFBAS+//HLo2qeeeooNGzawadMm4uLiBvQ+qoEXGd40V0T6R3Nl6J1uaqO8N9AfPNmI71wnAIk2c6h+Ps8TT4LNEuaRysVUA3+RtWvXYjKZWLp0aegxs9nMgw8+yIsvvkhdXR3Jycn9vp/L5QKgubk59FhJSQlNTU384Ac/6HPtsmXLeP/999m8eTP33HPPN/wkIiIiIteW5IjmFkc0t0wL9qCvPXOhB/3eow1s3VcLQErCxT3oHdisUWEeuQw3YQvw5eXlZGVlERMT0+fxadOmEQgEKC8vv2aAb2pqoqenB6/Xy+9+9zuAPvXzBw8eBGDKlCl9Xjd58mSMRiMHDx5UgBcREZEhZzAYSEuMIS0xhkUz0/EHAlTVnQsF+m0Hatm4uxqAdGdsKNBPzHBgtagHyVgXtt8B9fX1pKSkXPL4+fr1urq6a97jrrvuoqmpCQCHw8Evf/lL5syZ0+c9oqKicDgcfV53/rH+vIeIiIjIjWY0GPCkxOFJiePOQg89fj9f1Z4NBfqNe6r5eEclBgOMS7WFAn1Ouh2zetCPOWEL8O3t7ZhMlx5LbDabgWA9/LX827/9G62trZw4cYI1a9bQ0tLSr/c4/z79eY+vu1o90o3mdA6sXl9krNJcEekfzZXhLTXFzpzp6UCwB/2hk42UHTlN2dF6Piqt4INtJ4mMMJCbmcD0nCSmTXAy0ROPKVI96AfbcJsrYQvwFouFrq6uSx4/H6rPB/mrmT17NgALFy7ktttu495778VqtfLDH/4w9B6dnZ2XfW1HR0e/3uPrtIlVZHjTXBHpH82VkSfVZia1wM2dBW7aO7s5WuWjvHeF/o/rDvPGusNEmYxMSL/Q4SYzRT3ovyltYr2I0+m8bAlLfX09wIA2sAJkZGQwefJk3n///VCAdzqddHV10dTU1KeMprOzk6ampgG/h4iIiMhwYImKZMr4RKaMD/agb2nv4suKpmCgr2jknY3BHvTR5khyMy7qQe+MwaiWlSNe2AJ8Xl4eK1asoKWlpc9G1r1794aeH6j29nba2tpCP0+aNAmA/fv3M3/+/NDj+/fvx+/3h54XERERGcliLCbyJzrJnxjcS+hr6eRwRWNohX7P0WAP+jiriTxPfCjQJ8erB/1IFLYAX1xczKuvvsrbb78d6gPf2dnJypUrmTlzZmiDq9frpa2tjezs7NBrz5w5Q0JCQp/77d+/n0OHDnH33XeHHpszZw4Oh4M33nijT4D/4x//iNVqZcGCBTfwE4qIiIiEhz0misJJKRROCuapBl87hy4K9NsPBasg4uPMoTCf54kn0a4e9CNB2AL89OnTKS4u5vnnn6e+vh6Px8OqVavwer08++yzoet+9rOfUVpayuHDh0OPLVq0iMWLFzNx4kSsVitHjx7l3XffJSYmhsceeyx0ncVi4YknnuCZZ57hpz/9KfPnz2fHjh2sWbOGp556CpvNNqSfWURERCQcEu0W5k1NY97UNAKBAHWNbaEwv+94A5/vD/agT46PvqgHfTz2GPWgH47C2kj0ueee46WXXmL16tX4fD5yc3N55ZVXKCgouOrrfvCDH/DFF1/wySef0N7ejtPppLi4mMcee4yMjIw+1y5btgyTycSrr77K+vXrSUtL4+mnn2b58uU38qOJiIiIDEsGg4GUBCspCVZuzXfjDwTw1reEAn1p+Sk27fEC4HbGMMlz4VApq+Xy3f1kaBkCgcDQt1QZwdSFRmR401wR6R/NFbmSHr+filPnQoH+SGUTnd1+DAbITIkLrdBPSHdgjhr9PejVhUZEREREhrUIo5GsNBtZaTbunpNJd4+f497mUKBft72SD0sqiDAaGO+yhTbFZrttmCJHf6AfDrQCP0BagRcZ3jRXRPpHc0WuV0dXD0erfKFNsSdqmgkEwBRpJMdtD63Qj0uLI8I48g+V0gq8iIiIiIxoZlMEk7MSmJwV7AjY2t7Nl1VNHOpdoV+5+TgAlqgIJl7Ugz49OVY96AeJAryIiIiIXDerJZIZOUnMyEkCoLm188KhUicbKTvWAEBstIlcz4VAn5pgVQ/666QALyIiIiKDxmaNYlZeMrPygifeN57tCK3Ol588w87D9QDYY6OCYb63hj7JER3OYY8oCvAiIiIicsPEx5mZOyWVuVNSCQQC1PvaQ4H+4FeNbDtwCoAku+XCoVKZ8ThizWEe+fClAC8iIiIiQ8JgMJDsiCbZEc2C6S4CgQDehtZQoN95uJ7PymoASEu09jlUKjZaPejPU4AXERERkbAwGAy4k2JwJ8VwW0E6fn+AyroLPei37qtlw65qDEBGSmyfHvTR5rEbY8fuJxcRERGRYcVoNJCZGkdmahzFRR66e/x8VXOW8pNnKD/ZyPqd1XxUWonRYCDLFReqoc9224kyjZ0e9OoDP0DqAy8yvGmuiPSP5oqMRPYqgawAAAvbSURBVJ1dPRyr9lF+vge99yz+QIDICCM5blvvCn0C49LiiIwYnB706gMvIiIiInKdokwRTBqXwKRxwR70bR3dHKm60LLyvc9OsOqzE5hNfXvQZyTHYjSOnpaVCvAiIiIiMiJFmyOZlp3EtOxgD/pzbV0crmgMBfq3Pg32oI+xRJLrudDhxpU4snvQK8CLiIiIyKgQG22iIDeZgtxgD/qmcxf3oG9k15fBHvS2mKg+LSuddsslgf6LA7Ws3HSMM80dJNjMPLAwm7mTU4f8M12OAryIiIiIjEqOWDNzJqcypzd41ze1BQN97yp9ycFgD/pEW98e9IcqGvmPDw/R2e0HoKG5g//48BDAsAjxCvAiIiIiMiY4HdE4HdHc0tuDvvZMa2h1fveRerbsC/agNxoNlzQt6ez2s3LTMQV4EREREZFwMBgMpCXGkJYYw7dmpuMPBKjq7UH/pw1HL/uahuaOIR7l5Q1Ofx0RERERkRHMaDDgSYnjrkIPiTbzZa+50uNDTQFeREREROQiDyzMJiqyb0yOijTywMLsMI2oL5XQiIiIiIhc5Hydu7rQiIiIiIiMEHMnpzJ3cuqwPLVYJTQiIiIiIiOIAryIiIiIyAiiAC8iIiIiMoIowIuIiIiIjCAK8CIiIiIiI4gCvIiIiIjICKIALyIiIiIygijAi4iIiIiMIArwIiIiIiIjiE5iHSCj0TAm31tkJNFcEekfzRWR/hnquXKt9zMEAoHAEI1FRERERES+IZXQiIiIiIiMIArwIiIiIiIjiAK8iIiIiMgIogAvIiIiIjKCKMCLiIiIiIwgCvAiIiIiIiOIAryIiIiIyAiiAC8iIiIiMoIowIuIiIiIjCAK8CIiIiIiI0hkuAcgl1dXV8drr73G3r172b9/P62trbz22msUFRWFe2giw0pZWRmrVq2ipKTk/2/v7mKauv84jn8A8RkfwJosijjd0k4hgsYpEo0KJsaHQLItbEJd1DEVNEGjydR4oduiiWh0TB0DEzVZ5gWa1fViPgwSp01mok6NSAyISoMPCCIgiAzP/2JZJ5bt742ec+D9uju/8y39lAT64fBrq5qaGg0ZMkQJCQnKzc1VTEyM2fEAy7h69aq+++47lZWVqa6uThEREXK5XMrJydHEiRPNjgdYVmFhofLy8uRyueTxeMyOI4kCb1lVVVUqLCxUTEyMnE6nLl26ZHYkwJKKiop08eJFzZ07V06nU7W1tfrhhx+Ulpam4uJijR071uyIgCVUV1ero6NDH330kRwOh5qamvTzzz8rMzNThYWFSkpKMjsiYDm1tbXav3+/+vfvb3aUTkIMwzDMDoFgzc3Nam9v19ChQ3X69Gnl5ORwBR7owsWLFxUbG6vevXsH1m7duqWFCxdq/vz52r59u4npAGtrbW1VSkqKYmNjVVBQYHYcwHK++OIL1dTUyDAMNTY2WuYKPHvgLWrgwIEaOnSo2TEAy5s4cWKn8i5Jo0eP1rvvvqvKykqTUgH20K9fP0VGRqqxsdHsKIDlXLlyRcePH9eGDRvMjhKEAg+g2zEMQw8fPuSPYKALzc3Nqq+v182bN7Vr1y7duHFDiYmJZscCLMUwDH355ZdKS0vTe++9Z3acIOyBB9DtHD9+XPfv39eaNWvMjgJYzsaNG3XixAlJUnh4uD7++GOtWLHC5FSAtfz000+qqKjQ3r17zY7SJQo8gG6lsrJSW7du1aRJk5Sammp2HMBycnJylJ6ernv37snj8ejZs2dqb28P2ooG9FTNzc3auXOnPv/8cw0fPtzsOF1iCw2AbqO2tlbLly/X4MGDtWfPHoWG8isOeJnT6VRSUpI++OADHThwQNeuXbPkHl/ALPv371d4eLiWLFlidpR/xbMbgG6hqalJWVlZampqUlFRkRwOh9mRAMsLDw9XcnKyTp48qadPn5odBzDdgwcPdOjQIS1atEgPHz6U3++X3+9XW1ub2tvb5ff79fjxY7NjsoUGgP21tbVpxYoVunXrlg4ePKgxY8aYHQmwjadPn8owDD158kR9+/Y1Ow5gqrq6OrW3tysvL095eXlB55OTk5WVlaV169aZkO4fFHgAttbR0aHc3Fz98ccf2rdvn+Lj482OBFhSfX29IiMjO601NzfrxIkTeuuttxQVFWVSMsA6Ro4c2eULV3fv3q2WlhZt3LhRo0ePfvPBXkKBt7B9+/ZJUuC9rD0ejy5cuKBBgwYpMzPTzGiAZWzfvl0lJSWaNWuWGhoaOn3IxoABA5SSkmJiOsA6cnNz1adPHyUkJMjhcOju3bs6duyY7t27p127dpkdD7CEiIiILp83Dh06pLCwMMs8p/BJrBbmdDq7XB8xYoRKSkrecBrAmtxut86fP9/lOX5WgH8UFxfL4/GooqJCjY2NioiIUHx8vJYuXar333/f7HiApbndbkt9EisFHgAAALAR3oUGAAAAsBEKPAAAAGAjFHgAAADARijwAAAAgI1Q4AEAAAAbocADAAAANkKBBwAAAGyEAg8AsDy3263Zs2ebHQMALKGX2QEAAOb4/ffftXjx4n89HxYWprKysjeYCADwKijwANDDLViwQDNmzAhaDw3ln7QAYEUUeADo4caNG6fU1FSzYwAAXhGXVwAA/8nv98vpdCo/P19er1cLFy5UXFycZs6cqfz8fP35559BtykvL1dOTo6mTJmiuLg4zZs3T4WFhero6Aiara2t1VdffaXk5GTFxsYqMTFRS5Ys0blz54Jm79+/r7Vr12ry5MmaMGGCli1bpqqqqtfyuAHAqrgCDwA9XGtrq+rr64PWe/furYEDBwaOS0pKVF1drYyMDA0bNkwlJSX69ttvVVNTo23btgXmrl69KrfbrV69egVmS0tLlZeXp/Lycu3cuTMw6/f79cknn6iurk6pqamKjY1Va2urLl++LJ/Pp6SkpMBsS0uLMjMzNWHCBK1Zs0Z+v1+HDx9Wdna2vF6vwsLCXtN3CACshQIPAD1cfn6+8vPzg9ZnzpypgoKCwHF5ebmKi4s1fvx4SVJmZqZWrVqlY8eOKT09XfHx8ZKkr7/+Ws+ePdORI0fkcrkCs7m5ufJ6vfrwww+VmJgoSdqyZYsePHigoqIiTZ8+vdP9P3/+vNPxo0ePtGzZMmVlZQXWIiMjtWPHDvl8vqDbA0B3RYEHgB4uPT1dc+fODVqPjIzsdDxt2rRAeZekkJAQffbZZzp9+rROnTql+Ph41dXV6dKlS5ozZ06gvP89u3LlSv3yyy86deqUEhMT1dDQoN9++03Tp0/vsny//CLa0NDQoHfNmTp1qiTp9u3bFHgAPQYFHgB6uJiYGE2bNu3/zo0dOzZo7Z133pEkVVdXS/prS8yL6y8aM2aMQkNDA7N37tyRYRgaN27cK+UcPny4+vTp02ltyJAhkqSGhoZX+hoA0B3wIlYAgC381x53wzDeYBIAMBcFHgDwSiorK4PWKioqJEnR0dGSpJEjR3Zaf9HNmzf1/PnzwOyoUaMUEhKi69evv67IANAtUeABAK/E5/Pp2rVrgWPDMFRUVCRJSklJkSRFRUUpISFBpaWlunHjRqfZ77//XpI0Z84cSX9tf5kxY4bOnDkjn88XdH9cVQeArrEHHgB6uLKyMnk8ni7P/V3MJcnlcunTTz9VRkaGHA6Hfv31V/l8PqWmpiohISEwt2nTJrndbmVkZGjRokVyOBwqLS3V2bNntWDBgsA70EjS5s2bVVZWpqysLKWlpWn8+PFqa2vT5cuXNWLECK1fv/71PXAAsCkKPAD0cF6vV16vt8tzJ0+eDOw9nz17tt5++20VFBSoqqpKUVFRys7OVnZ2dqfbxMXF6ciRI/rmm2/0448/qqWlRdHR0Vq3bp2WLl3aaTY6OlpHjx7V3r17debMGXk8Hg0aNEgul0vp6emv5wEDgM2FGPyPEgDwH/x+v5KTk7Vq1SqtXr3a7DgA0OOxBx4AAACwEQo8AAAAYCMUeAAAAMBG2AMPAAAA2AhX4AEAAAAbocADAAAANkKBBwAAAGyEAg8AAADYCAUeAAAAsBEKPAAAAGAj/wPrFGdPg1CU5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZ4Tx8PNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f0cd1c41-1f54-4c12-bd74-c2abc5718b2b"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:04:19</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:04:19</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:04:18</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:04:17</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.52         0.38           0.84       0:04:19         0:00:12\n",
              "2               0.40         0.41           0.85       0:04:19         0:00:12\n",
              "3               0.34         0.51           0.87       0:04:18         0:00:12\n",
              "4               0.27         0.65           0.86       0:04:17         0:00:12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrRQFllONxsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0d0a9c-e42e-4fe1-f8c1-94333b3ea570"
      },
      "source": [
        "evaluation(y_val_fake, y_pred_val_fake)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine Grained Accuracy = 0.8548812664907651\n",
            "\n",
            "\n",
            "Fine Grained Metrics\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88       225\n",
            "           1       0.82      0.83      0.82       154\n",
            "\n",
            "    accuracy                           0.85       379\n",
            "   macro avg       0.85      0.85      0.85       379\n",
            "weighted avg       0.86      0.85      0.86       379\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHgr-fodo8e"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_val_fake, index = val_data.index, columns=['fake'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_val_fake.csv')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HWdCRDNxs0"
      },
      "source": [
        "**Training for Fake Class (Using Train +Val Data and Test Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwvcdNspi294"
      },
      "source": [
        "train_val_labels_fake = y_train_val_fake"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-RaRs7Nxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753e1856-6311-4623-8e7a-fe0945c4dd74"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_val_sentences)\n",
        "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_fake)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wfwVeBNxs0"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_val_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmjATAqNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d3daf2-a7c4-4466-d367-4325213115f6"
      },
      "source": [
        "training_stats, y_pred_test_fake = train_fn_test(train_val_dataloader, test_dataloader)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    382.    Elapsed: 0:01:01.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:32.\n",
            "  Batch   160  of    382.    Elapsed: 0:02:03.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:33.\n",
            "  Batch   240  of    382.    Elapsed: 0:03:04.\n",
            "  Batch   280  of    382.    Elapsed: 0:03:34.\n",
            "  Batch   320  of    382.    Elapsed: 0:04:05.\n",
            "  Batch   360  of    382.    Elapsed: 0:04:36.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:04:53\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:24\n",
            "[{'epoch': 1, 'Training Loss': 0.30044190840233675, 'Training Time': '0:04:53', 'Validation Time': '0:00:24'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    382.    Elapsed: 0:01:01.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:32.\n",
            "  Batch   160  of    382.    Elapsed: 0:02:03.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:33.\n",
            "  Batch   240  of    382.    Elapsed: 0:03:04.\n",
            "  Batch   280  of    382.    Elapsed: 0:03:35.\n",
            "  Batch   320  of    382.    Elapsed: 0:04:05.\n",
            "  Batch   360  of    382.    Elapsed: 0:04:36.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:04:53\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:24\n",
            "[{'epoch': 1, 'Training Loss': 0.30044190840233675, 'Training Time': '0:04:53', 'Validation Time': '0:00:24'}, {'epoch': 2, 'Training Loss': 0.2750048205358249, 'Training Time': '0:04:53', 'Validation Time': '0:00:24'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:31.\n",
            "  Batch    80  of    382.    Elapsed: 0:01:01.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:32.\n",
            "  Batch   160  of    382.    Elapsed: 0:02:02.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:33.\n",
            "  Batch   240  of    382.    Elapsed: 0:03:03.\n",
            "  Batch   280  of    382.    Elapsed: 0:03:34.\n",
            "  Batch   320  of    382.    Elapsed: 0:04:05.\n",
            "  Batch   360  of    382.    Elapsed: 0:04:35.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:04:52\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:24\n",
            "[{'epoch': 1, 'Training Loss': 0.30044190840233675, 'Training Time': '0:04:53', 'Validation Time': '0:00:24'}, {'epoch': 2, 'Training Loss': 0.2750048205358249, 'Training Time': '0:04:53', 'Validation Time': '0:00:24'}, {'epoch': 3, 'Training Loss': 0.1666237228880368, 'Training Time': '0:04:52', 'Validation Time': '0:00:24'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:30.\n",
            "  Batch    80  of    382.    Elapsed: 0:01:01.\n",
            "  Batch   120  of    382.    Elapsed: 0:01:31.\n",
            "  Batch   160  of    382.    Elapsed: 0:02:02.\n",
            "  Batch   200  of    382.    Elapsed: 0:02:32.\n",
            "  Batch   240  of    382.    Elapsed: 0:03:03.\n",
            "  Batch   280  of    382.    Elapsed: 0:03:33.\n",
            "  Batch   320  of    382.    Elapsed: 0:04:04.\n",
            "  Batch   360  of    382.    Elapsed: 0:04:34.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:04:51\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:24\n",
            "[{'epoch': 1, 'Training Loss': 0.30044190840233675, 'Training Time': '0:04:53', 'Validation Time': '0:00:24'}, {'epoch': 2, 'Training Loss': 0.2750048205358249, 'Training Time': '0:04:53', 'Validation Time': '0:00:24'}, {'epoch': 3, 'Training Loss': 0.1666237228880368, 'Training Time': '0:04:52', 'Validation Time': '0:00:24'}, {'epoch': 4, 'Training Loss': 0.120117291642267, 'Training Time': '0:04:51', 'Validation Time': '0:00:24'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlAyssNRJ2S"
      },
      "source": [
        "**Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhWwhMUNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "3a5f643f-c5c4-4759-87d2-26b54540803d"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-91155c2a8903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_stats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-6f844b95e724>\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(df_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Plot the learning curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valid. Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Label the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54illM8xNxs0"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnTc0kEYthUm"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_test_fake, index = test_data.index, columns=['fake'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_test_fake.csv')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jaHtVsc8Bww"
      },
      "source": [
        "torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, 'fake_test.tar')"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}