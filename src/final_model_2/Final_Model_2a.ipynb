{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model_2a.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyjuPoOPjJq"
      },
      "source": [
        "**Model Specifications**\n",
        "Detect Non Hostile Using verloop Bert -> Detect Fake Using verloop Bert ->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWMvHep3B7C"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOS1Mp42yMw",
        "outputId": "1f207dcd-e35c-4cc4-d528-ca16e02715ac"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBBc1EW3F4v"
      },
      "source": [
        "**Required Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPNhzGe3A_-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import ast\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ958U2_3YnT"
      },
      "source": [
        "**Reading Data and Rearranging into DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJalNxA3Xqj"
      },
      "source": [
        "train_file = 'train.csv'\n",
        "val_file = 'val.csv'\n",
        "test_file = 'test.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDH9cHl3fjU"
      },
      "source": [
        "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
        "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
        "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
        "train_val_data = train_data.append(val_data, ignore_index=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-Yczph4Chg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "0782333b-5042-4bcf-f9ca-b8d16cc7445d"
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5727, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üôè', 'üôè']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/8iy2MJSBAs']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
              "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡§Æ‡§æ‡§à ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§®‡§à-‡§®‡§à ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡•á‡§Ç ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/G945HvzM0Z', 'https://t.co/KfH7...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['LIVE']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
              "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§•‡•Ä, ‡§°‡•Ä‡§≤ ‡§¶‡•Ä‡§™‡•á‡§∂ ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§π...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/4e6lysg0VR']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['unlock4guidelines']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä\\n\\n- 7 ‡§∏‡§ø‡§§‡§Ç‡§¨...</td>\n",
              "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä - 7 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§¶‡•á‡§∂‡§≠‡§∞ ‡§Æ‡•á‡§ü...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ... Unnamed: 13\n",
              "Unique ID                                                     ...            \n",
              "1          ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
              "2          ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...  ...         NaN\n",
              "3          ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...  ...         NaN\n",
              "4          @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
              "5          #unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSxggvRQ4EGE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "a0a6d920-34e3-4b42-a289-60a5ab61040a"
      },
      "source": [
        "print(val_data.shape)\n",
        "val_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(811, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§∏‡•á ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•á...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§∏‡•á ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•á...</td>\n",
              "      <td>‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§¶‡•á‡§∂‡§π‡§ø‡§§ ‡§∏‡§∞‡•ç‡§µ‡•ã...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
              "      <td>defamation</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...</td>\n",
              "      <td>‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•á‡§Ç 10 ‡§π‡§ú‡§æ...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/9rlQowAsFh']</td>\n",
              "      <td>['@ArvindKejriwal', '@rajnathsingh', '@AmitSha...</td>\n",
              "      <td>['Delhi']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•á‡§Ç 10 ‡§π‡§ú‡§æ...</td>\n",
              "      <td>‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä 10 ‡§π‡§ú‡§æ‡§∞ ‡§¨‡•á‡§° ‡§µ‡§æ‡§≤‡§æ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ ‡§Æ‡•á‡§Ç PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/ZvKgxk6dbd']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ ‡§Æ‡•á‡§Ç PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§...</td>\n",
              "      <td>‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø ‡§∏‡§∞...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ ‡§Æ‡•á‡§Ç Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§µ ‡§∏‡§ö‡§ø‡§µ...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/hxM1uNNmX2']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['UP']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ ‡§Æ‡•á‡§Ç Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§µ ‡§∏‡§ö‡§ø‡§µ...</td>\n",
              "      <td>‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§∏‡§ö‡§ø‡§µ ‡§≤‡§æ‡§ñ‡•ã‡§Ç...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          ‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§∏‡•á ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•á...  ...  ‡§¶‡•É‡§¢‡§º ‡§á‡§ö‡•ç‡§õ‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§™‡§∞‡§ø‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡•ç‡§∞‡§£‡§¨‡§¶‡§æ ‡§¶‡•á‡§∂‡§π‡§ø‡§§ ‡§∏‡§∞‡•ç‡§µ‡•ã...\n",
              "2          ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§µ‡§æ‡§≤‡•á ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç ...  ...  ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä rss ‡§á‡§§‡§®‡•á ‡§ó‡§ø‡§∞‡•á ‡§π‡•Ç‡§Ç ‡§Æ‡•á‡§∞‡•Ä ‡§ú‡§æ‡§∏‡•Ç...\n",
              "3          ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§∏‡•á ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•á‡§Ç 10 ‡§π‡§ú‡§æ...  ...  ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ ‡§®‡§ø‡§™‡§ü‡§®‡•á ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä / ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä 10 ‡§π‡§ú‡§æ‡§∞ ‡§¨‡•á‡§° ‡§µ‡§æ‡§≤‡§æ...\n",
              "4          ‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ ‡§Æ‡•á‡§Ç PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§...  ...  ‡§ó‡§µ‡§∞‡•ç‡§®‡§∞ ‡§ï‡•â‡§®‡•ç‡§´‡•ç‡§∞‡•á‡§Ç‡§∏ PM ‡§Æ‡•ã‡§¶‡•Ä ‡§¨‡•ã‡§≤‡•á- ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§®‡•Ä‡§§‡§ø ‡§∏‡§∞...\n",
              "5          ‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ ‡§Æ‡•á‡§Ç Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§µ ‡§∏‡§ö‡§ø‡§µ...  ...  ‡§Ø‡•Ç‡§™‡•Ä: ‡§ó‡§æ‡§ú‡•Ä‡§™‡•Å‡§∞ Toilet ‡§ò‡•ã‡§ü‡§æ‡§≤‡§æ, ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§∏‡§ö‡§ø‡§µ ‡§≤‡§æ‡§ñ‡•ã‡§Ç...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHNlD7M44Esg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "fbd77233-a06b-4dd5-f1ff-beccc80c5b97"
      },
      "source": [
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1653, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...</td>\n",
              "      <td>‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§®‡•á...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/Dq05hREifM']</td>\n",
              "      <td>['@kumarprakash4u']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§®‡•á...</td>\n",
              "      <td>‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§ó‡•ã‡§≤‡•Ä ‡§Æ‡§æ‡§∞‡§ï...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üôè', 'üòÇ', 'üëç']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...</td>\n",
              "      <td>‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...</td>\n",
              "      <td>‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üëá', 'üòÇ', 'üòÇ', 'üòÇ', 'üòÇ']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡•á...</td>\n",
              "      <td>‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          ‡§ï‡•Ä‡§∏ ‡§ï‡•Ä ‡§ï‡•ã ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ö‡§æ‡§π‡§ø‡§è ‡§´‡§ø‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§®‡§π...  ...  ‡§ï‡•Ä‡§∏ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§π‡§®‡§æ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§Æ‡§ø‡§≤‡§§‡§æ 20 ‡§ï‡§∞‡•ã‡§° ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ 6 ...\n",
              "2          ‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§î‡§∞ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§®‡•á...  ...  ‡§™‡§ü‡§®‡§æ: BMP ‡§ï‡•à‡§Ç‡§™ ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§ï‡§æ‡§Ç‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§ó‡•ã‡§≤‡•Ä ‡§Æ‡§æ‡§∞‡§ï...\n",
              "3          ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä...  ...  ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏‡•Ä, ‡§ä‡§Ç‡§ö‡•Ä ‡§õ‡§§ ‡§™‡§∞, ‡§∞‡•á‡§≤‡§µ‡•á ‡§≤‡§æ‡§á‡§® ‡§™‡§∞, ‡§ä‡§Ç‡§ö‡•Ä ‡§¨‡§ø‡§≤...\n",
              "4          ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§ï‡•á ‡§≠‡§æ‡§à ‡§ï‡•ã ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§¶‡•ç‡§µ‡§æ...  ...  ‡§Ö‡§Ç‡§°‡§∞‡§µ‡§∞‡•ç‡§≤‡•ç‡§° ‡§°‡•â‡§® ‡§õ‡•ã‡§ü‡§æ ‡§∞‡§æ‡§ú‡§® ‡§≠‡§æ‡§à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§ü‡§ø‡§ï‡§ü ‡§Æ‡§ø‡§≤‡§æ ‡§π‡•à‡•§\n",
              "5          RT @_Pb_swain_: ‡§á‡§® ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ã‡§® ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§ï‡§ø ...  ...  ‡§™‡§Ç‡§ö‡§∞ ‡§õ‡§æ‡§™‡•ã‡§Ç ‡§∏‡§Æ‡§ù‡§æ‡§è ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡•ã‡§¶‡•Ä ‡§ü‡•ç‡§Ø‡•Ç‡§¨ ‡§≤‡•à...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMC_GwsU8-Sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "1bcc993a-f6de-4c41-cbd3-84d4ed9fc71b"
      },
      "source": [
        "print(train_val_data.shape)\n",
        "train_val_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6538, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['üôè', 'üôè']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...</td>\n",
              "      <td>‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§™‡§ï‡•ç‡§ï‡•á ‡§∞‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§ ‡§¨‡§æ‡§¨‡§∞...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/8iy2MJSBAs']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...</td>\n",
              "      <td>‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡§Æ‡§æ‡§à ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§®‡§à-‡§®‡§à ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡•á‡§Ç ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/G945HvzM0Z', 'https://t.co/KfH7...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['LIVE']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...</td>\n",
              "      <td>‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§•‡•Ä, ‡§°‡•Ä‡§≤ ‡§¶‡•Ä‡§™‡•á‡§∂ ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§π...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§Ø‡§π ‡§ï‡§π‡§§‡•á...</td>\n",
              "      <td>‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§∏‡§¨‡§ï...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://t.co/4e6lysg0VR']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['unlock4guidelines']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä\\n\\n- 7 ‡§∏‡§ø‡§§‡§Ç‡§¨...</td>\n",
              "      <td>- ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏ ‡§ú‡§æ‡§∞‡•Ä - 7 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§¶‡•á‡§∂‡§≠‡§∞ ‡§Æ‡•á‡§ü...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Post  ... Unnamed: 13\n",
              "0  ‡§Æ‡•á‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å ‡§¨‡§π‡•Å‡§§ ‡§®‡§ø‡§∞‡§æ‡§≤‡•á ‡§π‡•à‡•§ ‡§ï‡•Å‡§õ ‡§§‡•ã ‡§™‡§ï‡•ç‡§ï...  ...         NaN\n",
              "1  ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡•á ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§à ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø...  ...         NaN\n",
              "2  ‡§∏‡•Å‡§∂‡§æ‡§Ç‡§§ ‡§®‡•á ‡§ú‡•ã ‡§¨‡§ø‡§ú‡§®‡•á‡§∏ ‡§°‡•Ä‡§≤ 9 ‡§ú‡•Ç‡§® ‡§ï‡•ã ‡§ï‡•Ä ‡§•‡•Ä, ‡§µ‡•ã ‡§°‡•Ä‡§≤...  ...         NaN\n",
              "3  @prabhav218 ‡§∏‡§æ‡§≤‡•á ‡§ú‡•á‡§è‡§®‡§Ø‡•Ç ‡§õ‡§æ‡§™ ‡§ï‡§Æ‡§ø‡§®‡•á ‡§≤‡•ã‡§ó ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç...  ...         NaN\n",
              "4  #unlock4guidelines - ‡§Ö‡§®‡§≤‡•â‡§ï-4 ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§æ‡§á‡§°‡§≤‡§æ‡§á‡§®‡•ç‡§∏...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTg69u-b4wDw"
      },
      "source": [
        "**Transforming the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPoz0-5P4IsD"
      },
      "source": [
        "labels_set = {'defamation',\n",
        " 'fake',\n",
        " 'hate',\n",
        " 'non-hostile',\n",
        " 'offensive'}\n",
        "\n",
        "labels_mapping = {'defamation':0,\n",
        " 'fake':1,\n",
        " 'hate':2,\n",
        " 'non-hostile':3,\n",
        " 'offensive':4}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1OzBY4MKF"
      },
      "source": [
        "train_y = np.empty((0, 5))\n",
        "for index, row in train_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_y = np.vstack((train_y, y))\n",
        "\n",
        "\n",
        "val_y = np.empty((0, 5))\n",
        "for index, row in val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  val_y = np.vstack((val_y, y))\n",
        "\n",
        "train_val_y = np.vstack((train_y, val_y))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBa01jcE4NWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea37297-26e5-44b8-9900-f00bff8fea12"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(train_val_y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5727, 5)\n",
            "(811, 5)\n",
            "(6538, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aL98-Vi5wyt"
      },
      "source": [
        "y_train_non_hostile = train_y[:,3].astype(int)\n",
        "y_val_non_hostile = val_y[:,3].astype(int)\n",
        "y_train_val_non_hostile = train_val_y[:,3].astype(int)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWHaIm146GRw"
      },
      "source": [
        "**Results using different levels of filtering** \n",
        "1. Original Data (97% f1 score with 4 epochs)\n",
        "2. Filtered Data (91% f1 score with 4 epochs)\n",
        "3. Stopword removed Filterd Data (91% f1 score with 4 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ6H2Bmk6BWP"
      },
      "source": [
        "# train_sentences = train_data['Filtered_Post'].values\n",
        "# val_sentences = val_data['Filtered_Post'].values\n",
        "# test_sentences = test_data['Filtered_Post'].values\n",
        "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
        "\n",
        "train_sentences = train_data['Post'].values\n",
        "val_sentences = val_data['Post'].values\n",
        "test_sentences = test_data['Post'].values\n",
        "train_val_sentences = train_val_data['Post'].values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCtXMKS64VT"
      },
      "source": [
        "**Modelling Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AzCgmM40un"
      },
      "source": [
        "def X_process(sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FZSOIJ5Ua2"
      },
      "source": [
        "def train_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    return train_dataloader"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AFD9Fs5aOw"
      },
      "source": [
        "def val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return validation_dataloader"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fjVV8d5a5f"
      },
      "source": [
        "def test_load(input_ids, attention_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMF_Pg-9XYn"
      },
      "source": [
        "def train_val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_validation_dataloader = DataLoader(\n",
        "                train_val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return train_validation_dataloader"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBErql77BAv"
      },
      "source": [
        "def train_fn(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask,\n",
        "                                       labels=b_labels)\n",
        "                loss = state.loss\n",
        "                logits = state.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKn1eKZFaMsQ"
      },
      "source": [
        "def train_fn_test(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask)\n",
        "                logits = state.logits\n",
        "\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBONPGg77Clo"
      },
      "source": [
        "def stats(training_stats):\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    return df_stats\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhcuXIG7Dpk"
      },
      "source": [
        "def plot_stats(df_stats):\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evcCcgjA7FTu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MSQH9l7GSm"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHqtP0nElkb"
      },
      "source": [
        "def evaluation(y_true, y_pred):\n",
        "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXD8myPu4bsE"
      },
      "source": [
        "**Training for Non Hostile Class (Using Train Data and Val Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwYMVP0b4d7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a93178-f39a-42a1-d23b-24a20771e4f9"
      },
      "source": [
        "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
        "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(26)\n",
        "np.random.seed(26)\n",
        "torch.manual_seed(26)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device) # Send the model to the GPU if we have one"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihIQJe4H4n6Z"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBM-STd7kgd"
      },
      "source": [
        "**TODO: Tryout different batchsize and length (80, 100)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS8h43pH4ptH"
      },
      "source": [
        "batch_size = 8\n",
        "max_length = 256"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BEIQPiC7NWt"
      },
      "source": [
        "train_labels_non_hostile = y_train_non_hostile\n",
        "val_labels_non_hostile = y_val_non_hostile"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxuUUWlN7Tka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db3b836-267e-4b93-934f-9910aaba1460"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_sentences)\n",
        "train_dataloader = train_load(input_ids, attention_masks, train_labels_non_hostile)\n",
        "\n",
        "input_ids, attention_masks = X_process(val_sentences)\n",
        "validation_dataloader = val_load(input_ids, attention_masks, val_labels_non_hostile)\n",
        "\n",
        "input_ids, attention_masks = X_process(test_sentences)\n",
        "test_dataloader = test_load(input_ids, attention_masks)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4zE18ua79Gc"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq2sv8GZ8Byy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb98e14-2c49-4b29-9587-15148386635e"
      },
      "source": [
        "training_stats, y_pred_val_non_hostile = train_fn(train_dataloader, validation_dataloader)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    716.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    716.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    716.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    716.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    716.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    716.    Elapsed: 0:01:43.\n",
            "  Batch   280  of    716.    Elapsed: 0:02:00.\n",
            "  Batch   320  of    716.    Elapsed: 0:02:17.\n",
            "  Batch   360  of    716.    Elapsed: 0:02:34.\n",
            "  Batch   400  of    716.    Elapsed: 0:02:51.\n",
            "  Batch   440  of    716.    Elapsed: 0:03:08.\n",
            "  Batch   480  of    716.    Elapsed: 0:03:25.\n",
            "  Batch   520  of    716.    Elapsed: 0:03:42.\n",
            "  Batch   560  of    716.    Elapsed: 0:03:59.\n",
            "  Batch   600  of    716.    Elapsed: 0:04:16.\n",
            "  Batch   640  of    716.    Elapsed: 0:04:33.\n",
            "  Batch   680  of    716.    Elapsed: 0:04:50.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:05:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.16\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.2439687034309004, 'Valid. Loss': 0.16181047007386737, 'Valid. Accur.': 0.9501633986928105, 'Training Time': '0:05:06', 'Validation Time': '0:00:14'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    716.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    716.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    716.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    716.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    716.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    716.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    716.    Elapsed: 0:01:59.\n",
            "  Batch   320  of    716.    Elapsed: 0:02:16.\n",
            "  Batch   360  of    716.    Elapsed: 0:02:33.\n",
            "  Batch   400  of    716.    Elapsed: 0:02:50.\n",
            "  Batch   440  of    716.    Elapsed: 0:03:07.\n",
            "  Batch   480  of    716.    Elapsed: 0:03:24.\n",
            "  Batch   520  of    716.    Elapsed: 0:03:41.\n",
            "  Batch   560  of    716.    Elapsed: 0:03:58.\n",
            "  Batch   600  of    716.    Elapsed: 0:04:15.\n",
            "  Batch   640  of    716.    Elapsed: 0:04:32.\n",
            "  Batch   680  of    716.    Elapsed: 0:04:49.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.2439687034309004, 'Valid. Loss': 0.16181047007386737, 'Valid. Accur.': 0.9501633986928105, 'Training Time': '0:05:06', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.12536700562051725, 'Valid. Loss': 0.12379229074120339, 'Valid. Accur.': 0.9705882352941176, 'Training Time': '0:05:04', 'Validation Time': '0:00:14'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    716.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    716.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    716.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    716.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    716.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    716.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    716.    Elapsed: 0:01:59.\n",
            "  Batch   320  of    716.    Elapsed: 0:02:16.\n",
            "  Batch   360  of    716.    Elapsed: 0:02:33.\n",
            "  Batch   400  of    716.    Elapsed: 0:02:50.\n",
            "  Batch   440  of    716.    Elapsed: 0:03:07.\n",
            "  Batch   480  of    716.    Elapsed: 0:03:24.\n",
            "  Batch   520  of    716.    Elapsed: 0:03:41.\n",
            "  Batch   560  of    716.    Elapsed: 0:03:58.\n",
            "  Batch   600  of    716.    Elapsed: 0:04:15.\n",
            "  Batch   640  of    716.    Elapsed: 0:04:32.\n",
            "  Batch   680  of    716.    Elapsed: 0:04:49.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.2439687034309004, 'Valid. Loss': 0.16181047007386737, 'Valid. Accur.': 0.9501633986928105, 'Training Time': '0:05:06', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.12536700562051725, 'Valid. Loss': 0.12379229074120339, 'Valid. Accur.': 0.9705882352941176, 'Training Time': '0:05:04', 'Validation Time': '0:00:14'}, {'epoch': 3, 'Training Loss': 0.06899997623860557, 'Valid. Loss': 0.12355649451709207, 'Valid. Accur.': 0.9742647058823529, 'Training Time': '0:05:04', 'Validation Time': '0:00:14'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    716.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    716.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    716.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    716.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    716.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    716.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    716.    Elapsed: 0:01:59.\n",
            "  Batch   320  of    716.    Elapsed: 0:02:16.\n",
            "  Batch   360  of    716.    Elapsed: 0:02:33.\n",
            "  Batch   400  of    716.    Elapsed: 0:02:50.\n",
            "  Batch   440  of    716.    Elapsed: 0:03:07.\n",
            "  Batch   480  of    716.    Elapsed: 0:03:24.\n",
            "  Batch   520  of    716.    Elapsed: 0:03:41.\n",
            "  Batch   560  of    716.    Elapsed: 0:03:58.\n",
            "  Batch   600  of    716.    Elapsed: 0:04:15.\n",
            "  Batch   640  of    716.    Elapsed: 0:04:32.\n",
            "  Batch   680  of    716.    Elapsed: 0:04:49.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.2439687034309004, 'Valid. Loss': 0.16181047007386737, 'Valid. Accur.': 0.9501633986928105, 'Training Time': '0:05:06', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.12536700562051725, 'Valid. Loss': 0.12379229074120339, 'Valid. Accur.': 0.9705882352941176, 'Training Time': '0:05:04', 'Validation Time': '0:00:14'}, {'epoch': 3, 'Training Loss': 0.06899997623860557, 'Valid. Loss': 0.12355649451709207, 'Valid. Accur.': 0.9742647058823529, 'Training Time': '0:05:04', 'Validation Time': '0:00:14'}, {'epoch': 4, 'Training Loss': 0.036816640089770196, 'Valid. Loss': 0.13531412691044548, 'Valid. Accur.': 0.9767156862745098, 'Training Time': '0:05:04', 'Validation Time': '0:00:14'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVZcJgJo8EXS"
      },
      "source": [
        "**Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2lRXn3a8HAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9f3c61b7-06e0-474d-851c-37ffc54ec4b2"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1RU19oG8GeGYYbeQVBEEKWIgAi2SGLsqNixR43G2GKJuSZq1FxTjImaaNTEG0sSO0qzYsWSrgGNaARUsIAiIr0zMPP9YZzPEdBBgTPg81vrrnVnn3P2eWdkr7yz5937iJRKpRJERERERFQviIUOgIiIiIiINMcEnoiIiIioHmECT0RERERUjzCBJyIiIiKqR5jAExERERHVI0zgiYiIiIjqESbwRPTSS0lJgaurK9auXfvcfcyfPx+urq41GFXDVdXn7erqivnz52vUx9q1a+Hq6oqUlJQajy88PByurq44e/ZsjfdNRFQTJEIHQET0pOokwlFRUbC3t6/FaOqfwsJC/O9//0NkZCTu378PCwsL+Pr6Yvr06XB2dtaoj1mzZuHo0aPYu3cv3N3dKz1HqVSie/fuyM3Nxa+//go9Pb2afBu16uzZszh37hzGjx8PExMTocOpICUlBd27d8eYMWPw0UcfCR0OEWkZJvBEpHWWL1+u9jomJga7d+/GiBEj4Ovrq3bMwsLihe/XpEkTxMbGQkdH57n7+PTTT/Hxxx+/cCw1YdGiRTh06BACAwPRvn17pKen4+TJk7h48aLGCXxQUBCOHj2KsLAwLFq0qNJz/vzzT9y5cwcjRoyokeQ9NjYWYnHd/DB87tw5rFu3DoMHD66QwA8cOBD9+vWDrq5uncRCRFRdTOCJSOsMHDhQ7XV5eTl2796NNm3aVDj2pPz8fBgZGVXrfiKRCDKZrNpxPk5bkr2ioiIcOXIE/v7++Oqrr1TtM2bMQGlpqcb9+Pv7w87ODgcOHMAHH3wAqVRa4Zzw8HAAD5P9mvCi/wY1RUdH54W+zBER1TbWwBNRvdWtWzeMHTsWV65cwVtvvQVfX18MGDAAwMNEftWqVRg2bBg6dOiA1q1bo2fPnli5ciWKiorU+qmsJvvxtlOnTmHo0KHw9PSEv78/vvzyS5SVlan1UVkN/KO2vLw8/Pe//0WnTp3g6emJkSNH4uLFixXeT1ZWFhYsWIAOHTrAx8cH48aNw5UrVzB27Fh069ZNo89EJBJBJBJV+oWisiS8KmKxGIMHD0Z2djZOnjxZ4Xh+fj6OHTsGFxcXeHl5VevzrkplNfAKhQLff/89unXrBk9PTwQGBmL//v2VXp+YmIglS5agX79+8PHxgbe3N4YMGYKQkBC18+bPn49169YBALp37w5XV1e1f/+qauAzMzPx8ccfo0uXLmjdujW6dOmCjz/+GFlZWWrnPbr+jz/+wObNm9GjRw+0bt0avXv3RkREhEafRXXEx8fjnXfeQYcOHeDp6Ym+ffti48aNKC8vVzsvNTUVCxYsQNeuXdG6dWt06tQJI0eOVItJoVDgp59+Qv/+/eHj44O2bduid+/e+PDDDyGXy2s8diJ6PpyBJ6J67e7duxg/fjwCAgLQq1cvFBYWAgDS0tIQGhqKXr16ITAwEBKJBOfOncOmTZsQFxeHzZs3a9T/mTNnsHPnTowcORJDhw5FVFQUfvjhB5iammLq1Kka9fHWW2/BwsIC77zzDrKzs/Hjjz9i8uTJiIqKUv1aUFpaigkTJiAuLg5DhgyBp6cnEhISMGHCBJiammr8eejp6WHQoEEICwvDwYMHERgYqPG1TxoyZAjWr1+P8PBwBAQEqB07dOgQiouLMXToUAA193k/admyZdi6dSvatWuHN998ExkZGfjkk0/QtGnTCueeO3cO0dHReP3112Fvb6/6NWLRokXIzMzElClTAAAjRoxAfn4+jh8/jgULFsDc3BzA09de5OXlYdSoUbh16xaGDh2KVq1aIS4uDrt27cKff/6JkJCQCr/8rFq1CsXFxRgxYgSkUil27dqF+fPnw8HBoUIp2PO6dOkSxo4dC4lEgjFjxsDKygqnTp3CypUrER8fr/oVpqysDBMmTEBaWhpGjx4NR0dH5OfnIyEhAdHR0Rg8eDAAYP369VizZg26du2KkSNHQkdHBykpKTh58iRKS0u15pcmopeekohIy4WFhSldXFyUYWFhau1du3ZVuri4KPfs2VPhmpKSEmVpaWmF9lWrVildXFyUFy9eVLUlJycrXVxclGvWrKnQ5u3trUxOTla1KxQKZb9+/ZSdO3dW63fevHlKFxeXStv++9//qrVHRkYqXVxclLt27VK1bd++Xeni4qL87rvv1M591N61a9cK76UyeXl5yrffflvZunVrZatWrZSHDh3S6LqqjBs3Tunu7q5MS0tTax8+fLjSw8NDmZGRoVQqX/zzViqVShcXF+W8efNUrxMTE5Wurq7KcePGKcvKylTtly9fVrq6uipdXFzU/m0KCgoq3L+8vFz5xhtvKNu2basW35o1aypc/8ijv7c///xT1fb1118rXVxclNu3b1c799G/z6pVqypcP3DgQGVJSYmq/d69e0oPDw/lnDlzKtzzSY8+o48//vip540YMULp7u6ujIuLU7UpFArlrFmzlC4uLsrff/9dqVQqlXFxcUoXFxflhg0bntrfoEGDlH369HlmfEQkLJbQEFG9ZmZmhiFDhlRol0qlqtnCsrIy5OTkIDMzE6+88goAVFrCUpnu3bur7XIjEonQoUMHpKeno6CgQKM+3nzzTbXXHTt2BADcunVL1Xbq1Cno6Ohg3LhxaucOGzYMxsbGGt1HoVBg9uzZiI+Px+HDh/Haa69h7ty5OHDggNp5ixcvhoeHh0Y18UFBQSgvL8fevXtVbYmJifj777/RrVs31SLimvq8HxcVFQWlUokJEyao1aR7eHigc+fOFc43MDBQ/f+SkhJkZWUhOzsbnTt3Rn5+PpKSkqodwyPHjx+HhYUFRowYodY+YsQIWFhY4MSJExWuGT16tFrZUqNGjeDk5ISbN28+dxyPy8jIwIULF9CtWze4ubmp2kUiEaZNm6aKG4Dqb+js2bPIyMiosk8jIyOkpaUhOjq6RmIkotrBEhoiqteaNm1a5YLDHTt2IDg4GNevX4dCoVA7lpOTo3H/TzIzMwMAZGdnw9DQsNp9PCrZyM7OVrWlpKTAxsamQn9SqRT29vbIzc195n2ioqLw66+/YsWKFbC3t8c333yDGTNm4IMPPkBZWZmqTCIhIQGenp4a1cT36tULJiYmCA8Px+TJkwEAYWFhAKAqn3mkJj7vxyUnJwMAmjdvXuGYs7Mzfv31V7W2goICrFu3DocPH0ZqamqFazT5DKuSkpKC1q1bQyJR/8+mRCKBo6Mjrly5UuGaqv527ty589xxPBkTALRo0aLCsebNm0MsFqs+wyZNmmDq1KnYsGED/P394e7ujo4dOyIgIABeXl6q69577z288847GDNmDGxsbNC+fXu8/vrr6N27d7XWUBBR7WICT0T1mr6+fqXtP/74I7744gv4+/tj3LhxsLGxga6uLtLS0jB//nwolUqN+n/abiQv2oem12vq0aLLdu3aAXiY/K9btw7Tpk3DggULUFZWBjc3N1y8eBFLly7VqE+ZTIbAwEDs3LkT58+fh7e3N/bv3w9bW1u8+uqrqvNq6vN+Ef/5z39w+vRpDB8+HO3atYOZmRl0dHRw5swZ/PTTTxW+VNS2utoSU1Nz5sxBUFAQTp8+jejoaISGhmLz5s2YNGkS3n//fQCAj48Pjh8/jl9//RVnz57F2bNncfDgQaxfvx47d+5UfXklImExgSeiBmnfvn1o0qQJNm7cqJZI/fzzzwJGVbUmTZrgjz/+QEFBgdosvFwuR0pKikYPG3r0Pu/cuQM7OzsAD5P47777DlOnTsXixYvRpEkTuLi4YNCgQRrHFhQUhJ07dyI8PBw5OTlIT0/H1KlT1T7X2vi8H81gJyUlwcHBQe1YYmKi2uvc3FycPn0aAwcOxCeffKJ27Pfff6/Qt0gkqnYsN27cQFlZmdosfFlZGW7evFnpbHtte1Tadf369QrHkpKSoFAoKsTVtGlTjB07FmPHjkVJSQneeustbNq0CRMnToSlpSUAwNDQEL1790bv3r0BPPxl5ZNPPkFoaCgmTZpUy++KiDShXdMDREQ1RCwWQyQSqc38lpWVYePGjQJGVbVu3bqhvLwcW7duVWvfs2cP8vLyNOqjS5cuAB7ufvJ4fbtMJsPXX38NExMTpKSkoHfv3hVKQZ7Gw8MD7u7uiIyMxI4dOyASiSrs/V4bn3e3bt0gEonw448/qm2J+M8//1RIyh99aXhypv/+/fsVtpEE/r9eXtPSnh49eiAzM7NCX3v27EFmZiZ69OihUT81ydLSEj4+Pjh16hSuXr2qalcqldiwYQMAoGfPngAe7qLz5DaQMplMVZ706HPIzMyscB8PDw+1c4hIeJyBJ6IGKSAgAF999RXefvtt9OzZE/n5+Th48GC1Ete6NGzYMAQHB2P16tW4ffu2ahvJI0eOoFmzZhX2na9M586dERQUhNDQUPTr1w8DBw6Era0tkpOTsW/fPgAPk7Fvv/0Wzs7O6NOnj8bxBQUF4dNPP8Uvv/yC9u3bV5jZrY3P29nZGWPGjMH27dsxfvx49OrVCxkZGdixYwfc3NzU6s6NjIzQuXNn7N+/H3p6evD09MSdO3ewe/du2Nvbq603AABvb28AwMqVK9G/f3/IZDK0bNkSLi4ulcYyadIkHDlyBJ988gmuXLkCd3d3xMXFITQ0FE5OTrU2M3358mV89913FdolEgkmT56MhQsXYuzYsRgzZgxGjx4Na2trnDp1Cr/++isCAwPRqVMnAA/LqxYvXoxevXrByckJhoaGuHz5MkJDQ+Ht7a1K5Pv27Ys2bdrAy8sLNjY2SE9Px549e6Crq4t+/frVynskourTzv+SERG9oLfeegtKpRKhoaFYunQprK2t0adPHwwdOhR9+/YVOrwKpFIptmzZguXLlyMqKgqHDx+Gl5cXfvrpJyxcuBDFxcUa9bN06VK0b98ewcHB2Lx5M+RyOZo0aYKAgABMnDgRUqkUI0aMwPvvvw9jY2P4+/tr1G///v2xfPlylJSUVFi8CtTe571w4UJYWVlhz549WL58ORwdHfHRRx/h1q1bFRaOrlixAl999RVOnjyJiIgIODo6Ys6cOZBIJFiwYIHaub6+vpg7dy6Cg4OxePFilJWVYcaMGVUm8MbGxti1axfWrFmDkydPIjw8HJaWlhg5ciRmzpxZ7af/aurixYuV7uAjlUoxefJkeHp6Ijg4GGvWrMGuXbtQWFiIpk2bYu7cuZg4caLqfFdXV/Ts2RPnzp3DgQMHoFAoYGdnhylTpqidN3HiRJw5cwbbtm1DXl4eLC0t4e3tjSlTpqjtdENEwhIp62JlERERPZfy8nJ07NgRXl5ez/0wJCIialhYA09EpCUqm2UPDg5Gbm5upfueExHRy4klNEREWmLRokUoLS2Fj48PpFIpLly4gIMHD6JZs2YYPny40OEREZGWYAkNEZGW2Lt3L3bs2IGbN2+isLAQlpaW6NKlC2bPng0rKyuhwyMiIi3BBJ6IiIiIqB5hDTwRERERUT0iaA18aWkpvvnmG+zbtw+5ublwc3PDnDlzVPvWVuXYsWOIjIxEbGwsMjIyYGdnh65du2L69OkwNjZWO9fV1bXSPpYsWYJRo0bV2HshIiIiIqoLgpbQvPfeezh27BjGjRuHZs2aISIiApcvX8a2bdvg4+NT5XUdOnSAjY0NevTogcaNGyMhIQHBwcFwdHREWFgYZDKZ6lxXV1f4+/tjwIABan14e3vD0dGx2jFnZRVAoaj7j8zS0ggZGfl1fl+i+oZjhUgzHCtEmhFirIjFIpibG1Z5XLAZ+NjYWBw6dAgLFizAm2++CQAYNGgQAgMDsXLlSuzYsaPKa9esWYMOHTqotbVu3Rrz5s3DoUOHMGTIELVjzZs3x8CBA2skboVCKUgC/+jeRPRsHCtEmuFYIdKMto0VwWrgjxw5Al1dXQwbNkzVJpPJEBQUhJiYGNy/f7/Ka59M3gGgR48eAIDExMRKrykuLkZJSckLRk1EREREJCzBEvi4uDg4OTnB0FD95wEvLy8olUrExcVVq78HDx4AAMzNzSscCw0NRZs2beDl5YX+/fvj+PHjzx84EREREZGABCuhSU9PR6NGjSq0W1tbA8BTZ+Ars3HjRujo6KBXr15q7T4+Pujbty/s7e2RmpqKrVu3YsaMGfjqq68QGBj4/G+AiIiIiEgAgiXwxcXF0NXVrdD+aAFqdcpdDhw4gNDQUEyZMgUODg5qx4KDg9VeDx48GIGBgVixYgX69esHkUhUrbgtLY2qdX5NsrY2fvZJRMSxQqQhjhUizWjbWBEsgdfT04NcLq/Q/ihxf3wnmaeJjo7GwoUL8frrr2P27NnPPN/AwAAjR47EV199haSkJDg7O1cr7oyMfEEWMlhbGyM9Pa/O70tU33CsEGmGY4VIM0KMFbFY9NRJY8ESeGtr60rLZNLT0wEANjY2z+wjPj4e06ZNg6urK1atWgUdHR2N7m1nZwcAyMnJqUbERERERFUrKipAfn4OyssrTlBS/XX/vhgKhaLG+tPR0YWRkSn09aveJvJZBEvg3dzcsG3bNhQUFKgtZL148aLq+NPcvn0bkyZNgoWFBb7//nsYGBhofO/k5GQAgIWFxXNETkRERKROLi9FXl4WzMysoKsrq3aJLmkviUSMsrKaSeCVSiXk8hJkZz+ARKILXV3pc/Uj2C40AQEBkMvlCAkJUbWVlpYiPDwcbdu2VS1wvXv3boWtIdPT0zFx4kSIRCJs3ry5ykQ8MzOzQltWVhZ27twJe3v753qQExEREdGT8vKyYWRkCqlUj8k7VUkkEkEq1YOhoSny87Ofux/BZuC9vb0REBCAlStXIj09HQ4ODoiIiMDdu3exbNky1Xnz5s3DuXPnkJCQoGqbNGkSkpOTMWnSJMTExCAmJkZ1zMHBQfUU1x07diAqKgqvv/46GjdujLS0NOzevRuZmZn49ttv6+7NEhERUYNWVlYKmYy/7JNm9PT0UVDw/KXcgiXwALB8+XKsXr0a+/btQ05ODlxdXbFhwwb4+vo+9br4+HgAwKZNmyocGzx4sCqB9/Hxwfnz5xESEoKcnBwYGBigTZs2mDJlyjPvoS3++Ocews8kIjO3BBYmMgzp4oxOHrZCh0VERESPUSjKIRZrthaPSCzWgUJR/tzXi5RKpXY9G1bL1eUuNH/8cw9bDsej9LG6K6lEjPF93JjEE1WBO2sQaYZjpWbdu3cLtrbNhA6DakFN1sA/7ml/M8/ahUawGnh6tvAziWrJOwCUlikQfiaxiiuIiIiIqKFjAq/FMnIrf5hVVe1ERERE9c2MGZMxY8bkOr+2PhO0Bp6eztJEVmmybm6k2UOuiIiIiJ6Xv7+fRueFhOyHnV3jWo6GHscEXosN6eJcoQYeAErkZbh1Lw/NbLXrsb5ERETUcCxe/Ina6z17diEtLRUzZ76n1m5mZv5C91m16vl3BnyRa+szJvBa7NFC1cd3oeni0wRnLtzBsu0xmBTYCn5uz35iLREREVF19e7dV+316dNRyMnJrtD+pOLiYujp6Wl8H11d3eeK70Wvrc+YwGu5Th626ORhq7ZbwKtejbEuPBbf7b2Mwa81R2CnZnxoBBEREdW5GTMmIz8/Hx988CHWrl2FhIR4jBkzDm+9NQW//HIa+/dH4OrVBOTm5sDa2gZ9+/bH2LEToKOjo9YHAKxbtwEAcP58NGbNmoqlS5fjxo0k7N0bhtzcHHh6euP99z+EvX3TGrkWAMLC9iA4eAcyMh7A2dkZM2bMwcaN69X61EZM4OshU0MpPhjlgx8PxyPi5ySkZhRgQh836Eq4/ywREVFD8ehZMBm5JbDU4mfBZGdn4YMP5qBXrwAEBPRDo0YPY4yMPAh9fQOMGDEGBgb6iImJxqZN/0NBQQHeeWf2M/vdsmUzxGIdjB49Dnl5udi1axs+/ngRNm7cUiPXRkSEYtWq5WjTpi1GjBiF1NRULFgwF8bGxrC21u4KBybw9ZSuRAdvB7ZCY0tDhP+chPSsIswY6gVTQ6nQoREREdELevJZMBm5Jdhy+OGDLLUtiX/wIB3z5y9GYOBAtfYlSz6DTPb/pTSDBgVhxYrPERERgrffngap9Ok5S1lZGX74YQskkofpqomJKb75ZiWSkq6jefMWL3StXC7Hpk3r4eHhidWrv1Od16JFSyxduoQJPNUekUiEwFccYWdpgI0Hr+DTLX9h1lAvODTi4lYiIiJt8NulVPwam1rt6xLv5qCsXP3BkaVlCvwYGYef/75b7f78vezQ2dOu2tdpQk9PDwEB/Sq0P568FxYWoLRUDm9vH+zbF45bt26iZUuXp/bbr98AVWINAN7ebQAAd+/eeWYC/6xr4+OvICcnB9OnD1Y7r2fPAKxZ8/VT+9YGTOAbAF9XG1iZ6mNNWCyWbT+PyQNawaeltdBhERER0XN6Mnl/VruQrK1t1JLgR5KSErFx43qcP/8XCgoK1I4VFOQ/s99HpTiPGBubAADy8p79BOFnXXvv3sMvVU/WxEskEtjZ1c4XnZrEBL6BaGZrjMXj/bA2LBbrwi4h6HVnBHRw4OJWIiIiAXX2fL6Z7/e/+63SZ8FYmsgwb0zbmgitxjw+0/5IXl4eZs6cDAMDI7z11lQ0aWIPqVSKq1fjsX79WigUikp6UicWV762T6l89peYF7m2PuCTWBsQMyMZ5o1ui3buNgg5nYgfIuMgL3v2ACEiIiLtMqSLM6QS9TRNKhFjSBdngSKqngsXYpCTk4OFC/+L4cNHoXPnV9GuXQfVTLjQbG0ffqlKSUlWay8rK0NqavVLnuoaE/gGRqqrgykDPDDQ3wm/XbqHlcEXkFtYKnRYREREVA2dPGwxvo8bLE0ePn3d0kSG8X3ctG4Ba1XE4ocp5uMz3nK5HBERIUKFpMbNrRVMTU2xf38EysrKVO3Hjx9BXl6ugJFphiU0DZBIJMJAfyfYWRpg86E4fLYlGrOCvGBvbSR0aERERKShR8+CqY88Pb1gbGyCpUuXIChoBEQiEY4ejYS2VLDo6upi4sTJWLVqBd59dzq6du2O1NRUHD58AE2a2Gt9CTJn4Buw9u6NMH9MW8jLFfh8WwxiEx8IHRIRERG9BExNzbB8+SpYWlph48b12LVrO/z8OmD69FlCh6YydOgIvPvuXNy7l4pvv/0GFy9ewBdffA0jI2NIpTKhw3sqkbKhVPPXkYyMfCgUdf+RPf4k1urKzC3GmrBYJN/Px4iuLdCzXVOt/2ZJ9LxeZKwQvUw4VmrWvXu3YGvbTOgw6AUpFAoEBvZEly5dMW/eIgCARCJGWS2sKXza34xYLIKlZdWVE5yBfwlYmOhhwRhftG1pjeCT17HlSALKyrm4lYiIiF5eJSUVd/k5cuQQcnNz4OPjK0BEmmMN/EtCJtXBtMGtsfeXJBz8/RbuZxVi+mBPGOnrCh0aERERUZ2Ljf0b69evxeuvd4OJiSmuXo3HoUP70by5M7p27SF0eE/FBP4lIhaJMOQ1Z9hZGuLHyHh8tiUas4d5wc7SUOjQiIiIiOpU48ZNYGVljdDQ3cjNzYGJiSkCAvph6tQZ0NXV7glO1sBXU32sga/M9Ts5WBcWC3m5EtMGeaC1k2WN9U0kJNb1EmmGY6VmsQa+4WINPGmNFk1MsWi8HyxN9LB6TyyiYlKEDomIiIiINMAE/iVmZaqPD8e2hZezJXYcv4ptx7i4lYiIiEjbMYF/yelJJZgxxBN9Ojjg1Pk7WB1yEQXFcqHDIiIiIqIqMIEniMUiDOvaAhP7uiPhdjY+2xqDtMxCocMiIiIiokowgScVfy87vD/KBwVFcny2NRpxNzOFDomIiIiInsAEntS4NDXD4vF+MDOS4es9F3H6wh2hQyIiIiKixzCBpwqszfTx4VhfeDhZYOvRBOw8cRXlCi5uJSIiItIGTOCpUvoyCWYN9UKvdk1xIjoF34TGorC4TOiwiIiIqJ6KjDwAf38/pKbeVbUFBfXH0qVLnuvaF3X+fDT8/f1w/nx0jfVZV5jAU5XEYhFGdm+J8QGuiLuZhaXbonE/i4tbiYiIXgYffDAHPXr4o6ioqMpz3ntvBnr37oKSkpI6jKx6Tpw4ij17dgodRo1iAk/P1KVNE/xnRBvkFpTis60xSLidJXRIREREVMt69uyN4uJi/PrrmUqPZ2VlIibmL7z2WlfIZLLnusfOnWGYN2/Ri4T5TFFRx7Bnz64K7W3atEVU1G9o06Ztrd6/NjCBJ424NTPHovF+MDbQxcrgv/HLxZr7CYuIiIi0z6uvvg59fQOcOHG00uMnT55AeXk5evUKeO57SKVSSCSS577+RYjFYshkMojF9S8dFuYTo3qpkbkBFo71xfp9/+DHw/FIzShE0OvOEItFQodGRERENUxPTw+vvtoFp06dQG5uLkxMTNSOnzhxFJaWlmjatBlWrvwCMTHnkJaWBj09PbRt64d33pkNO7vGT71HUFB/+Pj4YuHCJaq2pKRErF69ApcvX4KpqSkGDhwCKyvrCtf+8stp7N8fgatXE5CbmwNraxv07dsfY8dOgI6ODgBgxozJ+Pvv8wAAf38/AICtrR1CQw/g/PlozJo1FWvW/A9t2/qp+o2KOobt23/CrVs3YWBgiFdffQ1TpsyEmZmZ6pwZMyYjPz8fH330Cb7+ejni4v6BsbEJhg0biTFjxlfvg34OTOCpWgz0dPHuMC8En7iOI+duIzWjAJMHeEBfxj8lIiKimnTu3nnsTzyCrJJsmMvMMMA5AO1t67bco2fPABw7dhinT0dhwIDBqvZ791Jx+XIsgoJGIi7uH1y+HIsePXrD2toGqal3sXdvGGbOnILt20Ogp6en8f0yMh5g1qypUCgUeOON8dDT08f+/RGVluhERh6Evr4BRowYAwMDfcTERGPTpv+hoKAA77wzGwAwfvxEFBUVIS0tFTNnvgcA0Nc3qPL+kZEH8PnnH6ozb3IAACAASURBVMPDwxPTps3C/ftpCAvbjX/+uYyNG7eqxZGbm4P//GcWunbtju7de+HUqRNYv34tmjdvgU6dOmv8np8Hsy6qNh2xGGN6ucDOygA7j1/D59tjMHuoF6zM9IUOjYiIqEE4d+88dsaHQa6QAwCySrKxMz4MAOo0iW/XrgPMzMxx4sRRtQT+xImjUCqV6NmzN5ydW6Br1x5q13Xu/BqmTp2A06ejEBDQT+P77dixBTk52di0aRtcXd0AAH36BGLUqMEVzl2y5DPIZP//5WDQoCCsWPE5IiJC8Pbb0yCVStGuXUeEh4cgJycbvXv3feq9y8rKsH79WrRo4YK1a7+HVCoFALRq1QqLFy/AgQMRCAoaqTr//v00/Pe/n6Fnz4clRIGBAxEUFIhDh/YxgSft1a2tPRpZGGB9xGV8ujUaM4Z4oqW92bMvJCIiekmcTY3BH6l/Vfu6Gzm3UaZU375ZrpBjR1wofr97rtr9dbJrhw52vtW+TiKRoFu3Hti7NwwPHjyAlZUVAODEiWOwt2+KVq1aq51fVlaGgoJ82Ns3hZGRMa5eja9WAv/HH7/B09NblbwDgLm5OXr27IOIiBC1cx9P3gsLC1BaKoe3tw/27QvHrVs30bKlS7Xea3z8FWRlZaqS/0e6d++JNWtW4ffff1NL4I2MjNCjR2/Va11dXbi7e+Du3dp/CCYTeHohHo4WWDjOF2tCY7Fi1wW82ccNr7S2EzosIiKieu3J5P1Z7bWpZ88AhIeH4OTJYxg+fDRu3ryB69evYsKEtwEAJSXF2LbtJ0RGHkB6+n0olUrVtfn5+dW6V1raPXh6eldod3BoVqEtKSkRGzeux/nzf6GgoEDtWEFB9e4LPCwLquxeYrEY9vZNkZaWqtZuY9MIIpH6OkBjYxMkJl6v9r2riwk8vTA7S0MsHOeH7yIuYdPBOKRmFGLwa80hFnFxKxERvdw62Pk+18z3ot8+R1ZJdoV2c5kZ3m07tSZC05inpzfs7Jrg+PEjGD58NI4fPwIAqtKRVatWIDLyAIYNG4XWrT1hZGQEQIQlSz5US+ZrUl5eHmbOnAwDAyO89dZUNGliD6lUiqtX47F+/Voo6uAJ8mKxTqXttfWeH8cEnmqEkb4u3hvRBjuOX8WhP24hNaMQbwe2gkxa+R83ERERVW2Ac4BaDTwA6Ip1McD5+bdsfBE9evTCtm0/IiUlGVFRx+Dq6q6aqX5U5z5z5hzV+SUlJdWefQeARo1skZKSXKH99u1baq8vXIhBTk4Oli5dobaPe+VPatVsQtHW1k51r8f7VCqVSElJhpOTs0b91IX6t/ElaS2JjhjjertiVI+WuHAtHcu2xyAzt1josIiIiOqd9rZtMdptKMxlD9eWmcvMMNptaJ3vQvNIr159AADr1q1CSkqy2t7vlc1Eh4XtRnl5ebXv06lTZ1y6dBEJCfGqtqysLBw/fljtvEd7tz8+2y2XyyvUyQOAvr6+Rl8m3NxawdzcAnv3hkIu//8vTidPnkB6+n288krtLkytDs7AU40SiUTo6dcUthYG+N++y/h0SzRmDvVC88Ymz76YiIiIVNrbthUsYX+Sk1NztGjhgl9//RlisRjdu///4s1XXvHH0aORMDQ0gqOjE/755xKio8/B1NS02vcZPXo8jh6NxHvvvYOgoJGQyfSwf38EGjWyQ37+NdV5np5eMDY2wdKlSxAUNAIikQhHj0aisuoVV1c3HDt2GGvXfg03t1bQ1zeAv/9rFc6TSCSYNm0mPv/8Y8ycOQU9evTC/ftpCA3djebNndG/f8WdcITCGXiqFZ7NLfHhWD9IdcX4cud5nL2SJnRIRERE9AIezbr7+PiqdqMBgNmz56J37744fvww1q1bjQcPHmD16m+fut96VaysrLBmzfdwcnLGtm0/ISRkFwIC+mLYsJFq55mammH58lWwtLTCxo3rsWvXdvj5dcD06bMq9Dlw4FD07t0HkZEH8fHHi7B69Yoq79+3b38sWbIUJSXF+PbbbxAZeQC9e/fBN9/8r9K96IUiUtZFpX0DkpGRD4Wi7j8ya2tjpKfn1fl9X1ReYSm+Db+Eqyk5GNDZEQP8nbi4lWpVfR0rRHWNY6Vm3bt3C7a2FXdKofpPIhGjrKzmF8U+7W9GLBbB0tKoyms5A0+1ythAirmjfODvaYf9v93E9/v+QYm8+jVxRERERPQQa+Cp1kl0xJjQ1w2NrQwRcuo60rOLMHOoF8yNteenKCIiIqL6gjPwVCdEIhECOjhgZpAXUjML8emWv3DzXq7QYRERERHVO0zgqU61aWGFhW/4QkcsxhfbzyM6/r7QIRERERHVK0zgqc7Z2xhh8Xg/ODQyxnd7L+PAbzfq5KllRERERA0BE3gShImhFO+PaoNOHraI+OUGNh64AnkZF7cSERERPQsXsZJgdCU6mBTojsZWBgg7k4T72UWYOcQTpkZc3EpERERUFc7Ak6BEIhH6dXLEO4M9kZKej0+3RuN2GvclJiKi+ofloKSpF/1bYQJPWsHX1RoLxvhCqQSWbT+PC1fThQ6JiIhIYzo6EsjlpUKHQfWEXF4KHZ3nL4RhAk9ao5mtMRaP90NjK0OsC7+EyD9vcTaDiIjqBSMjM2Rnp6O0tIT/7aIqKZVKlJaWIDs7HUZGZs/dD2vgSauYGckwb7QPfoiMQ+jpRKQ+KMC4ADfoSvhdk4iItJe+viEAICfnAcrLywSOhmqSWCyGQqGosf50dCQwNjZX/c08DybwpHWkujqYMsADja0MsfeXG0jLLsKMIZ4wMZAKHRoREVGV9PUNXygpI+1kbW2M9HTtWp/HaU3SSiKRCAM6O2HaoNa4fS8Pn22JRkp6vtBhEREREQmOCTxptXZuNpg3pi3KyhVYui0GF68/EDokIiIiIkExgSet52RngsXj28HW3ABrQmNx9NxtLhAiIiKilxYTeKoXzI1lmP9GW/i6WmP3yevYciQeZeU1t6CEiIiIqL4QNIEvLS3FihUr4O/vDy8vLwwfPhx//PHHM687duwY3n33XXTr1g3e3t4ICAjAl19+iby8yhcYhISEoE+fPvD09ETv3r2xY8eOmn4rVAdkujqYOqg1+r/iiJ8vpuKr4L+RXyQXOiwiIiKiOqWzZMmSJULd/P3330d4eDiGDx+O/v37IyEhAZs3b0anTp1gZ2dX5XWjR49GaWkp+vbti379+sHQ0BA7d+5EVFQUhg4dConk/zfXCQ4OxkcffYQOHTrgjTfegEKhwIYNG2BoaAgfH59qx1xUVAohqjcMDWUoLOQDIkQiEdybmaORuT5Onr+Dv+Luo5WjBYy5Qw39i2OFSDMcK0SaEWKsiEQiGDwltxEpBSomjo2NxbBhw7BgwQK8+eabAICSkhIEBgbCxsbmqbPkZ8+eRYcOHdTa9u7di3nz5mHZsmUYMmQIAKC4uBhdunSBr68vvvvuO9W5c+fOxcmTJ3HmzBkYGxtXK+6MjHwoFHX/kWnjFkZCS7yTg7XhlyAvK8e0ga3Rurml0CGRFuBYIdIMxwqRZoQYK2KxCJaWRlUfr8NY1Bw5cgS6uroYNmyYqk0mkyEoKAgxMTG4f/9+ldc+mbwDQI8ePQAAiYmJqrazZ88iOzsbo0ePVjt3zJgxKCgowM8///yib4ME5NzEFIvH+cHKVB+rQi7iRHQyF7cSERFRgydYAh8XFwcnJycYGqo/8MDLywtKpRJxcXHV6u/Bg4fbC5qbm6varly5AgBo3bq12rkeHh4Qi8Wq41R/WZrqYcEbbeHtbIWdJ65h+7GrXNxKREREDZpgCXx6ejpsbGwqtFtbWwPAU2fgK7Nx40bo6OigV69eaveQSqUwMzNTO/dRW3XvQdpJTyrBjKGe6NPRAacu3MGqPRdRUMzFrURERNQwSZ59Su0oLi6Grq5uhXaZTAbgYT28pg4cOIDQ0FBMmTIFDg4Oz7zHo/tU5x6PPK0eqbZZW1evXv9lM32YD1wdLbEu5G98seM8Fr/VEU2shfv3IuFwrBBphmOFSDPaNlYES+D19PQgl1ecJX2UVD9K5J8lOjoaCxcuxOuvv47Zs2dXuEdpaeWrhktKSjS+x+O4iFW7eTmaY+5IH6wLv4T3Vp3B9MGt0crRQuiwqA5xrBBphmOFSDNcxPoYa2vrSktY0tPTAaDS8ponxcfHY9q0aXB1dcWqVaugo6NT4R5yuRzZ2dlq7aWlpcjOztboHlT/uDQ1w+LxfjA3luHr3Rdx+sIdoUMiIiIiqjGCJfBubm64ceMGCgoK1NovXryoOv40t2/fxqRJk2BhYYHvv/8eBgYGFc5xd3cHAFy+fFmt/fLly1AoFKrj1PBYm+njw7G+aN3cAluPJmDn8asoV3BxKxEREdV/giXwAQEBkMvlCAkJUbWVlpYiPDwcbdu2RaNGjQAAd+/eVdsaEng4Sz9x4kSIRCJs3rwZFhaVl0h07NgRZmZm2Llzp1r7rl27YGBggNdee62G3xVpE32ZBLOGeqFXu6Y4EZOCb0JiUVhcJnRYRERERC9EsCex2tra4vr169ixYwcKCgqQkpKCZcuWITExEStWrEDjxo0BANOnT8fy5csxc+ZM1bWjR49GUlISRo0ahdLSUiQkJKj+V1RUpHqKq0QigYGBAX766Sdcv34d+fn52Lp1K/bt24fZs2fjlVdeqXbcfBJr/SISidC6uSXMjWWIiknB+avp8GxuAUP9yhc3U/3HsUKkGY4VIs1o45NYBVvECgDLly/H6tWrsW/fPuTk5MDV1RUbNmyAr6/vU6+Lj48HAGzatKnCscGDB8PHx0f1esyYMdDV1cUPP/yAqKgo2NnZYeHChRg3blzNvhnSaq95N4aNmT6+jbiET7dEY8YQT7g6mD/7QiIiIiItI1Ly0ZXVwl1o6re0rEKsCY3F/awijO3tite8GwsdEtUwjhUizXCsEGmGu9AQCayRuQEWjvWFWzNz/HQ4HrtPXhPkCxkRERHR82ICTy8dAz1dvDvMC9197XH0XDLWhMWiqISLW4mIiKh+YAJPLyUdsRhjerpgbC8XXE7KxOfbY/Agu0josIiIiIieiQk8vdS6trXHnBHeyMotwadbo3EtJfvZFxEREREJiAk8vfQ8HC2wcJwvDGQSrNh1Ab9dShU6JCIiIqIqMYEnAmBnaYiF4/zQ0t4Mmw/FIfR0IhTcoImIiIi0EBN4on8Z6etiznBvvN6mMSL/vIVvwy+huJSLW4mIiEi7MIEneoxER4yxvV0xukdL/H39AZZtP4+MnGKhwyIiIiJSYQJP9ASRSIQefk3x7jBvPMgpwqdbo5F4J0fosIiIiIgAMIEnqpJnc0t8ONYPMl0xvtx5AX9euSd0SERERERM4ImepomVIRaN80PzxibYsP8KIn5O4uJWIiIiEhQTeKJnMDaQYu7INvD3ssOB32/if3svo0ReLnRYRERE9JJiAk+kAYmOGBP6uGFEtxaISUjHFzvOIyuvROiwiIiI6CXEBJ5IQyKRCL3bO2BmkBfuZRbiky1/4UZqrtBhERER0UuGCTxRNbVpYYWFb/hCIhbjyx3n8Vf8faFDIiIiopcIE3ii52BvY4TF4/3g0MgY6/dexv7fbkDJxa1ERERUB5jAEz0nE0Mp3h/lg1da22LvLzfw/f5/UMrFrURERFTLJEIHQFSf6UrEeKufOxpbGSLsdCLSs4sxc6gnzIxkQodGREREDRRn4IlekEgkQt+OzfDOEE/ceZCPT7dE49a9PKHDIiIiogaKCTxRDWnrYo0P3/AFACzbEYPzV9MFjoiIiIgaIibwRDXIoZExPhrvB3trI6wLv4RDf9zk4lYiIiKqUUzgiWqYqZEMH4zyQYdWjRB2JgmbDsZBXqYQOiwiIiJqILiIlagWSHV1MLl/KzS2NEDELzeQnl2EGUM8YWIoFTo0IiIiquc4A09US0QiEfp3dsL0Qa1xOy0Pn26JRsr9fKHDIiIionqOCTxRLfNzs8G8MW1RrlBg6fYY/H39gdAhERERUT3GBJ6oDjjZmWDx+HawtTDA2tBYHDl7m4tbiYiI6LkwgSeqI+bGMswf0xa+rtbYc+o6fjwcj7JyLm4lIiKi6mECT1SHZLo6mDqoNQZ0dsSvsalYGfw38gpLhQ6LiIiI6hEm8ER1TCwSYdCrzTF5QCsk3c3FZ1ujcedBgdBhERERUT3BBJ5IIB1b2WLeGB+UyBX4fFs0LiVlCB0SERER1QNM4IkE5NzYFB+N94OVqT5Wh1zE8ehkLm4lIiKip2ICTyQwCxM9LHijLdq0sMKuE9ew7WgCF7cSERFRlZjAE2kBPakE7wzxRL9OzXD677tYteci8ovkQodFREREWogJPJGWEItEGNrFGZMC3XEtJRtLt0YjNYOLW4mIiEgdE3giLfNKazu8P8oHhSVlWLo1Bv/czBQ6JCIiItIiTOCJtFBLezMsHucHcxMZVu2+iFPnU4QOiYiIiLQEE3giLWVlpo8P3/CFZ3MLbDt2FTuOXUW5gotbiYiIXnZM4Im0mL5MgplDvRDQ3gFR51OwOiQWhcVc3EpERPQyYwJPpOXEYhGGd2uBCX3cEH8rC0u3xSAtq1DosIiIiEggTOCJ6olXvRtj7sg2yCuU47Mt0Yi/lSV0SERERCQAJvBE9YirgzkWjfOFiaEUX+3+Gz9fvCt0SERERFTHmMAT1TM25gZYONYP7s3M8dPheARHXYNCoRQ6LCIiIqojTOCJ6iEDPQlmD/NCD197HPsrGWvCYlFUUiZ0WERERFQHmMAT1VM6YjFG93TB2N6uuJyUic+3xSA9u0josIiIiKiWSYQOgJ7u3L3z2J94BNkl2TCTmWGAcwDa27YVOizSIl19mqCRuT6+i7iMT7dEY8YQT7g0NRM6LCIiIqolnIHXYufuncfO+DBklWRDCSCrJBs748Nw7t55oUMjLdPK0QKLxvvBUE+ClcEX8NulVKFDIiIiolrCBF6L7U88ArlC/aE9coUc4dcOokzBemdSZ2thgEXj/dDS3gybD8Uh5PR1KJRc3EpERNTQsIRGi2WVZFfanifPx/s//xctzJvD3bwlXC1aorGhLUQiUR1HSNrGUE8Xc4Z7Y+eJazj8523cyyjE2/1bQU/KoU5ERNRQ8L/qWsxcZlZpEm+ka4i2Nt6Iz7qKsIwEAICJ1Biu5i3hbtESrhYtYCYzretwSUtIdMQY28sFTawMsfPEVSzbfh6zhnrB0lRP6NCIiIioBoiUSv7GXh0ZGfl1tuf2oxr4x8todMW6GO02VLWQNbM4C/GZ1xGfeRUJWdeRLy8AANgaNvp3dr4FWpo1h56EydvL6HJSBtbvuwxdiQ5mDvGEc5OG/8XO2toY6el5QodBpPU4Vog0I8RYEYtFsLQ0qvI4E/hqqssEHqjeLjQKpQJ38u+pkvnr2UmQK8ogFonhZOIAN4uWcLNwQTNje+iIdersPZCw7j4owDehF5GVV4qJfd3Q0cNW6JBqFZMSIs1wrBBphgl8A1DXCfwjz/PHIy+XIzHnJhKyHs7QJ+fdhRJK6OnowcXc+WFCb94CNgbWrJ9v4PKL5Pg2/BISkrMR+IojBr3qBHED/TdnUkKkGY4VIs0wgW8A6lMC/6T80gJczU5EfOZVxGdeQ0ZxFoCHtfaPknlXi5Ywllb9B0P1V1m5AtuOJuCX2FT4ulpjUr9WkEkb3i8xTEqINMOxQqQZJvANQH1O4B+nVCrxoCgT8VkPk/mErEQUlT18iqe9UWO4WrSAu7kLnM2cINXRrbH7krCUSiWO/5WM3Sevw6GRMWYFecHcWCZ0WDWKSQmRZjhWiDTDBL4BaCgJ/JMUSgVu56UgPvMa4jOvISnnFsqV5ZCIJWhu6gh385Zws2gJe+PGEIv4+ID67uL1B/jf/n+gJ9XBrKFecLIzETqkGsOkhEgzHCtEmmEC3wA01AT+SSXlpbiefUNVbnO34B4AwFBiABeLFqr95630LeosJqpZKen5WBMai5yCUrzVzx3t3RsJHVKNYFJCpBmOFSLNMIFvAF6WBP5JOSV5SMi6ppqhzynNBQBY6Vv+Wz/fEq7mzjDQNRAsRqq+3IJSrIu4hOspORjk74T+nR3r/YJmoccKUX3BsUKkGSbwDcDLmsA/TqlUIq3wPuIyryEh6xquZiWipLwUIojgYGz/73aVLeFk2gy6Yj4rTNvJyxTYciQev1++h/buNpjY1x1S3fq7uFWbxgqRNuNYIdIME/gnlJaW4ptvvsG+ffuQm5sLNzc3zJkzB506dXrqdbGxsQgPD0dsbCyuXr0KuVyOhISECuelpKSge/fulfaxceNGvPbaa9WOmQl8ReWKctzIvY2EzGuIz7qGm7nJUCgVkIp10cKsuSqhb2xoW+9ndxsqpVKJI2dvI/R0IhztjDFzqBfMjOrn4lZtHitE2oRjhUgz2pjACzo9On/+fBw7dgzjxo1Ds2bNEBERgbfffhvbtm2Dj49PldedOXMGISEhcHV1RdOmTZGUlPTU+wwYMAD+/v5qbW5ubjXyHgjQEeughZkTWpg5oR96oaisCNeykhD/b8lN+PWDAABjqdHDUhuLlnC3aAkzWcN/Kmh9IRKJ0KdjMzSyMMDGA1fw6ZZozBrqhWa2xkKHRkRERE8QbAY+NjYWw4YNw4IFC/Dmm28CAEpKShAYGAgbGxvs2LGjymsfPHgAIyMj6OnpYenSpdi6detTZ+Afv8eL4gx89WUVZz+snf83oc+XFwAAbA1sVMl8S7Pm0JPoCRwpAcDttDysCYtFfpEcbwd6wNfVWuiQqqU+jxWiusSxQqSZBjsDX1ZWhqioKOTk5KBr166wtn72f/CPHDkCXV1dDBs2TNUmk8kQFBSEVatW4f79+7Cxsan0Wisrq2rHWFhYCIlEAqlUWu1r6cWY65mhU+N26NS4HRRKBe7m31Ml87/fPYczKb9BLBLD0cQBbv8m9M2Mm0JHXH/rsOszh0bGWDzOD2vDL+HbiEsY2qU5+nZsxvInIiIiLVHtBH758uU4e/YswsLCADysnZ0wYQKio6OhVCphZmaGPXv2wMHB4an9xMXFwcnJCYaGhmrtXl5eUCqViIuLqzKBr65vvvkGy5Ytg0gkgre3N+bOnYt27drVSN9UPWKRGPbGjWFv3Bg9HLpAXi5HUs4tVUJ/+MYJRN44Dj0dGVqaO6t2uGlkYM0Esg6ZGskwb7QPfoyMR9iZJNx9UIA3+7hBV8IvVUREREKrdgL/yy+/4JVXXlG9PnnyJP766y9MmjQJ7u7u+PTTT7FhwwZ89tlnT+0nPT0djRpV3Hf60ez9/fv3qxtaBWKxGP7+/ujZsydsbGxw69YtbN68GRMmTMBPP/0EPz+/avf5tJ8zapu1dcOsR25sawF/PFzzkFeSj3/uX0XsvTjEpsXh0tUrAABLfXN42rrBq5EbPBu5wVSv4Tx4SJt9OLED9kRdxfbD8cjKL8WHE9rD3Fj7S50a6lghqmkcK0Sa0baxUu0E/t69e2jWrJnq9alTp2Bvb4+5c+cCAK5du4YDBw48s5/i4mLo6upWaJfJHu58UVJSUt3QKmjcuDE2b96s1ta3b1/069cPK1euRHBwcLX7ZA187XPWawlnx5YY7DgAD4oyHm5XmXkN55L/xukbfwAAmhjZwe3fp8O2MHOCVIelUbWlm3djmMgk2HTwCuZ8fRqzgrzR1Ea4L7LP8jKNFaIXwbFCpJkGUQMvl8shkfz/ZWfPnlWbkW/atCnS09Of2Y+enh7kcnmF9keJ+6NEvqY1atQI/fr1w549e1BUVAR9ff1auQ/VDCt9S7zaxBKvNukIhVKB5Lw7qodJnUn5DVHJP0Mi0kFzU0fVdpVNjZtALBILHXqD4udmAyszPawJjcXn22Mwpb8H2rSs/loUIiIienHVTuBtbW1x4cIFDB8+HNeuXUNycjJmzZqlOp6RkQEDg2c/jdPa2rrSMplHyX9N1b9Xxs7ODgqFArm5uUzg6xGxSIxmJk3RzKQpejt2Q0l5KRKzb6h2uNmfdAT7k47AUGIAF3Nn1Q43VvqWQofeIDjammDx+HZYGxaLtWGxGNa1BXq3b8q1CURERHWs2gl8v3798N133yEzMxPXrl2DkZERunTpojoeFxf3zAWswMN92Ldt24aCggK1hawXL15UHa8tycnJ0NHRgakp9yGvz2Q6UrSydEUrS1cAQG5pHhIyr6sS+gvplwAAVnoWcP13dt7VvAUMdZ/9BZMqZ24sw7wxbbH5UBz2nLqOuw8KMC7AFRId/uJBRERUV6qdwE+ZMgWpqamIioqCkZERvvzyS5iYPFxQmJeXh5MnT2q053pAQAB++OEHhISEqM4vLS1FeHg42rZtq1rgevfuXRQVFcHZ2bm6oSIzMxMWFhZqbbdu3cKhQ4fg5+cHPT3tX4xHmjORGqOdrQ/a2fpAqVQirTBdlczHpP2N3+6ehQgiNDVuotqu0snUEbpiQZ9nVu/IdHUwdaAH9lsaYP9vN3E/qxDvDPGEsQHXIRAREdWFGn2Qk0KhQEFBAfT09CpdoPqk2bNnIyoqCuPHj4eDgwMiIiJw+fJlbNmyBb6+vgCAsWPH4ty5c2oParpz5w727dsHAPj5559x4cIFzJ49G8DDmftu3boBABYsWIDk5GR07NgRNjY2uH37NoKDg1FWVoYdO3bAw8Oj2u+Ri1jrp3JFOW7mJqu2q7yZexsKpQK6Yl20MHNSbVfZ2MiW9fPVcPZKGjYfioOZkRSzh3mjiZXhsy+qZRwrRJrhWCHSjDYuYq3RBL60tLRaD0oqKSnB6tWrceDAAeTk5MDV1RXvvfee2qLYyhL4s2fPYty4cZX2OXjwYHzxxRcAgIMHDyI4OBjXr19HXl4eTExM0L59e8yYMQMtW7Z8rvfIBL5hKCorxvXsJMT9uyA2rfDhegxjXSO4WrRQ7XBjrmcmcKTaL/FuDtaFXUJpWTmmPUMrWAAAIABJREFUDGgNL2dh1xxwrBBphmOFSDMNIoE/c+YMYmNjMXPmTFXbjh078NVXX6G4uBh9+vTBF198odEMfH3EBL5hyirORnzWdcRnXkVC5nXkyfMBAI0MrFWz8y3NnaEvYdlVZTJzi7EmNBbJ6fkY2a0levjZC7a4lWOFSDMcK0Sa0cYEvtrFv5s3b4al5f/PsCUmJuLzzz9H06ZNYW9vj8jISHh6empUB0+kLcz1zNDJzg+d7PygVCpxt+Ae4v5N5n+/+xfOpPwOsUgMR5OmcDNvCVeLlnAycYCOmE8mBQALEz0seMMXGw9ewa6oa7ibUYAxPV24uJWIiKgWVDuBT0pKUtt1JjIyEjKZDKGhoTAyMsJ//vMf7N27lwk81VsikQhNjOzQxMgOPRy6QK4ow42cW6r95w/fjELkzRPQ05GhpXlzuJo/XBDbyMDmpd5SUSbVwfTBrRHxcxIO/XELaZmFmD7YE0b6DfPXOCIiIqFUO4HPycmBubm56vXvv/+Ojh07wsjo4TR/+/btcebMmZqLkEhgumIJXMyd4WLujAHOASiQF+JqViLiM68iPus6Lj2IAwCYyUzhat5C9UApE6l2PXa5LohFIgzt4gw7SwP8dDgen22NxuwgL9hZCr+4lYiIqKGodgJvbm6Ou3fvAgDy8/Nx6dIlvPfee6rjZWVlKC8vr7kIibSMoa4BfGw84WPjCQB48H/t3XlYXPW9P/D3mRWYYYYBhmWGfU/CMmQnC6RGa2rjUpdf6ha1bapVb6s+3qe1tvfpva21vzZutdpq1KvxF7U1TcSmGjWJBZNo0ixASCABQhJg2Pd9Bub8/hgYIEAcEmAW3q/n+iRz5pw535Peb+bNJ9+lt8UR5oubSnCo7igAwKAKGwrzSUgIiIVSOneWWVyRGo6QAD+8uKMIv9l6FA/elIoFsYFffyERERF9rSkHeJPJhPfeew8JCQnIz8/H4OAgsrOzHe+fP39+RndRJXI3wb6BWGVcjlXG5bCJNlR11uB0SzlKWsuQX30Q+6q+gEyQIlYbjZTAJKQEJiDKP8Lrl6tMiNDil/csxh+3F+G5vxXijmsScdXCCFc3i4iIyONNeRWa8vJybNy4ES0tLQDsyzY+/fTTAABRFLF27VosW7bMcczbcBUamgrLoAUVbedQ0noGpS1lqOmqBQD4yXyRpEtASmACUnRJ0Pu5dunFmdTbP4BXPzyJwopmXLXQiNuvToRUMnM/vLCvEDmHfYXIOe64Cs1lrQPf1taGY8eOwd/fH0uWLHEcb29vxwcffIBly5YhJSXl8lrs5hjg6Up0WrpwuqUMJUMbSrX1twMAgnwC7WE+MAlJunio5d41ZtxmE7E9rwK7D13AghgdfnRTKvx8ZmZyK/sKkXPYV4ic4zUBfi5jgKfpIooiGnoaUdJahtMt5TjTWoG+wT4IEBDpb7APt9ElIk4bDbnUO1Zy+aLQjK2fnIY+wBc/uS0doTq/ab8H+wqRc9hXiJzjVQH+woUL2Lt3L6qqqgAAkZGRWLt2LaKioi6vpR6CAZ5myqBtEOc7qxzLVVZ2XIBNtEEukSMhIHZohZskGNVhHj1+/vSFVry0sxiiKOLB76RhXrTu6y+aAvYVIuewrxA5x2sC/PPPP48tW7aMW21GIpHg/vvvx09+8pOpt9RDMMDTbOkb6ENZ21l7oG8tR113PQBALVc5wvy8wETofAJc3NKpa2jrxR+3F6G+pQd3fTMJOSbjtH02+wqRc9hXiC7tcN0xfFixG239bQhQBuCG+HVYGrZwVu497QF++/bt+MUvfoHMzEz84Ac/QGJiIgCgrKwMr7/+Oo4fP46nnnoKN99885W13E0xwJOrtPW3D1Xny3G6tQwdFvv/P4T4BSNFl4SUwEQk6eLgK/N1cUud09M3gL98WIzisy24ZnEkNlyVAInkyjfCYl8hcg77CtHkDtcdwzulf4fVZnUck0vkuCPlllkJ8dMe4G+++WbI5XJs27YNMtnYVSgHBgZw5513wmq1YseOHZfXYjfHAE/uQBRFmLvrHBNiy1vPwmKzQiJIEO0f6dhMKlYTBalE6urmTmrQZsPf9lXgsyNVSIsLwgM3LoCvcsqr247BvkLkHPYVookN2gbxX1/+zrHQxGg6ZQB+s/LnM96GrwvwU/6mrKiowGOPPTYuvAOATCbDddddh2effXaqH0tEUyAIAozqcBjV4bgqKhtW2wDOtZ9H6VCg331uLz4+twdKqQKJAfGOQB/mFwJBuPIq93SRSiS4/epEhAf5YdtnZ/DU20fx41vTERLgGf+KQERE7m/QNoguaze6rN3otHTZf2/pRqe1C11Drzst3eiydqHL0o3ugZ5JP6u1v20WWz65KQd4uVyOnp7JH6y7uxtyuXesmEHkKeQSGRJ18UjUxeN6rEOPtQdnWiuGVrgpQ3FzCQBAq9A4wnyyLhFapb+LW263JtOIUJ0vXv6gGL956wgevjkNSZGeN7afiIhm3oBtwBHC7b92oXP0r46gbg/kPQO9E36OAAEquR/UCjX85SoYVGFQ6+y//1f1gQmv0ynd47tpykNo7rvvPlRWVmL79u0IDg4e815zczNuueUWxMfH4/XXX5/WhroLDqEhT9Tc2zI0GbYMp1vL0W21/xBuUIU5An1CQByUUoVL21nf0oPntxehqa0X96xLwar08Cl/BvsKkXPYV8hdDAfy4Sr46Cq5/fVIdbzT2o3eSwRytVwFtUI19Ksa/nI11AoV/B2v7b+q5Sqo5H6TrurmdWPg//3vf+Pee++FSqXCLbfcgoSEBAD2HVp37NiB7u5uvPnmm1i8ePGVtdxNMcCTp7OJNlR3mlE6tJlURfs5DNgGIBWkiNNGI1lnD/TRmgiXLFfZ3WfFnz8oxqlzrVi3LAq35sRPaXIr+wqRc9hXaKZYbQOjhqZ0TVwlHw7l1m70DvRN+DkSQQKV3M8ewuUq+CvUI+Fcrra/lqvgr7C/9pP7Tuv3lletQgMA+/btw69//WvU1taOOW4wGPBf//VfWLNmzZQb6ikY4MnbWAatqGivRGmLfbhNVZcZAOAr80WSLh4pQ4Fe7xs0a+PnBwZteHdvGT4/VgNTQjA2XT/f6cmt7CtEzmFfIWdZB632MD5cDR8O5RcNVRkO6H2D/RN+jkSQDIVvlSN8j66Kj66O+yvU8JX5uMW+J16zDjwA2Gw2FBcXo7q6GoB9I6cFCxbgb3/7G7Zu3YqPPvro8lrs5hjgydt1WrpwurXcsaHU8ISdQB+dI8wn6xKgVqhmvC17j1bj3T1lMASr8ONb0xCs/frJrewrRM5hX5m7LIPWcUNVOh0hvMsxtnw4nPcPWib8HIkgGRW+R6rjo8O5Wm4fvmIP5L5utZCCs9wxwF/2em0SiQTp6elIT08fc7y1tRWVlZWX+7FE5GL+CjUWh5qwONQEURTR0NvkqM4fayjCwdrDECAgwt/gCPTx2hjIpdM/eX3togiEBvrizx+ctE9uvSUdCUbttN+HiMiTWQYtjjB+8a8XjyPvtHbDMkkglwrSkfAtVyFYGzj0erg6Pjx0xf6rr8zHIwO5N7iyBZeJyKsJgoBQPz1C/fTIiViBQdsgLnRW25erbCnD3qp8fHbhX5BLZIjXxjomxBrV4dP2z56psUH4xcZFeOH9Ivz+nWO471vzkJUaNi2fTUTkbkRRRP+gZWiIylBVfDiUj6uO24esWEZNtBxNJpE5KuBqhRohfsGjquPjx5H7SBnIPQUDPBE5TSqRIlYbjVhtNL4VezX6BvpR3nbWscLNBxUfARWAWq5Csi7BEegDfXRXdN/wIBV+cc9ivLzzBLbsOgVzcze+kx0HCb9oiMjN2QN5/0WrrIyE89FDVTqHXlsnCeRyiQzqUUNVwlQhQwF9aKUVR/Xc/tpHqmQg91IM8ER02XxkSqQGz0Nq8DwAQFt/O063lDtWuDnaUAgACPENdoT5xIB4+MmnvlGT2leOxzaY8P8+PYN/fnkedc09+MH6+VAq3HenWSLyPqIoom+wf9TQlLHjyDtHra4yfGzANjDhZ8kl8pFVVBRqhKvCHNXxkTHlI0NWlFIFAzkBYIAnomkUoNRiWfgiLAtfBFEUUdtd7wjzX9UdRX7NlxAgIEYTieTARKToEhGrjYJM4txfRTKpBPesS4YhWIW/7ivD09uO4se3pCNQ4zPDT0ZE3soeyPsmrI6PHrIyehnEAXFwws9SSOSOCZ0ahb99YyBHGB8ZRz782tV7b5DncmoVmv/93/91+gMPHjyI/fv3o6Sk5Ioa5q64Cg3R5RmwDaCy/YIj0J/vqIIIEQqpAokBcfYKvS4R4apQpypMRRVN+EvuSSjlUvzHLemIM2gAsK8QOctb+4ooiugd6BsVvscucXjxOPJua/fkgVyqGLsR0PCYccda5KqRSZ4KFRQM5F7JHVehcSrAp6SkTOmmgiAwwE8zb/2LluauHmsvzrRVOFa4aehtAgBoFf6O6nxyYAIClJOvOlPT2IUXthehvduC7PRwFJQ3oaWjH4EaJW7OiUfWAk52JZqMp3yviKKInoHekQr4cBCfYKiKfX3yHgxOEsh9pMqxyxuOmtA5EtRHhq4oZmB1LfI8HhvgDx8+POUbL126dMrXeAIGeKKZ0dzbitLWM44x9N3WHgBAuCrUUZ1PCIiDj0w55rqOHguefvso6lvHbq2tkElwz7dSGOKJJuGq7xWbaBsK5KOHplxcJR+7WZBNtE34WT5Sn5Hq+EUbAY3euXN4J8+ZWO6WvJ/HBngawQBPNPNsog01XbWOzaTK2ysxYBuAVJAiVhvlWH8+yj8CUokUj798AO2ySsgiz0BQ9EG0+GCgKgkBA7H4w4MrXf04RG5lureHt4k29Fh7HePHxwxdGV5hZXjIirUL3daeSQO5r8zHsYrK2Or4+M2C1Ao15E7OnyG6EgzwXoABnmj2WQatONt+zrFcZVVnDQD7l31SQDyOlrRCGlQHQTISCsRBCayVqXhi/Q2IDffnyg1EsIf3d0r/PmaZQrlEjjtSbnGEeJtoQ7e1Z9xa453jhqp0O4K5iIm/F31lvhdVx8eH85FVVlROT2gnmk0M8F6AAZ7I9bos3TjdWobSoeE2LX2tE54n2gTYurVQyqXQqpTQqBSOteOH87yA8cHecWz43IneG349wQ8GI9ePPyaMOjLyGWOPCROdNUFbcPFnCuOvm/D5hIs/ZewTjv6oS//5jD/m3PONacwk149vy0Sffqm2TPj6oudy5s9nwvZN8Gd96eebqG3T9HzOtHfoRh9V7kHvQO+482WCDMF+Qeiy2CvkkwVyP5nvqPA9dhy5I6iPGsIilXCZV/J87hjg+aMuEXkctUKFRaEmLAo1QRRFPPz5Tyc8T5CICNOp0dbZj4bWPjS19cPfT44AtRK+ypFgMTqs2Esaov0/+/+NIo46Z+T16N85PmvUheKody96y/Fh464fc8oExy7+LHF8W0buN6YxE18/QVsmfL5LtGXi9l7i+cQJjl183gTnjHu+sQ8x5vypPt/4c77u+SZ/Bk8yIA4gzE8PdUCsY7WViyd0quV+DOREboIBnog8miAI0CkD0NrfNu49nTIAv1r5YwDAuboO5BWY8dWJejRaBmHUq5CdYcCK1DCofDixjaafKI79YWKi9xyvnfxhYtwPRJf4YWnM74Z++9ThZ9HW3z6uPTplADalbZzwOYjI/XAIzRRxCA2R+3FmXO+w3v4BHC6pR36hGZW1nZDLJFicHIIckwGJEVqOlSevNpW+QkR27jiEhgF+ihjgidzT5ayscb6uE/mFZnx5sg59lkGEB/khx2TEitQwqH1ZlSfvNN2r0BB5OwZ4L8AAT+TeLqev9FsGcbikHnmFZpw1d0AmlWBxsh45JgOSIgNYlSevxO8VIue4Y4DnGHgimvOUCilWZxiwOsOAqoYu5BeYcfBkHb46VY/QQD/kZBiwIi0MGj9uk05ERK7HCvwUsQJP5N6mq6/0WwdxpLQBeYVmlFe3QyoRsChZj5wMA5KjdY7lKIk8Fb9XiJzDCjwRkYdQyqVYmRaOlWnhqGnsQl6hGV8W1+FwSQNCdL7IzjBgZVo4tCpW5YmIaHaxAj9FrMATubeZ7CsW6yCOnm5EXqEZZ6raIJUIyEwMRo7JiHkxrMqTZ+H3CpFzWIEnIvJgCrkUWalhyEoNg7mpG/mFZhwsrsOR040I1vogx2Svygeola5uKhEReTFW4KeIFXgi9zbbfcU6MIijZxqRX2BG6YU2SAQBpsRg5JgMWBATCImEVXlyT/xeIXIOK/BERF5GLpNi+fwwLJ8fhrqWHuQXmrG/qBbHzjQiSOOD1RnhWJ1ugM6fVXkiIpoerMBPESvwRO7NHfrKwKANx8uakFdQg1PnWiEIQEa8vSqfFhfEqjy5BXfoK0SegBV4IqI5QCaVYElKCJakhKChtQf5hbXYf6IWBeVN0PkrsTo9HNkZBgRqfFzdVCIi8kCswE8RK/BE7s1d+8rAoA2F5U3IKzDjZGULIABpcUHIMRmQHh8EqUTi6ibSHOOufYXI3bACT0Q0R8mkEixKDsGi5BA0tvXiiyIzviiqxYt/P4EAtQKr0g3ITg9HcICvq5tKRERujhX4KWIFnsi9eVJfGRi0oaiiGfmFZpyoaAYALIgLRE6GERkJQZBJWZWnmeNJfYXIlViBJyIiB5lUgoVJeixM0qOpvRf7i2rxRVEtXtp5AlqVAqvSw7E6w4AQVuWJiGgUVuCniBV4Ivfm6X1l0GbDibMtyC8wo7CiCaIILIjRIcdkhCkxmFV5mjae3leIZgsr8EREdElSiQSmhGCYEoLR0tE3VJU34+UPiqHxk2NlWjiyTQaE6vxc3VQiInIRVuCniBV4IvfmjX3FZhNRXNmCvIIaFJY3wyaKmBetQ47JgMxEPeQyVuVp6ryxrxDNBFbgiYhoyiQSAenxQUiPD0JrZz/2n6hFfoEZf8k9CbWvHCvTwpCdYUB4kMrVTSUiolnACvwUsQJP5N7mSl+xiSJOnWtBXoEZBWVNGLSJSI4MQI7JgEXJeshlUlc3kdzcXOkrRFeKFXgiIpoWEkFAamwQUmOD0N41VJUvNOPVf5yC6jMZVqTax8obg1mVJyLyNgzwREQeTqtW4ttZMfjW8miUnm9FXoEZ+45V47MjVUiM0CLHZMDi5BAo5KzKExF5AwZ4IiIvIREEzI8JxPyYQHR0W3CwuA55BTV4bVcJ3vmsDFmpYcgxGRChn/yfZYmIyP0xwBMReSGNSoF1y6Jw7dJInL7QhrxCM/IKarD3aDXijRrkZBixZF4IlKzKExF5HAZ4IiIvJggCUqJ1SInWobMnEQeL65BfaMYbH5Xg3b1nsHxBGHIyDIgK9Xd1U4mIyEkuDfAWiwUvvPACcnNz0dHRgZSUFDz66KPIysq65HVFRUXYsWMHioqKcObMGVitVpw+fXrCc202G15//XW8++67aGxsRExMDH70ox/huuuum4lHIiJyW/5+Cly7NArfXBKJsup25BXU4IvCWnx+rAax4RrkmAxYOi8EPgrWdoiI3JlLd//42c9+hrfeegs33HADnnzySUgkEmzatAnHjx+/5HV5eXl4//33AQCRkZGXPPe5557D5s2bsWrVKvzyl7+EwWDAo48+it27d0/bcxAReRJBEJAUGYBN1y/Asw+vxO1rE9FvHcSbH5fi0T8dwNbdpThfx+UFiYjclcvWgS8qKsJtt92GJ554Avfeey8AoL+/H+vXr0dISAi2bds26bVNTU1Qq9Xw8fHBU089ha1bt05Yga+vr8fatWtx++2348knnwQAiKKIu+66C7W1tdizZw8kkqn9DMN14IncG/vK5RFFERU1HcgrqMHh0gZYB2yIDvNHjsmAZfNC4atkVd7bsK8QOccd14F3WQV+9+7dkMvluO222xzHlEolbr31Vhw9ehQNDQ2TXhscHAwfH5+vvceePXtgtVpxxx13OI4JgoDbb78dNTU1KCoqurKHICLyEoIgICFCi++vn4/nHl6JO69JwuCgDVt3n8ZjfzqANz8uQWVtB7j3HxGR67mspFJSUoLY2FioVGM3GUlPT4coiigpKUFISMgV30OtViM2NnbcPQDg1KlTMJlMV3QPIiJv4+cjx9pFEbhqoRFnazuQV2DGV6fqkV9Yi6gQNbJNBiyfHwY/H1bliYhcwWV/+zY2NiI0NHTccb1eDwCXrMBP5R7BwcEzeg8iIm8lCALiDVrEG7T47lWJOHSqDnkFZvy/T8/gb5+XY2lKKHJMBsQZNBAEwdXNJSKaM1wW4Pv6+iCXy8cdVyqVAOzj4afjHgqFYlrvcanxSDNNr+cyb0TOYF+ZGdGROtz2zRSUV7fhk6/OI+9YNfafqEVMuAbXLo/GmkWRUPuO/3ud3Bf7CpFz3K2vuCzA+/j4wGq1jjs+HKqHQ/aV3sNisUzrPTiJlci9sa/MvAAfGTasiccNWdE4XFKPvAIzXtl5Am/84ySWpIQgx2RAglHLqrybY18hco47TmJ1WYDX6/UTDmFpbGwEgCse/z58jyNHjszoPYiI5ipfpQw5JiNyTEacr+tEXqEZX52sw8HiOhiCVcjOMGBFahir8kRE08xlq9CkpKSgsrIS3d3dY44XFhY63r9S8+bNQ1dXFyorKye8x7x58674HkREBESH+WPjtcl49uGVuO9bKfBRSPHe3jI89qcDePUfJ3H6QitXsCEimiYuC/Dr1q2D1Wp1bMgE2Hdm3bFjBxYuXOiY4Go2m1FRUXFZ91i7di3kcjneeecdxzFRFPHee+/BYDAgIyPjyh6CiIjG8FHIsDrDgF9sXIxf3bcE2RnhKCxvwv995zie3HIIuw9dQGfP+KGNRETkPJcNocnIyMC6deuwefNmNDY2IioqCjt37oTZbMbTTz/tOO+nP/0pDh8+PGajppqaGuTm5gIATpw4AQB4+eWXAdgr91dddRUAICwsDBs3bsQbb7yB/v5+pKWlYc+ePThy5Aiee+65KW/iREREzosK9cdd30zGbd9IwJHSBuQVmPG3z8uxI78CC5P0yDEZkRIVwLHyRERT5NJFfH//+9/j+eefR25uLtrb25GcnIxXX30VixYtuuR11dXVeOGFF8YcG379ne98xxHgAeDxxx+HVqvFX//6V+zYsQOxsbF45plncN11103/AxER0ThKuRQr08KxMi0c1Y1dyC8w42BxHQ6XNCBU54tskwErU8OhUY1fNYyIiMYTRA5KnBKuQkPk3thXPIPFOoijpxuRV1CDM9XtkEoEZCbpkWMyYF60DhJW5Wcc+wqRc7gKDREREQCFXIqs1DBkpYbB3NSN/EIzDpyoxZHSBugDfJCdYcCqtHBo1Ve+pDARkbdhBX6KWIEncm/sK57LOjCIo2cakV9gRumFNkglAkwJwcgxGTA/NpBV+WnGvkLkHFbgiYiIJiGXSbF8fhiWzw9DXUsP8gvN2F9Ui6NnGhGk8UF2RjhWpRug82dVnojmNlbgp4gVeCL3xr7iXawDNhwva0RegRkl51shEQRkJAQhx2RAamwQJBJW5S8X+wqRc1iBJyIimgK5TIKl80KxdF4o6lvtVfkDRbU4XtaEQI0Sq9MNWJ0ejkCNj6ubSkQ0a1iBnyJW4IncG/uK9xsYtKGgrAl5hWacrGyBIADpcUHIMRmRFh8IKff4cAr7CpFzWIEnIiK6QjKpBItTQrA4JQSNbb34osiMLwprUfj3IgSoFfaqfEY4grW+rm4qEdGMYAV+iliBJ3Jv7Ctz08CgDUUVzcgrMKP4bDMAIDUuCNkZBmQkBEEmZVX+YuwrRM5hBZ6IiGgGyKQSLEzSY2GSHk3tvdhfVIsvimrx0s4T0KoUWJUejuwMA/QBrMoTkedjBX6KWIEncm/sKzRs0GbDiYoW5BXUoOhsMyAC82MDkZNhgCkxeM5X5dlXiJzDCjwREdEskUokMCUGw5QYjJaOPuwvqkV+kRkvf1AMjZ8cK4eq8qE6P1c3lYhoSliBnyJW4IncG/sKXYrNJqK40j5WvrC8GTZRxLxoHXJMBmQm6iGXzZ2qPPsKkXNYgSciInIhiURAenww0uOD0drZj/0napFfYMZfck9C7SvHqrRwZJsMCAtkVZ6I3Bcr8FPECjyRe2NfoamyiSJOVbYgr8CMgvImDNpEpEQFINtkwKIkPeQyqaubOCPYV4icwwo8ERGRm5EIAlLjgpAaF4T2rqGqfKEZr354CmpfOVakhiE7wwBDsMrVTSUiAsAAT0RE5KBVK/HtrBh8a3k0Ss63Iq/AjL1Hq/Hpv6uQFKFFjsmIRcl6KOTeWZUnIs/AAE9ERHQRiSBgQUwgFsQEoqPbggPFtcgrMGPLrlPY9pnMXpU3GRChn/yfuImIZgoDPBER0SVoVAp8a1k01i2NQumFNuQV1OBfBTXYc7QaCUYtsjMMWDIvBEpW5YloljDAExEROUEQBMyL1mFetA6dPRYcLK5DXoEZb3xUgnf3liFrQShyTEZEhrAqT0QziwGeiIhoivz9FLh2aRS+uSQSZ6rakFdoRn5hLfYdq0GcQYOcDAOWzguFUsGqPBFNPy4jOUVcRpLIvbGvkKt09VrxZXEd8grNMDd1w0chxfIFYcjJMCA6zN/VzRuHfYXIOVxGkoiIyEupfeW4Zkkkrl4cgfKaduQVmHHgRC3+dbwGMWH+yDYZsGxeKHyV/OoloivDCvwUsQJP5N7YV8iddPdZ8dXJeuQV1KC6sRtKuRTL5ocix2RATJg/BEFwWdvYV4icwwo8ERHRHKLykWPtoghctdCIs+YO5BWa8dWpOuQXmhEVqkaOyYjl81mVJ6KpYQV+iliBJ3Jv7Cvk7nr6BnDolH0FmwsNXVDIJVg6z16VjwvXzFpVnn2FyDmswBMREc1xfj4yfGNhBNZkGnGurhN5BWYcOlWP/UW1iNCrkWMyIGs4zzheAAAaFElEQVRBKPx85K5uKhG5KVbgp4gVeCL3xr5Cnqi3fwCHSuqRV2DG+bpOKGQSLEkJQY7JiHjjzFTl2VeInMMKPBEREY3jq5RhjcmINSYjztd12sfKn6zDgeI6GINVyM4wICs1DGpfVuWJiBX4KWMFnsi9sa+Qt+izDOBwSQPyCsyorO2ATCrBkhQ9ckxGJEZor7gqz75C5BxW4ImIiMgpPgoZsjMMyM4w4EJ9J/ILzfjyZB2+PFmP8CA/ZGcYsCI1DP5+Clc3lYhmGSvwU8QKPJF7Y18hb9ZvGcS/SxuQV1iDipoOyKQCFiWHICfDgOSogClV5dlXiJzDCjwRERFdNqVCilXp4ViVHo7qxi7kF5hxsLgOh07VI1Tni2yTAStTw6FRsSpP5M1YgZ8iVuCJ3Bv7Cs01Fusgjpy2j5Uvq26HVCJgYZIeOSYDUqJ1kExSlWdfIXIOK/BEREQ0rRRyKVakhmNFajhqmrrxRaEZB07U4t+lDdAH+CA7w4BVaeHQqpUAgC9P1mFHXgVaOvoRqFHi5px4ZC0Ic/FTENFUsAI/RazAE7k39hUiwDowiKOnG5FXYMbpqjZIJQJMicEI0flg75EaWAZsjnMVMgnu+VYKQzzRJFiBJyIiohknl0mxfEEYli8IQ21zN74orMX+E7U4eto67lzLgA078ioY4Ik8iMTVDSAiIqKZEx6kwv+5KgHPPLRy0nOaO/pRXNmM3v6BWWwZEV0uVuCJiIjmALlMgiCNEs0d/RO+/+xfCyEAMOrVSIjQIsGoQYJRC32A7xVvGkVE04sBnoiIaI64OSceb31cOm4M/O1XJyI4wBcV1e0or2nHoVN1+NfxGgCAxk+OeKN2KNRrERPmD7lM6qpHICIwwBMREc0Zw+PcJ1uFZkFMIADAZhNhbu5G+VCgL69px/GyJgCATCogOswfCUat47/hFW6IaHZwFZop4io0RO6NfYXIOVPtKx3dFlTUjAT6ytpODAzaK/nBWh9HhT7BqEWEXg2JhMNuyDtwFRoiIiLySBqVAplJemQm6QEA1gEbLtR3OgJ9yblWfHWyHoB9x9h4g8YR6OMMGvj5yF3ZfCKvwgBPREREUyaXSRBv1CLeqMW1AERRRHN7nyPQl9e04x8Hz0EUAQGAQa8aGXYToUUIJ8cSXTYGeCIiIrpigiAgOMAXwQG+WD40pr63fwCVtR2OQH+4pAF5BWYAgL+f3BHo44cmxyrknBxL5AwGeCIiIpoRvkoZ5scEYv7w5FhRRG1T96gqfYdjcqxUMnZybLxRC50/J8cSTYQBnoiIiGaFRBBg1Kth1KuRYzICADp6RibHVlS34/PjNfj031UAhibHDoX5BKMWESEqSCXcg5KIAZ6IiIhcRuOnQGaiHpmJ9smxA4M2XKjvclTpSy+04qtTQ5Nj5VLEGTSIN2qRGKFFPCfH0hzFAE9ERERuQyaVIM6gQZxBg28uibRPju3oG6rQ28fTf/TlediGVsE2BqscFfqECC1CdZwcS96PAZ6IiIjcliAICNb6Iljri+Xz7ZNj+ywDqKwdWsKyuh1HShuQX2ifHKv2lQ8Nu9EgMSKAk2PJKzHAExERkUfxUcgwL1qHedE6AEOTY5t77GPph3aPLSgfmRwbFervqNAncHIseQEGeCIiIvJoEkGAMVgFY7AK2RkGAEBnjwUV5g5HoP9XQQ0+O2KfHBukUTqG3SRGBHByLHkcBngiIiLyOv5+CpgSgmFKCAZgnxxb1dDlCPRl1fZ16QFAIZcgLlzjqNDHGbRQ+3JyLLkvBngiIiLyejKpBLHhGsSGa3DNkkgAQMvQ5Njy6naU1bTjoy8vOCbHhgf5jdk5NizQj5NjyW0wwBMREdGcFKjxwVKND5bOCwUA9FsGx+wce+xMI74oqgUAqHxkY8bRx4RroOTkWHIRBngiIiIiAEqFFCnROqSMmhxb39KDsqFhNxU17SisaAZgnxwbGaIeE+oDNT6ubD7NIQzwRERERBOQCALCg1QIDxqZHNvVax3ZObamHfmFZuw5Wg0ACNQox+wcGxmihkzKybE0/RjgiYiIiJyk9pUjIyEYGaMmx1Y3dqGsut0R7B2TY2X2cffDFfp4IyfH0vRggCciIiK6TDKpBDFhGsSEaXDN4osmxw5V6XcfuoBB28jkWMfOsUYtwoL8IOHkWJoilwZ4i8WCF154Abm5uejo6EBKSgoeffRRZGVlfe219fX1+O1vf4sDBw7AZrNh+fLleOKJJxAZGTnmvOTk5Amv/9WvfoXbb799Wp6DiIiIaNi4ybHWQZwbnhxb3Y7jZxqxf9Tk2Pih6nyiUYvYcA2UCk6OpUtzaYD/2c9+hk8//RQbN25EdHQ0du7ciU2bNuHtt99GZmbmpNd1d3dj48aN6O7uxgMPPACZTIY333wTGzduxAcffACtVjvm/FWrVuGGG24YcywjI2NGnomIiIhoNKVciuQoHZKj7JNjRVFEXUuPo0JfXtOBoqHJsRJBQGSoemQJS6MWgRoll7CkMVwW4IuKivDPf/4TTzzxBO69914AwE033YT169dj8+bN2LZt26TXvvPOOzh//jx27NiB+fPnAwBWr16N66+/Hm+++SZ+8pOfjDk/Li4ON95444w9CxEREZGzhFGTY1enj0yOPWtud1TpvygyY+/Q5Fid/+idYzk5llwY4Hfv3g25XI7bbrvNcUypVOLWW2/Fc889h4aGBoSEhEx47SeffAKTyeQI7wAQHx+PrKwsfPzxx+MCPAD09fVBEAQolcrpfxgiIiKiK6D2lSM9Phjp8fbJsYM2G6obuh1j6cur23GkdGRybEy4xlGhjzdq4O+ncGXzaZa5LMCXlJQgNjYWKpVqzPH09HSIooiSkpIJA7zNZsPp06exYcOGce+lpaXhwIED6O3tha+vr+P49u3b8fbbb0MURSQlJeHHP/4xrrnmmul/KCIiIqJpIJVIEB3mj+gwf6xdFAHAPjm2wtyB8qF16T85fAEfDU2ODQ30Q4JRg8SIAMQbtQjn5Fiv5rIA39jYiNDQ0HHH9Xo9AKChoWHC69ra2mCxWBznXXytKIpobGxEVFQUACAzMxPXXXcdIiIiUFtbi61bt+Lhhx/GM888g/Xr10/jExERERHNnECNDwI1PliSYi9wWqyDOFfX6ajQF5Y348CJOgCAn1I2NOzGXqmPNWjgo+Dig97CZf9L9vX1QS4fvxbq8BCX/v7+Ca8bPq5QjP+nouFr+/r6HMfee++9Med85zvfwfr16/GHP/wB3/72t6c8KSQoSD2l86eTXu/vsnsTeRL2FSLnsK94PqMhACsX2lfgE0UR5qZulFS2oPR8C0rOtWDnF5UAAIkAxBi0mBcTiJSYQMyPCYRe58vJsU5yt77isgDv4+MDq9U67vhwQJ9srPrwcYvFMum1Pj6Tb2Xs5+eH7373u3jmmWdw9uxZxMfHT6ndzc1dsA39c9Vs0uv90djYOev3JfI07CtEzmFf8U4KABmxOmTE6gDEo7vPirOjht3sOXwB/zxgD/UBasXIOPoILaJD/Tk5dgKu6CsSiXDJorHLArxer59wmExjYyMATDqBNSAgAAqFwnHexdcKgjDh8JrRwsPDAQDt7e1TbTYRERGRx1D5yJEWF4S0uCAAYyfHDu8ce+S0PVPJZRLEhPmP2TlWw8mxbsllAT4lJQVvv/02uru7x0xkLSwsdLw/EYlEgqSkJBQXF497r6ioCNHR0WMmsE6kqqoKABAYGHi5zSciIiLyOBNNjm3t7HeE+Yqadnx6uAof2y4AAEJ1vo4KfYJRC0OwipNj3YDLAvy6devwxhtv4P3333esA2+xWLBjxw4sXLjQMcHVbDajt7d3zFCXa6+9Fs8++yxOnTrlWEry7Nmz+Oqrr7Bp0ybHeS0tLeNCemtrK9555x1EREQgJiZmZh+SiIiIyM3p/JVYnBKCxRdNjh0O9UVnm3Gg2D451lcpQ7xhaAnLCPvOsb5KTo6dbS77E8/IyMC6deuwefNmx6oxO3fuhNlsxtNPP+0476c//SkOHz6M06dPO47dcccdeP/99/HDH/4Q9913H6RSKd58803o9XrHDwMAsG3bNuzduxdr1qyBwWBAfX09/vrXv6KlpQUvvfTSbD4uERERkUdQyKVIigxAUmQAAPvk2Ia2Xsc4+vKaduTur4QIQBCASL3aUaFPMGoRrPXh5NgZ5tIfmX7/+9/j+eefR25uLtrb25GcnIxXX30VixYtuuR1arUab7/9Nn7729/i5Zdfhs1mw7Jly/Dkk09Cp9M5zsvMzMSxY8fw/vvvo729HX5+fjCZTLj//vu/9h5EREREZN85NlTnh1CdH1am2ecR9gxPjh0K9AeL6/D5sRoAgFalcFToE4xaRIX6Qy7j5NjpJIiiOPtLqngwrkJD5N7YV4icw75C08lmE1Hd2IWKmnaUDa1L39RuX9ZbJpUgJtx/1M6xWmhVnjM5lqvQEBEREZHXkUgERIX6IyrUH99YaJ8c29Y1Mjm2vKYde45UYfch++TYkABfR4XeMTlWwmE3zmKAJyIiIqJpF6BWYlFyCBYl2yfHWgcGcb6uC+U17SirbkPx2WYcdEyOlSLOMBLo4wycHHsp/JMhIiIiohknl0ntVfcILdYti4Ioimhs6x2q0Ns3m/pweHIsAKNejcSIkY2m9Jwc68AAT0RERESzThAEhOj8EKLzw4rU4cmxA6is7UBZdRsqatrx5ck6fH7cPjlWoxrZOTbBqEV0mBpymdSVj+AyDPBERERE5Bb8fGRYEBuIBbH2fXxsNhE1TfadY8ur7RtNHTtj3zlWJhUQHeaPRGMA4o1aJBg10KqVrmz+rGGAJyIiIiK3JJEIiAxRIzJEjW9kGgEA7d0WR5gvr2nHnqNV2H3YPjlWH+AzZrWbCL3aKyfHMsATERERkcfQqhRYlKzHomQ9AMA6YMP5+k5HqD95rhVfnqwHAPgopIg3aOwV+ggt4sK18PPx/Pjr+U9ARERERHOWXCZxVN0B+86xTe19Y3aO/cfBcxDF4cmxKkeFPiFCi5AA3wknx355sg478irQ0tGPQI0SN+fEI2tB2Cw/3cQY4ImIiIjIawiCAH2AL/QBvshKtQfu3v4BnK3tQMVQqD9UUo9/FZgBAP5+8jE7x8aE+ePI6Ua89XEpLAM2AEBzRz/e+rgUANwixDPAExEREZFX81XKsCAmEAtiRibHmocnxw79d7ysCQAglQgQBGBgUBzzGZYBG3bkVTDAExERERHNNolEQESIGhEhaqwZmhzb0W1xTIz9eGjH2Is1d/TPZjMnJXF1A4iIiIiIXE2jUiAzSY/bvpGAIM3Ey1FOdny2McATEREREY1yc048FLKxMVkhk+DmnHgXtWgsDqEhIiIiIhpleJw7V6EhIiIiIvIQWQvCkLUgDHq9PxobO13dnDE4hIaIiIiIyIMwwBMREREReRAGeCIiIiIiD8IAT0RERETkQRjgiYiIiIg8CAM8EREREZEHYYAnIiIiIvIgDPBERERERB6EAZ6IiIiIyINwJ9YpkkiEOXlvIk/CvkLkHPYVIufMdl/5uvsJoiiKs9QWIiIiIiK6QhxCQ0RERETkQRjgiYiIiIg8CAM8EREREZEHYYAnIiIiIvIgDPBERERERB6EAZ6IiIiIyIMwwBMREREReRAGeCIiIiIiD8IAT0RERETkQRjgiYiIiIg8iMzVDaCJNTQ0YOvWrSgsLERxcTF6enqwdetWLFu2zNVNI3IrRUVF2LlzJw4dOgSz2YyAgABkZmbikUceQXR0tKubR+Q2Tpw4gb/85S84deoUmpub4e/vj5SUFDz00ENYuHChq5tH5La2bNmCzZs3IyUlBbm5ua5uDgAGeLdVWVmJLVu2IDo6GsnJyTh+/Lirm0Tkll577TUcO3YM69atQ3JyMhobG7Ft2zbcdNNN2L59O+Lj413dRCK3UFVVhcHBQdx2223Q6/Xo7OzEP/7xD9x1113YsmULVq5c6eomErmdxsZG/PnPf4afn5+rmzKGIIqi6OpG0HhdXV2wWq3Q6XTYs2cPHnroIVbgiSZw7NgxpKamQqFQOI6dO3cO119/Pb797W/jd7/7nQtbR+Teent7cfXVVyM1NRWvvPKKq5tD5HZ+9rOfwWw2QxRFdHR0uE0FnmPg3ZRarYZOp3N1M4jc3sKFC8eEdwCIiYlBYmIiKioqXNQqIs/g6+uLwMBAdHR0uLopRG6nqKgIH374IZ544glXN2UcBngi8jqiKKKpqYk/BBNNoKurCy0tLTh79iyeffZZnDlzBllZWa5uFpFbEUURv/71r3HTTTdh3rx5rm7OOBwDT0Re58MPP0R9fT0effRRVzeFyO38/Oc/xyeffAIAkMvl+O53v4sHHnjAxa0ici8ffPABysvL8dJLL7m6KRNigCcir1JRUYH/+Z//waJFi3DjjTe6ujlEbuehhx7Chg0bUFdXh9zcXFgsFlit1nFD0Yjmqq6uLjzzzDP44Q9/iJCQEFc3Z0IcQkNEXqOxsRH3338/tFotXnjhBUgk/CuO6GLJyclYuXIlbrnlFrz++us4efKkW47xJXKVP//5z5DL5bjvvvtc3ZRJ8duNiLxCZ2cnNm3ahM7OTrz22mvQ6/WubhKR25PL5Vi7di0+/fRT9PX1ubo5RC7X0NCAt956C3fccQeamppQXV2N6upq9Pf3w2q1orq6Gu3t7a5uJofQEJHn6+/vxwMPPIBz587hzTffRFxcnKubROQx+vr6IIoiuru74ePj4+rmELlUc3MzrFYrNm/ejM2bN497f+3atdi0aRMef/xxF7RuBAM8EXm0wcFBPPLIIygoKMDLL78Mk8nk6iYRuaWWlhYEBgaOOdbV1YVPPvkE4eHhCAoKclHLiNxHRETEhBNXn3/+efT09ODnP/85YmJiZr9hF2GAd2Mvv/wyADjWss7NzcXRo0eh0Whw1113ubJpRG7jd7/7Hfbt24dvfOMbaGtrG7PJhkqlwtVXX+3C1hG5j0ceeQRKpRKZmZnQ6/Wora3Fjh07UFdXh2effdbVzSNyC/7+/hN+b7z11luQSqVu853CnVjdWHJy8oTHjUYj9u3bN8utIXJPd999Nw4fPjzhe+wrRCO2b9+O3NxclJeXo6OjA/7+/jCZTPje976HpUuXurp5RG7t7rvvdqudWBngiYiIiIg8CFehISIiIiLyIAzwREREREQehAGeiIiIiMiDMMATEREREXkQBngiIiIiIg/CAE9ERERE5EEY4ImIiIiIPAgDPBERub27774bV111laubQUTkFmSubgAREbnGoUOHsHHjxknfl0qlOHXq1Cy2iIiInMEAT0Q0x61fvx7Z2dnjjksk/EdaIiJ3xABPRDTHzZ8/HzfeeKOrm0FERE5ieYWIiC6puroaycnJePHFF7Fr1y5cf/31SEtLw5o1a/Diiy9iYGBg3DWlpaV46KGHsGzZMqSlpeG6667Dli1bMDg4OO7cxsZG/OY3v8HatWuRmpqKrKws3HfffThw4MC4c+vr6/HYY49hyZIlyMjIwPe//31UVlbOyHMTEbkrVuCJiOa43t5etLS0jDuuUCigVqsdr/ft24eqqirceeedCA4Oxr59+/CnP/0JZrMZTz/9tOO8EydO4O6774ZMJnOc+/nnn2Pz5s0oLS3FM8884zi3uroat99+O5qbm3HjjTciNTUVvb29KCwsxMGDB7Fy5UrHuT09PbjrrruQkZGBRx99FNXV1di6dSsefPBB7Nq1C1KpdIb+hIiI3AsDPBHRHPfiiy/ixRdfHHd8zZo1eOWVVxyvS0tLsX37dixYsAAAcNddd+Hhhx/Gjh07sGHDBphMJgDAU089BYvFgvfeew8pKSmOcx955BHs2rULt956K7KysgAA//3f/42Ghga89tprWL169Zj722y2Ma9bW1vx/e9/H5s2bXIcCwwMxB/+8AccPHhw3PVERN6KAZ6IaI7bsGED1q1bN+54YGDgmNcrVqxwhHcAEAQBP/jBD7Bnzx589tlnMJlMaG5uxvHjx3HNNdc4wvvwuT/60Y+we/dufPbZZ8jKykJbWxu++OILrF69esLwffEkWolEMm7VnOXLlwMAzp8/zwBPRHMGAzwR0RwXHR2NFStWfO158fHx444lJCQAAKqqqgDYh8SMPj5aXFwcJBKJ49wLFy5AFEXMnz/fqXaGhIRAqVSOORYQEAAAaGtrc+oziIi8ASexEhGRR7jUGHdRFGexJURErsUAT0RETqmoqBh3rLy8HAAQGRkJAIiIiBhzfLSzZ8/CZrM5zo2KioIgCCgpKZmpJhMReSUGeCIicsrBgwdx8uRJx2tRFPHaa68BAK6++moAQFBQEDIzM/H555/jzJkzY8599dVXAQDXXHMNAPvwl+zsbOTn5+PgwYPj7seqOhHRxDgGnohojjt16hRyc3MnfG84mANASkoK7rnnHtx5553Q6/XYu3cvDh48iBtvvBGZmZmO85588kncfffduPPOO3HHHXdAr9fj888/x/79+7F+/XrHCjQA8Mtf/hKnTp3Cpk2bcNNNN2HBggXo7+9HYWEhjEYj/vM//3PmHpyIyEMxwBMRzXG7du3Crl27Jnzv008/dYw9v+qqqxAbG4tXXnkFlZWVCAoKwoMPPogHH3xwzDVpaWl477338Mc//hHvvvsuenp6EBkZiccffxzf+973xpwbGRmJv//973jppZeQn5+P3NxcaDQapKSkYMOGDTPzwEREHk4Q+W+URER0CdXV1Vi7di0efvhh/Md//Ierm0NENOdxDDwRERERkQdhgCciIiIi8iAM8EREREREHoRj4ImIiIiIPAgr8EREREREHoQBnoiIiIjIgzDAExERERF5EAZ4IiIiIiIPwgBPRERERORBGOCJiIiIiDzI/wfhUigww6OHyQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrc3c9ZK8Iid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "05cf3341-e7de-4d7a-b72e-c8a6a72460a6"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0:05:06</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:05:04</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0:05:04</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0:05:04</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.24         0.16           0.95       0:05:06         0:00:14\n",
              "2               0.13         0.12           0.97       0:05:04         0:00:14\n",
              "3               0.07         0.12           0.97       0:05:04         0:00:14\n",
              "4               0.04         0.14           0.98       0:05:04         0:00:14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlAf38u8J2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010f020a-136f-4477-e558-177079a5e8bb"
      },
      "source": [
        "evaluation(y_val_non_hostile, y_pred_val_non_hostile)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine Grained Accuracy = 0.9765721331689272\n",
            "\n",
            "\n",
            "Fine Grained Metrics\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       376\n",
            "           1       0.98      0.97      0.98       435\n",
            "\n",
            "    accuracy                           0.98       811\n",
            "   macro avg       0.98      0.98      0.98       811\n",
            "weighted avg       0.98      0.98      0.98       811\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl1HHAKb8NxS"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_val_non_hostile, index = val_data.index, columns=['non-hostile'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_val_non_hostile.csv')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsO3V06CJgI6"
      },
      "source": [
        "torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, 'non_hostile_val.tar')\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8pWsVLw9ymN"
      },
      "source": [
        "**Training for Non Hostile Class (Using Train +Val Data and Test Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQkmggpPPVDZ"
      },
      "source": [
        "train_val_labels_non_hostile = y_train_val_non_hostile"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrOZjkhYBJUj",
        "outputId": "d464b4be-b1d7-4983-8c04-8ed9347e0b26"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_val_sentences)\n",
        "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_non_hostile)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2SLITzKBB0A"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_val_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l975nE0w-lq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e8428d-8728-4d46-b62d-c61390b4bca4"
      },
      "source": [
        "training_stats, y_pred_test_non_hostile = train_fn_test(train_val_dataloader, test_dataloader)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    818.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    818.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    818.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    818.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    818.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    818.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    818.    Elapsed: 0:01:59.\n",
            "  Batch   320  of    818.    Elapsed: 0:02:16.\n",
            "  Batch   360  of    818.    Elapsed: 0:02:33.\n",
            "  Batch   400  of    818.    Elapsed: 0:02:50.\n",
            "  Batch   440  of    818.    Elapsed: 0:03:07.\n",
            "  Batch   480  of    818.    Elapsed: 0:03:24.\n",
            "  Batch   520  of    818.    Elapsed: 0:03:41.\n",
            "  Batch   560  of    818.    Elapsed: 0:03:58.\n",
            "  Batch   600  of    818.    Elapsed: 0:04:15.\n",
            "  Batch   640  of    818.    Elapsed: 0:04:32.\n",
            "  Batch   680  of    818.    Elapsed: 0:04:49.\n",
            "  Batch   720  of    818.    Elapsed: 0:05:06.\n",
            "  Batch   760  of    818.    Elapsed: 0:05:23.\n",
            "  Batch   800  of    818.    Elapsed: 0:05:40.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:29\n",
            "[{'epoch': 1, 'Training Loss': 0.07989396572749977, 'Training Time': '0:05:48', 'Validation Time': '0:00:29'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    818.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    818.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    818.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    818.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    818.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    818.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    818.    Elapsed: 0:01:59.\n",
            "  Batch   320  of    818.    Elapsed: 0:02:16.\n",
            "  Batch   360  of    818.    Elapsed: 0:02:33.\n",
            "  Batch   400  of    818.    Elapsed: 0:02:50.\n",
            "  Batch   440  of    818.    Elapsed: 0:03:07.\n",
            "  Batch   480  of    818.    Elapsed: 0:03:24.\n",
            "  Batch   520  of    818.    Elapsed: 0:03:41.\n",
            "  Batch   560  of    818.    Elapsed: 0:03:58.\n",
            "  Batch   600  of    818.    Elapsed: 0:04:15.\n",
            "  Batch   640  of    818.    Elapsed: 0:04:32.\n",
            "  Batch   680  of    818.    Elapsed: 0:04:49.\n",
            "  Batch   720  of    818.    Elapsed: 0:05:06.\n",
            "  Batch   760  of    818.    Elapsed: 0:05:23.\n",
            "  Batch   800  of    818.    Elapsed: 0:05:40.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:05:47\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:29\n",
            "[{'epoch': 1, 'Training Loss': 0.07989396572749977, 'Training Time': '0:05:48', 'Validation Time': '0:00:29'}, {'epoch': 2, 'Training Loss': 0.05009346804877335, 'Training Time': '0:05:47', 'Validation Time': '0:00:29'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    818.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    818.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    818.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    818.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    818.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    818.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    818.    Elapsed: 0:01:59.\n",
            "  Batch   320  of    818.    Elapsed: 0:02:16.\n",
            "  Batch   360  of    818.    Elapsed: 0:02:33.\n",
            "  Batch   400  of    818.    Elapsed: 0:02:50.\n",
            "  Batch   440  of    818.    Elapsed: 0:03:07.\n",
            "  Batch   480  of    818.    Elapsed: 0:03:24.\n",
            "  Batch   520  of    818.    Elapsed: 0:03:41.\n",
            "  Batch   560  of    818.    Elapsed: 0:03:58.\n",
            "  Batch   600  of    818.    Elapsed: 0:04:14.\n",
            "  Batch   640  of    818.    Elapsed: 0:04:31.\n",
            "  Batch   680  of    818.    Elapsed: 0:04:48.\n",
            "  Batch   720  of    818.    Elapsed: 0:05:05.\n",
            "  Batch   760  of    818.    Elapsed: 0:05:22.\n",
            "  Batch   800  of    818.    Elapsed: 0:05:39.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:05:47\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:29\n",
            "[{'epoch': 1, 'Training Loss': 0.07989396572749977, 'Training Time': '0:05:48', 'Validation Time': '0:00:29'}, {'epoch': 2, 'Training Loss': 0.05009346804877335, 'Training Time': '0:05:47', 'Validation Time': '0:00:29'}, {'epoch': 3, 'Training Loss': 0.01604674383277882, 'Training Time': '0:05:47', 'Validation Time': '0:00:29'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    818.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    818.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    818.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    818.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    818.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    818.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    818.    Elapsed: 0:01:59.\n",
            "  Batch   320  of    818.    Elapsed: 0:02:16.\n",
            "  Batch   360  of    818.    Elapsed: 0:02:33.\n",
            "  Batch   400  of    818.    Elapsed: 0:02:49.\n",
            "  Batch   440  of    818.    Elapsed: 0:03:06.\n",
            "  Batch   480  of    818.    Elapsed: 0:03:23.\n",
            "  Batch   520  of    818.    Elapsed: 0:03:40.\n",
            "  Batch   560  of    818.    Elapsed: 0:03:57.\n",
            "  Batch   600  of    818.    Elapsed: 0:04:14.\n",
            "  Batch   640  of    818.    Elapsed: 0:04:31.\n",
            "  Batch   680  of    818.    Elapsed: 0:04:48.\n",
            "  Batch   720  of    818.    Elapsed: 0:05:05.\n",
            "  Batch   760  of    818.    Elapsed: 0:05:22.\n",
            "  Batch   800  of    818.    Elapsed: 0:05:39.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:05:47\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:29\n",
            "[{'epoch': 1, 'Training Loss': 0.07989396572749977, 'Training Time': '0:05:48', 'Validation Time': '0:00:29'}, {'epoch': 2, 'Training Loss': 0.05009346804877335, 'Training Time': '0:05:47', 'Validation Time': '0:00:29'}, {'epoch': 3, 'Training Loss': 0.01604674383277882, 'Training Time': '0:05:47', 'Validation Time': '0:00:29'}, {'epoch': 4, 'Training Loss': 0.004706299155908652, 'Training Time': '0:05:47', 'Validation Time': '0:00:29'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqVGibIcQxI2"
      },
      "source": [
        "**Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3XfmpU6A8TP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "6dbb5633-2ca4-42b5-90a8-ae053dfc7fef"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-91155c2a8903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_stats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-6f844b95e724>\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(df_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Plot the learning curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valid. Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Label the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHuEtaXQBumV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f0810ab7-93b7-4003-dc1a-5361135198ad"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.99e-02</td>\n",
              "      <td>0:05:48</td>\n",
              "      <td>0:00:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.01e-02</td>\n",
              "      <td>0:05:47</td>\n",
              "      <td>0:00:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.60e-02</td>\n",
              "      <td>0:05:47</td>\n",
              "      <td>0:00:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.71e-03</td>\n",
              "      <td>0:05:47</td>\n",
              "      <td>0:00:29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss Training Time Validation Time\n",
              "epoch                                             \n",
              "1           7.99e-02       0:05:48         0:00:29\n",
              "2           5.01e-02       0:05:47         0:00:29\n",
              "3           1.60e-02       0:05:47         0:00:29\n",
              "4           4.71e-03       0:05:47         0:00:29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edzrl2k7Pf2m"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_test_non_hostile, index = test_data.index, columns=['non-hostile'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_test_non_hostile.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlOMpeiyP0e5"
      },
      "source": [
        "torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()}, 'non_hostile_test.tar')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJj5LP_OCFQl"
      },
      "source": [
        "TODO: 2 level model ( NH followed by others), 3 level model ( NH followed by fake followed by others)"
      ]
    }
  ]
}