{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model_2d.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyjuPoOPjJq"
      },
      "source": [
        "**Model Specifications**\n",
        "Detect Offensive using verloop Bert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCWMvHep3B7C"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOS1Mp42yMw",
        "outputId": "59a91adc-9216-4b67-ca7c-fe153ff1a9fb"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBBc1EW3F4v"
      },
      "source": [
        "**Required Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPNhzGe3A_-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import ast\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ958U2_3YnT"
      },
      "source": [
        "**Reading Data and Rearranging into DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJalNxA3Xqj"
      },
      "source": [
        "train_file = 'train.csv'\n",
        "val_file = 'val.csv'\n",
        "test_file = 'test.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDH9cHl3fjU"
      },
      "source": [
        "train_data = pd.read_csv(train_file, header=0, index_col=0)\n",
        "val_data = pd.read_csv(val_file, header=0, index_col=0)\n",
        "non_hostile_val_data = pd.read_csv('y_pred_val_non_hostile.csv', header=0, index_col=0)\n",
        "test_data = pd.read_csv(test_file, header=0, index_col=0)\n",
        "train_val_data = train_data.append(val_data, ignore_index=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6tPwxYgijPd"
      },
      "source": [
        "non_hostile_test_data = pd.read_csv('y_pred_test_non_hostile.csv', header=0, index_col=0)\n",
        "val_data_orig = val_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Y-IcvgC1DK"
      },
      "source": [
        "train_data.drop(train_data[train_data['Labels Set']=='non-hostile'].index, inplace = True)\n",
        "val_data.drop(non_hostile_val_data[non_hostile_val_data['non-hostile']==1].index, inplace=True)\n",
        "train_val_data.drop(train_val_data[train_val_data['Labels Set']=='non-hostile'].index, inplace = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mtwrtNEig5N"
      },
      "source": [
        "test_data.drop(non_hostile_test_data[non_hostile_test_data['non-hostile']==1].index, inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "mL-Yczph4Chg",
        "outputId": "f02f7572-8215-49f6-bc89-bc5a8edd7460"
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ... Unnamed: 13\n",
              "Unique ID                                                     ...            \n",
              "1          मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "4          @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "6          चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "11         RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "12         RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "nSxggvRQ4EGE",
        "outputId": "dfd6c57c-22e2-42d9-8bba-c0023c933bbb"
      },
      "source": [
        "print(val_data.shape)\n",
        "val_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(379, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>defamation</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...</td>\n",
              "      <td>भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...</td>\n",
              "      <td>अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...</td>\n",
              "      <td>भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...</td>\n",
              "      <td>दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>non-hostile</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...</td>\n",
              "      <td>सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "2          भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...  ...  भारतीय जनता पार्टी rss इतने गिरे हूं मेरी जासू...\n",
              "8          अद्भुत - जो वामपंथी कहते है कि महाभारत का युद्...  ...  अद्भुत - वामपंथी महाभारत युद्ध काल्पनिक है, सन...\n",
              "13         भाई जाके हिन्दू भाइयों की मदद कर जिनकी नौकरी च...  ...  भाई जाके हिन्दू भाइयों मदद जिनकी नौकरी चली आत्...\n",
              "14         यह दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे म...  ...  दुर्घटना कन्नूर अंतर्राष्ट्रीय हवाई अड्डे हुई,...\n",
              "15         सत्य कभी कमजोर नही होने देता। और “ज्ञान” कभी द...  ...  सत्य कमजोर नही देता। “ज्ञान” दुःखी भयभीत नही द...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JHNlD7M44Esg",
        "outputId": "5256f9d3-4add-4b12-f362-4bd6e019eec4"
      },
      "source": [
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(775, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...</td>\n",
              "      <td>कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '😂', '👍']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...</td>\n",
              "      <td>कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...</td>\n",
              "      <td>अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['👇', '😂', '😂', '😂', '😂']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>इन पंचर छापों को कोन समझाए कि उनके रोजगार मे...</td>\n",
              "      <td>पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@BasudebaTripat4:', '@Rajanspsingh1']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>अच्छा किया साले का सर फोड़ दिया,, गर्दन तोड़...</td>\n",
              "      <td>अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Post  ...                     Filtered_Post_Stopword_Removed\n",
              "Unique ID                                                     ...                                                   \n",
              "1          कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...  ...  कीस रोजगार कहना रोजगार मिलता 20 करोड रोजगार 6 ...\n",
              "3          कोई भी कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊ...  ...  कांग्रेसी, ऊंची छत पर, रेलवे लाइन पर, ऊंची बिल...\n",
              "4          अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...  ...  अंडरवर्ल्ड डॉन छोटा राजन भाई बीजेपी टिकट मिला है।\n",
              "5          RT @_Pb_swain_: इन पंचर छापों को कोन समझाए कि ...  ...  पंचर छापों समझाए रोजगार कमी कारण मोदी ट्यूब लै...\n",
              "8          @BasudebaTripat4: @Rajanspsingh1 अच्छा किया सा...  ...  अच्छा साले सर फोड़ दिया,, गर्दन तोड़ देते अच्छ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hMC_GwsU8-Sm",
        "outputId": "272af895-3e42-415a-8a2c-c6c63cafc507"
      },
      "source": [
        "print(train_val_data.shape)\n",
        "train_val_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3054, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Post</th>\n",
              "      <th>Labels Set</th>\n",
              "      <th>emails</th>\n",
              "      <th>urls</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>emojis</th>\n",
              "      <th>emoticons</th>\n",
              "      <th>reserved_words</th>\n",
              "      <th>Filtered_Post</th>\n",
              "      <th>Filtered_Post_Stopword_Removed</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>hate,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🙏', '🙏']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
              "      <td>मेरे देश हिन्दु निराले है। पक्के राम भक्त बाबर...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
              "      <td>defamation,offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@prabhav218']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं को यह कहते...</td>\n",
              "      <td>साले जेएनयू छाप कमिने लोग हिन्दुओं संविधान सबक...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>fake</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...</td>\n",
              "      <td>चीन UN तर्क भारत विपक्ष अजर‌ मसुद आतंकी मानता ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...</td>\n",
              "      <td>hate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@_Pb_swain_:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['🤔']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>मोदीजी और जब सारा देश सेना के साथ खडी है,\\n\\...</td>\n",
              "      <td>मोदीजी देश सेना खडी है, सयाने विदेश पडे है? बो...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ShilpiSinghINC:']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['RT']</td>\n",
              "      <td>48000 घरों को तोड़ने का आदेश आया है, किसी को...</td>\n",
              "      <td>48000 घरों तोड़ने आदेश आया है, फर्क़ पड़ता! अम...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Post  ... Unnamed: 13\n",
              "0   मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...  ...         NaN\n",
              "3   @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...  ...         NaN\n",
              "5   चीन ने UN में तर्क दिया की भारत का विपक्ष ही अ...  ...         NaN\n",
              "10  RT @_Pb_swain_: मोदीजी और जब सारा देश सेना के ...  ...         NaN\n",
              "11  RT @ShilpiSinghINC: 48000 घरों को तोड़ने का आद...  ...         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTg69u-b4wDw"
      },
      "source": [
        "**Transforming the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPoz0-5P4IsD"
      },
      "source": [
        "labels_set = {'defamation',\n",
        " 'fake',\n",
        " 'hate',\n",
        " 'non-hostile',\n",
        " 'offensive'}\n",
        "\n",
        "labels_mapping = {'defamation':0,\n",
        " 'fake':1,\n",
        " 'hate':2,\n",
        " 'non-hostile':3,\n",
        " 'offensive':4}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1OzBY4MKF"
      },
      "source": [
        "train_y = np.empty((0, 5))\n",
        "for index, row in train_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_y = np.vstack((train_y, y))\n",
        "\n",
        "\n",
        "val_y = np.empty((0, 5))\n",
        "for index, row in val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  val_y = np.vstack((val_y, y))\n",
        "\n",
        "train_val_y = np.empty((0, 5))\n",
        "for index, row in train_val_data.iterrows():\n",
        "  y = np.zeros((1, 5))\n",
        "  for label in row['Labels Set'].split(','):\n",
        "    y[0, labels_mapping[label]] = 1\n",
        "\n",
        "  train_val_y = np.vstack((train_val_y, y))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBa01jcE4NWo",
        "outputId": "4f3d12ca-d5bc-4704-8288-0488107dfb33"
      },
      "source": [
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(train_val_y.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2678, 5)\n",
            "(379, 5)\n",
            "(3054, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCtXMKS64VT"
      },
      "source": [
        "**Modelling Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AzCgmM40un"
      },
      "source": [
        "def X_process(sentences):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids, attention_masks\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FZSOIJ5Ua2"
      },
      "source": [
        "def train_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler = SequentialSampler(train_dataset), # Select batches sequentially\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    return train_dataloader"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AFD9Fs5aOw"
      },
      "source": [
        "def val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return validation_dataloader"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fjVV8d5a5f"
      },
      "source": [
        "def test_load(input_ids, attention_masks):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMF_Pg-9XYn"
      },
      "source": [
        "def train_val_load(input_ids, attention_masks, labels):\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    train_val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    train_validation_dataloader = DataLoader(\n",
        "                train_val_dataset, # The validation samples.\n",
        "                sampler = SequentialSampler(train_val_dataset), # Pull out batches sequentially.\n",
        "                batch_size = batch_size # Evaluate with this batch size.\n",
        "            )\n",
        "    \n",
        "    return train_validation_dataloader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRBErql77BAv"
      },
      "source": [
        "def train_fn(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask,\n",
        "                                       labels=b_labels)\n",
        "                loss = state.loss\n",
        "                logits = state.logits\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17SD78fGdXtx"
      },
      "source": [
        "def train_fn_test(train_dataloader, validation_dataloader):\n",
        "    \n",
        "    seed_val = 42\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "            state = model(b_input_ids, \n",
        "                                 token_type_ids=None, \n",
        "                                 attention_mask=b_input_mask, \n",
        "                                 labels=b_labels)\n",
        "            loss = state.loss\n",
        "            logits = state.logits\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        \n",
        "        y_pred_val = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "\n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                state = model(b_input_ids, \n",
        "                                       token_type_ids=None, \n",
        "                                       attention_mask=b_input_mask)\n",
        "                logits = state.logits\n",
        "\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            \n",
        "#             labels = label_ids\n",
        "            preds = logits\n",
        "            \n",
        "            pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#             labels_flat = labels.flatten()\n",
        "#             y_true.extend(labels_flat)\n",
        "            y_pred_val.extend(pred_flat)\n",
        "\n",
        "\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "        print(training_stats)\n",
        "        \n",
        "    return training_stats, y_pred_val\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBONPGg77Clo"
      },
      "source": [
        "def stats(training_stats):\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    return df_stats\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhcuXIG7Dpk"
      },
      "source": [
        "def plot_stats(df_stats):\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evcCcgjA7FTu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MSQH9l7GSm"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHqtP0nElkb"
      },
      "source": [
        "def evaluation(y_true, y_pred):\n",
        "  print(\"Fine Grained Accuracy = {}\".format(accuracy_score(y_true, y_pred)))\n",
        "  print(\"\\n\\nFine Grained Metrics\\n\")\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEu7-vTNxst"
      },
      "source": [
        "\n",
        "**Training for Offensive Class (Using Train Data and Val Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxBtbX61Nxsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c2a897-c3e1-4563-8562-6e141469f7e3"
      },
      "source": [
        "MODEL_NAME = 'verloop/Hinglish-Bert'\n",
        "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(26)\n",
        "np.random.seed(26)\n",
        "torch.manual_seed(26)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(device) # Send the model to the GPU if we have one"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at verloop/Hinglish-Bert were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at verloop/Hinglish-Bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UumXdB9Nxsx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Nr_05qNxsy"
      },
      "source": [
        "**TODO: Tryout different batchsize and length (80, 100)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2RNGhpNxsy"
      },
      "source": [
        "batch_size = 8\n",
        "max_length = 256"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPL2bLLvOWzr"
      },
      "source": [
        "# train_sentences = train_data['Filtered_Post'].values\n",
        "# val_sentences = val_data['Filtered_Post'].values\n",
        "# test_sentences = test_data['Filtered_Post'].values\n",
        "# train_val_sentences = train_val_data['Filtered_Post'].values\n",
        "\n",
        "train_sentences = train_data['Post'].values\n",
        "val_sentences = val_data['Post'].values\n",
        "test_sentences = test_data['Post'].values\n",
        "train_val_sentences = train_val_data['Post'].values"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbgOIjuQffx"
      },
      "source": [
        "y_train_offensive = train_y[:,4].astype(int)\n",
        "y_val_offensive = val_y[:,4].astype(int)\n",
        "y_train_val_offensive = train_val_y[:,4].astype(int)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzuEr8LedH7Y"
      },
      "source": [
        "train_labels_offensive = y_train_offensive\n",
        "val_labels_offensive = y_val_offensive"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN8t3Bc3Nxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a4cd74-0625-4891-cba7-0f6a9660c9bd"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_sentences)\n",
        "train_dataloader = train_load(input_ids, attention_masks, train_labels_offensive)\n",
        "\n",
        "input_ids, attention_masks = X_process(val_sentences)\n",
        "validation_dataloader = val_load(input_ids, attention_masks, val_labels_offensive)\n",
        "\n",
        "input_ids, attention_masks = X_process(test_sentences)\n",
        "test_dataloader = test_load(input_ids, attention_masks)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW2p6AI3Nxsy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JzyqSFNxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fae091b-8a7c-41fc-b3d1-26145bda81dc"
      },
      "source": [
        "training_stats, y_pred_val_offensive = train_fn(train_dataloader, validation_dataloader)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:35.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:10.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:27.\n",
            "  Batch   240  of    335.    Elapsed: 0:01:44.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:01.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:18.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:02:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.537229884871796, 'Valid. Loss': 0.5451016042691966, 'Valid. Accur.': 0.7578125, 'Training Time': '0:02:25', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    335.    Elapsed: 0:01:43.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:01.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:18.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:02:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.52\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.537229884871796, 'Valid. Loss': 0.5451016042691966, 'Valid. Accur.': 0.7578125, 'Training Time': '0:02:25', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.46404343485387406, 'Valid. Loss': 0.5215615703103443, 'Valid. Accur.': 0.7430555555555555, 'Training Time': '0:02:24', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    335.    Elapsed: 0:01:43.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:01.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:18.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:02:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.537229884871796, 'Valid. Loss': 0.5451016042691966, 'Valid. Accur.': 0.7578125, 'Training Time': '0:02:25', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.46404343485387406, 'Valid. Loss': 0.5215615703103443, 'Valid. Accur.': 0.7430555555555555, 'Training Time': '0:02:24', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.3861414603610982, 'Valid. Loss': 0.5845326463071009, 'Valid. Accur.': 0.7699652777777778, 'Training Time': '0:02:24', 'Validation Time': '0:00:07'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    335.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    335.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    335.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    335.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    335.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    335.    Elapsed: 0:01:43.\n",
            "  Batch   280  of    335.    Elapsed: 0:02:00.\n",
            "  Batch   320  of    335.    Elapsed: 0:02:18.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:02:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.76\n",
            "  Validation took: 0:00:07\n",
            "[{'epoch': 1, 'Training Loss': 0.537229884871796, 'Valid. Loss': 0.5451016042691966, 'Valid. Accur.': 0.7578125, 'Training Time': '0:02:25', 'Validation Time': '0:00:07'}, {'epoch': 2, 'Training Loss': 0.46404343485387406, 'Valid. Loss': 0.5215615703103443, 'Valid. Accur.': 0.7430555555555555, 'Training Time': '0:02:24', 'Validation Time': '0:00:07'}, {'epoch': 3, 'Training Loss': 0.3861414603610982, 'Valid. Loss': 0.5845326463071009, 'Valid. Accur.': 0.7699652777777778, 'Training Time': '0:02:24', 'Validation Time': '0:00:07'}, {'epoch': 4, 'Training Loss': 0.3149909248116857, 'Valid. Loss': 0.7551700459249938, 'Valid. Accur.': 0.7725694444444445, 'Training Time': '0:02:24', 'Validation Time': '0:00:07'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoV30azNxsz"
      },
      "source": [
        "**Evaluation on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvWJNE7YNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "76709dcb-cf5e-49ac-86ad-6e91cb6e69c6"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZ4Tx8PNxsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f5307ea9-6bf5-4207-e075-d04603f05ea1"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.54</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:02:25</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0:02:24</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0:02:24</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0:02:24</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.54         0.55           0.76       0:02:25         0:00:07\n",
              "2               0.46         0.52           0.74       0:02:24         0:00:07\n",
              "3               0.39         0.58           0.77       0:02:24         0:00:07\n",
              "4               0.31         0.76           0.77       0:02:24         0:00:07"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrRQFllONxsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7ae6c1-bd65-48d6-ded3-66d47dac5022"
      },
      "source": [
        "evaluation(y_val_offensive, y_pred_val_offensive)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine Grained Accuracy = 0.7783641160949868\n",
            "\n",
            "\n",
            "Fine Grained Metrics\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       276\n",
            "           1       0.60      0.55      0.58       103\n",
            "\n",
            "    accuracy                           0.78       379\n",
            "   macro avg       0.72      0.71      0.71       379\n",
            "weighted avg       0.77      0.78      0.78       379\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHgr-fodo8e"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_val_offensive, index = val_data.index, columns=['offensive'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_val_offensive.csv')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HWdCRDNxs0"
      },
      "source": [
        "**Training for Offensive Class (Using Train +Val Data and Test Data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwvcdNspi294"
      },
      "source": [
        "train_val_labels_offensive = y_train_val_offensive"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-RaRs7Nxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d37c8b6-5af2-44d9-c004-6452801a7829"
      },
      "source": [
        "input_ids, attention_masks = X_process(train_val_sentences)\n",
        "train_val_dataloader = train_val_load(input_ids, attention_masks, train_val_labels_offensive)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wfwVeBNxs0"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_val_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmjATAqNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5413b69-f2c7-47c7-fd4a-d5a770148e2c"
      },
      "source": [
        "training_stats, y_pred_offensive = train_fn_test(train_val_dataloader, test_dataloader)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:52.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    382.    Elapsed: 0:01:43.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:00.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:18.\n",
            "  Batch   360  of    382.    Elapsed: 0:02:35.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.36833641875513307, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}]\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    382.    Elapsed: 0:01:43.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:00.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:17.\n",
            "  Batch   360  of    382.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.36833641875513307, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.3144976261665518, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}]\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:09.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:26.\n",
            "  Batch   240  of    382.    Elapsed: 0:01:43.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:00.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:17.\n",
            "  Batch   360  of    382.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.36833641875513307, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.3144976261665518, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}, {'epoch': 3, 'Training Loss': 0.22565877527554387, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}]\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    382.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    382.    Elapsed: 0:00:34.\n",
            "  Batch   120  of    382.    Elapsed: 0:00:51.\n",
            "  Batch   160  of    382.    Elapsed: 0:01:08.\n",
            "  Batch   200  of    382.    Elapsed: 0:01:25.\n",
            "  Batch   240  of    382.    Elapsed: 0:01:42.\n",
            "  Batch   280  of    382.    Elapsed: 0:02:00.\n",
            "  Batch   320  of    382.    Elapsed: 0:02:17.\n",
            "  Batch   360  of    382.    Elapsed: 0:02:34.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:02:43\n",
            "\n",
            "Running Validation...\n",
            "  Validation took: 0:00:14\n",
            "[{'epoch': 1, 'Training Loss': 0.36833641875513307, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}, {'epoch': 2, 'Training Loss': 0.3144976261665518, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}, {'epoch': 3, 'Training Loss': 0.22565877527554387, 'Training Time': '0:02:44', 'Validation Time': '0:00:14'}, {'epoch': 4, 'Training Loss': 0.16695906920267112, 'Training Time': '0:02:43', 'Validation Time': '0:00:14'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlAyssNRJ2S"
      },
      "source": [
        "**Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhWwhMUNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "outputId": "8f42bef4-9777-4cb4-b770-4ced1a54f52f"
      },
      "source": [
        "df_stats  = stats(training_stats)\n",
        "plot_stats(df_stats)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-91155c2a8903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_stats\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-6f844b95e724>\u001b[0m in \u001b[0;36mplot_stats\u001b[0;34m(df_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Plot the learning curve.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valid. Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Label the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Valid. Loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54illM8xNxs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c2a2f196-d097-4df6-ca8c-8708ae4f3f09"
      },
      "source": [
        "df_stats"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0:02:44</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0:02:44</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0:02:44</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.17</td>\n",
              "      <td>0:02:43</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss Training Time Validation Time\n",
              "epoch                                             \n",
              "1               0.37       0:02:44         0:00:14\n",
              "2               0.31       0:02:44         0:00:14\n",
              "3               0.23       0:02:44         0:00:14\n",
              "4               0.17       0:02:43         0:00:14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amqNhvhitcLw"
      },
      "source": [
        "result_df = pd.DataFrame(y_pred_offensive, index = test_data.index, columns=['offensive'])\n",
        "result_df.index.name = 'Unique ID'\n",
        "result_df.to_csv('y_pred_test_offensive.csv')"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}